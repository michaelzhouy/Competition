{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:42:56.171022Z",
     "start_time": "2020-06-17T08:42:54.748873Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from itertools import product\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:42:56.186941Z",
     "start_time": "2020-06-17T08:42:56.171980Z"
    }
   },
   "outputs": [],
   "source": [
    "# 节省内存读文件\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\"\n",
    "    iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\n",
    "    @param df:\n",
    "    @return:\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum()\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('str')\n",
    "\n",
    "    end_mem = df.memory_usage().sum()\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:42:56.219401Z",
     "start_time": "2020-06-17T08:42:56.188937Z"
    }
   },
   "outputs": [],
   "source": [
    "class MeanEncoder:\n",
    "    def __init__(self, categorical_features, n_splits=10, target_type='classification', prior_weight_func=None):\n",
    "        \"\"\"\n",
    "        :param categorical_features: list of str, the name of the categorical columns to encode\n",
    " \n",
    "        :param n_splits: the number of splits used in mean encoding\n",
    "        \n",
    "        :param target_type: str, 'regression' or 'classification'\n",
    " \n",
    "        :param prior_weight_func:\n",
    "        a function that takes in the number of observations, and outputs prior weight\n",
    "        when a dict is passed, the default exponential decay function will be used:\n",
    "        k: the number of observations needed for the posterior to be weighted equally as the prior\n",
    "        f: larger f --> smaller slope\n",
    "        \"\"\"\n",
    " \n",
    "        self.categorical_features = categorical_features\n",
    "        self.n_splits = n_splits\n",
    "        self.learned_stats = {}\n",
    " \n",
    "        if target_type == 'classification':\n",
    "            self.target_type = target_type\n",
    "            self.target_values = []\n",
    "        else:\n",
    "            self.target_type = 'regression'\n",
    "            self.target_values = None\n",
    " \n",
    "        if isinstance(prior_weight_func, dict):\n",
    "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n",
    "        elif callable(prior_weight_func):\n",
    "            self.prior_weight_func = prior_weight_func\n",
    "        else:\n",
    "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n",
    " \n",
    "    @staticmethod\n",
    "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n",
    "        X_train = X_train[[variable]].copy()\n",
    "        X_test = X_test[[variable]].copy()\n",
    " \n",
    "        if target is not None:\n",
    "            nf_name = '{}_pred_{}'.format(variable, target)\n",
    "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n",
    "        else:\n",
    "            nf_name = '{}_pred'.format(variable)\n",
    "            X_train['pred_temp'] = y_train  # regression\n",
    "        prior = X_train['pred_temp'].mean()\n",
    " \n",
    "        col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg(['mean', 'size'])\n",
    "        col_avg_y['size'] = prior_weight_func(col_avg_y['size'])\n",
    "        col_avg_y[nf_name] = col_avg_y['size'] * prior + (1 - col_avg_y['size']) * col_avg_y['mean']\n",
    "        col_avg_y.drop(['size', 'mean'], axis=1, inplace=True)\n",
    " \n",
    "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n",
    "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n",
    " \n",
    "        return nf_train, nf_test, prior, col_avg_y\n",
    " \n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :param y: pandas Series or numpy array, n_samples\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        if self.target_type == 'classification':\n",
    "            skf = StratifiedKFold(self.n_splits)\n",
    "        else:\n",
    "            skf = KFold(self.n_splits)\n",
    " \n",
    "        if self.target_type == 'classification':\n",
    "            self.target_values = sorted(set(y))\n",
    "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n",
    "                                  product(self.categorical_features, self.target_values)}\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(X, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        else:\n",
    "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(X, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        return X_new\n",
    " \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    " \n",
    "        if self.target_type == 'classification':\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "        else:\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    " \n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:20.298915Z",
     "start_time": "2020-06-17T08:42:56.220360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 97824.00 MB\n",
      "Memory usage after optimization is: 55082.00 MB\n",
      "Decreased by 43.7%\n",
      "Memory usage of dataframe is 16488.00 MB\n",
      "Memory usage after optimization is: 16488.00 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage of dataframe is 320987648.00 MB\n",
      "Memory usage after optimization is: 255787058.00 MB\n",
      "Decreased by 20.3%\n",
      "Memory usage of dataframe is 17697536.00 MB\n",
      "Memory usage after optimization is: 14102750.00 MB\n",
      "Decreased by 20.3%\n"
     ]
    }
   ],
   "source": [
    "train_user = reduce_mem_usage(pd.read_csv('../input/train/train_user.csv', usecols=['phone_no_m', 'label']))\n",
    "test_user = reduce_mem_usage(pd.read_csv('../input/test/test_user.csv', usecols=['phone_no_m']))\n",
    "\n",
    "train_voc = reduce_mem_usage(pd.read_csv('../input/train/train_voc.csv'))\n",
    "test_voc = reduce_mem_usage(pd.read_csv('../input/test/test_voc.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:20.305885Z",
     "start_time": "2020-06-17T08:43:20.299898Z"
    }
   },
   "outputs": [],
   "source": [
    "df_user = pd.concat([train_user, test_user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:20.864587Z",
     "start_time": "2020-06-17T08:43:20.307426Z"
    }
   },
   "outputs": [],
   "source": [
    "# 只取最后一个月的数据\n",
    "train_voc = train_voc[train_voc['start_datetime'] >= '2020-03-01 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:20.874528Z",
     "start_time": "2020-06-17T08:43:20.866583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['phone_no_m', 'opposite_no_m', 'calltype_id', 'start_datetime', 'call_dur', 'city_name', 'county_name', 'imei_m'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_voc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:21.118930Z",
     "start_time": "2020-06-17T08:43:20.876035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voc = pd.concat([train_voc, test_voc])\n",
    "\n",
    "del train_voc, test_voc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:23.424759Z",
     "start_time": "2020-06-17T08:43:21.120892Z"
    }
   },
   "outputs": [],
   "source": [
    "df_voc['voc_day'] = df_voc['start_datetime'].astype('datetime64').dt.day\n",
    "df_voc['voc_hour'] = df_voc['start_datetime'].astype('datetime64').dt.hour\n",
    "df_voc['voc_dayofweek'] = df_voc['start_datetime'].astype('datetime64').dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:23.931304Z",
     "start_time": "2020-06-17T08:43:23.425756Z"
    }
   },
   "outputs": [],
   "source": [
    "phone_no_m = df_voc[['phone_no_m']].copy()\n",
    "phone_no_m = phone_no_m.drop_duplicates(subset=['phone_no_m'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:25.012433Z",
     "start_time": "2020-06-17T08:43:23.932303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通话次数，通话人数\n",
    "tmp = df_voc.groupby('phone_no_m')['opposite_no_m'].agg(opposite_cnt='count', opposite_nunique='nunique')\n",
    "phone_no_m = phone_no_m.merge(tmp, how='left', on='phone_no_m')\n",
    "\n",
    "del tmp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:27.194815Z",
     "start_time": "2020-06-17T08:43:25.013396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "主叫通话\n",
    "\"\"\"\n",
    "\n",
    "df_calltype_id_1 = df_voc.loc[df_voc['calltype_id'] == 1, :].copy()\n",
    "\n",
    "# 主叫通话次数，主叫通话使用的手机个数\n",
    "tmp = df_calltype_id_1.groupby('phone_no_m')['imei_m'].agg(voc_calltype_id_1_cnt='count', imeis='nunique')\n",
    "phone_no_m = phone_no_m.merge(tmp, on='phone_no_m', how='left')\n",
    "del tmp\n",
    "gc.collect()\n",
    "\n",
    "# 主叫通话时长\n",
    "tmp = df_calltype_id_1.groupby('phone_no_m')['call_dur'].agg(voc_calltype_id_1_call_dur_sum='sum')\n",
    "phone_no_m = phone_no_m.merge(tmp, on='phone_no_m', how='left')\n",
    "del tmp\n",
    "gc.collect()\n",
    "\n",
    "# 主叫通话时长小于30s的次数\n",
    "tmp1 = df_calltype_id_1[df_calltype_id_1['call_dur'] < 30]\n",
    "tmp2 = tmp1.groupby('phone_no_m')['call_dur'].agg(voc_calltype_id_1_30s_cnt='count')\n",
    "phone_no_m = phone_no_m.merge(tmp2, on='phone_no_m', how='left')\n",
    "del tmp1, tmp2\n",
    "gc.collect()\n",
    "\n",
    "# 主叫通话时长小于60s的次数\n",
    "tmp1 = df_calltype_id_1[df_calltype_id_1['call_dur'] < 60]\n",
    "tmp2 = tmp1.groupby('phone_no_m')['call_dur'].agg(voc_calltype_id_1_60s_cnt='count')\n",
    "phone_no_m = phone_no_m.merge(tmp2, on='phone_no_m', how='left')\n",
    "del tmp1, tmp2\n",
    "gc.collect()\n",
    "\n",
    "# 主叫通话时长大于300s（5分钟）的次数\n",
    "tmp1 = df_calltype_id_1[df_calltype_id_1['call_dur'] > 300]\n",
    "tmp2 = tmp1.groupby('phone_no_m')['call_dur'].agg(voc_calltype_id_1_300s_cnt='count')\n",
    "phone_no_m = phone_no_m.merge(tmp2, on='phone_no_m', how='left')\n",
    "del tmp1, tmp2\n",
    "gc.collect()\n",
    "\n",
    "# 主叫通话时长小于30s的次数的占比\n",
    "phone_no_m['voc_calltype_id_1_30s_rate'] = phone_no_m['voc_calltype_id_1_30s_cnt'] / phone_no_m['voc_calltype_id_1_cnt']\n",
    "\n",
    "# 主叫通话时长小于60s的次数的占比\n",
    "phone_no_m['voc_calltype_id_1_60s_rate'] = phone_no_m['voc_calltype_id_1_60s_cnt'] / phone_no_m['voc_calltype_id_1_cnt']\n",
    "\n",
    "# 主叫通话时长小于60s的次数的占比\n",
    "phone_no_m['voc_calltype_id_1_300s_rate'] = phone_no_m['voc_calltype_id_1_300s_cnt'] / phone_no_m['voc_calltype_id_1_cnt']\n",
    "\n",
    "\n",
    "# 主叫通话次数/通话次数，\n",
    "phone_no_m[\"call_type_id_1_rate\"] = phone_no_m['voc_calltype_id_1_cnt'] / phone_no_m['opposite_cnt']\n",
    "\n",
    "# 主叫通话时所在地市的个数\n",
    "tmp = df_calltype_id_1.groupby('phone_no_m')['city_name'].agg(city_name_call='nunique')\n",
    "phone_no_m = phone_no_m.merge(tmp, on='phone_no_m', how='left')\n",
    "del tmp\n",
    "gc.collect()\n",
    "\n",
    "# 主叫通话时所在区县的个数\n",
    "tmp = df_calltype_id_1.groupby(\"phone_no_m\")['county_name'].agg(county_name_call='nunique')\n",
    "phone_no_m = phone_no_m.merge(tmp, on=\"phone_no_m\", how=\"left\")\n",
    "del tmp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:29.073822Z",
     "start_time": "2020-06-17T08:43:27.195813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "与对端通话统计\n",
    "\"\"\"\n",
    "\n",
    "# 与对端通话次数，与对端总通话时长\n",
    "tmp = df_voc.groupby(['phone_no_m', 'opposite_no_m'])['call_dur'].agg(call_count='count', call_sum='sum')\n",
    "\n",
    "# 与对端通话次数的统计量\n",
    "phone2opposite = tmp.groupby('phone_no_m')['call_count'].agg(phone2opposite_cnt_mean='mean',\n",
    "                                                             phone2opposite_cnt_median='median',\n",
    "                                                             phone2opposite_cnt_min='min',\n",
    "                                                             phone2opposite_cnt_max='max',\n",
    "                                                             phone2opposite_cnt_std='std')\n",
    "phone_no_m = phone_no_m.merge(phone2opposite, on='phone_no_m', how='left')\n",
    "del phone2opposite\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# 与对端总通话时长的统计量\n",
    "phone2opposite = tmp.groupby('phone_no_m')['call_sum'].agg(phone2opposite_call_dur_mean='mean',\n",
    "                                                           phone2opposite_call_dur_median='median',\n",
    "                                                           phone2opposite_call_dur_min='min',\n",
    "                                                           phone2opposite_call_dur_max='max',\n",
    "                                                           phone2opposite_call_dur_std='std')\n",
    "phone_no_m = phone_no_m.merge(phone2opposite, on='phone_no_m', how='left')\n",
    "del phone2opposite, tmp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:29.536566Z",
     "start_time": "2020-06-17T08:43:29.074787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "通话时长的统计\n",
    "\"\"\"\n",
    "\n",
    "# 通话时长的统计量\n",
    "tmp = df_voc.groupby('phone_no_m')['call_dur'].agg(call_dur_mean='mean',\n",
    "                                                   call_dur_median='median',\n",
    "                                                   call_dur_max='max',\n",
    "                                                   call_dur_min='min',\n",
    "                                                   call_dur_std='std')\n",
    "phone_no_m = phone_no_m.merge(tmp, on='phone_no_m', how='left')\n",
    "del tmp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:31.031677Z",
     "start_time": "2020-06-17T08:43:29.537563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 收费号码所在地市的个数\n",
    "tmp = df_voc.groupby('phone_no_m')['city_name'].agg(city_name_nunique='nunique')\n",
    "phone_no_m = phone_no_m.merge(tmp, on='phone_no_m', how='left')\n",
    "\n",
    "# 收费号码所在区县的个数\n",
    "tmp = df_voc.groupby('phone_no_m')['county_name'].agg(county_name_nunique='nunique')\n",
    "phone_no_m = phone_no_m.merge(tmp, on=\"phone_no_m\", how='left')\n",
    "\n",
    "# 收费号码通话类型的个数\n",
    "tmp = df_voc.groupby('phone_no_m')['calltype_id'].agg(calltype_id_unique='nunique')\n",
    "phone_no_m = phone_no_m.merge(tmp, on='phone_no_m', how='left')\n",
    "\n",
    "del tmp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:35.796067Z",
     "start_time": "2020-06-17T08:43:31.032675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "通话时间点的偏好\n",
    "\"\"\"\n",
    "tmp = df_voc.groupby('phone_no_m')['voc_hour'].agg(voc_hour_mode=lambda x: stats.mode(x)[0][0],        # 频次最高的元素\n",
    "                                                   voc_hour_mode_count=lambda x: stats.mode(x)[1][0],  # 频次最高的元素的频次\n",
    "                                                   voc_hour_nunique='nunique')\n",
    "phone_no_m = phone_no_m.merge(tmp, on='phone_no_m', how='left')\n",
    "\n",
    "\n",
    "tmp = df_voc.groupby('phone_no_m')['voc_day'].agg(voc_day_mode=lambda x: stats.mode(x)[0][0],\n",
    "                                                  voc_day_mode_count=lambda x: stats.mode(x)[1][0],\n",
    "                                                  voc_day_nunique='nunique')\n",
    "phone_no_m = phone_no_m.merge(tmp, on='phone_no_m', how='left')\n",
    "\n",
    "del tmp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:35.807996Z",
     "start_time": "2020-06-17T08:43:35.797025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['phone_no_m', 'opposite_cnt', 'opposite_nunique', 'voc_calltype_id_1_cnt', 'imeis', 'voc_calltype_id_1_call_dur_sum', 'voc_calltype_id_1_30s_cnt', 'voc_calltype_id_1_60s_cnt', 'voc_calltype_id_1_300s_cnt', 'voc_calltype_id_1_30s_rate', 'voc_calltype_id_1_60s_rate', 'voc_calltype_id_1_300s_rate', 'call_type_id_1_rate', 'city_name_call', 'county_name_call', 'phone2opposite_cnt_mean', 'phone2opposite_cnt_median', 'phone2opposite_cnt_min', 'phone2opposite_cnt_max', 'phone2opposite_cnt_std', 'phone2opposite_call_dur_mean', 'phone2opposite_call_dur_median', 'phone2opposite_call_dur_min', 'phone2opposite_call_dur_max', 'phone2opposite_call_dur_std', 'call_dur_mean', 'call_dur_median', 'call_dur_max', 'call_dur_min', 'call_dur_std', 'city_name_nunique', 'county_name_nunique', 'calltype_id_unique', 'voc_hour_mode', 'voc_hour_mode_count', 'voc_hour_nunique', 'voc_day_mode', 'voc_day_mode_count', 'voc_day_nunique'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_no_m.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:35.916217Z",
     "start_time": "2020-06-17T08:43:35.809542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voc = df_user.merge(phone_no_m, how='left', on='phone_no_m')\n",
    "\n",
    "del df_user, phone_no_m\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:35.929182Z",
     "start_time": "2020-06-17T08:43:35.917215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6106, 40), (2045, 40))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voc_train = df_voc[df_voc.label.notna()]\n",
    "df_voc_test = df_voc[df_voc.label.isna()]\n",
    "\n",
    "df_voc_train.shape, df_voc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:35.942150Z",
     "start_time": "2020-06-17T08:43:35.930180Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df_voc_train.drop('label', axis=1), df_voc_train['label'],\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:35.948133Z",
     "start_time": "2020-06-17T08:43:35.943150Z"
    }
   },
   "outputs": [],
   "source": [
    "train_cols = [i for i in X_train if i not in ['phone_no_m', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:35.956111Z",
     "start_time": "2020-06-17T08:43:35.952123Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'binary',\n",
    "          'boosting': 'gbdt',\n",
    "          'metric': 'auc',\n",
    "          'learning_rate': 0.1,\n",
    "          'num_leaves': 31,\n",
    "          'lambda_l1': 0,\n",
    "          'lambda_l2': 1,\n",
    "          'min_data_in_leaf': 20,\n",
    "          'is_unbalance': True,\n",
    "          'max_depth': -1,\n",
    "          'seed': 2020}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:41.276918Z",
     "start_time": "2020-06-17T08:43:35.959104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opposite_cnt\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.874224\tvalid_0's auc: 0.834843\n",
      "[40]\ttraining's auc: 0.877919\tvalid_0's auc: 0.831199\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.870285\tvalid_0's auc: 0.838273\n",
      "*****\n",
      "0.8382733653800163\n",
      "********************\n",
      "\n",
      "\n",
      "opposite_nunique\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.904897\tvalid_0's auc: 0.873224\n",
      "[40]\ttraining's auc: 0.906297\tvalid_0's auc: 0.873087\n",
      "[60]\ttraining's auc: 0.907017\tvalid_0's auc: 0.872573\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's auc: 0.904134\tvalid_0's auc: 0.873933\n",
      "*****\n",
      "0.8739327737121538\n",
      "********************\n",
      "\n",
      "\n",
      "voc_calltype_id_1_cnt\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.866163\tvalid_0's auc: 0.83139\n",
      "[40]\ttraining's auc: 0.869541\tvalid_0's auc: 0.828081\n",
      "[60]\ttraining's auc: 0.871562\tvalid_0's auc: 0.827922\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.865587\tvalid_0's auc: 0.83251\n",
      "*****\n",
      "0.8325097455397714\n",
      "********************\n",
      "\n",
      "\n",
      "imeis\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.843497\tvalid_0's auc: 0.832652\n",
      "[40]\ttraining's auc: 0.84359\tvalid_0's auc: 0.832839\n",
      "[60]\ttraining's auc: 0.84359\tvalid_0's auc: 0.832839\n",
      "[80]\ttraining's auc: 0.84359\tvalid_0's auc: 0.832839\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.84359\tvalid_0's auc: 0.832839\n",
      "*****\n",
      "0.8328385827713206\n",
      "********************\n",
      "\n",
      "\n",
      "voc_calltype_id_1_call_dur_sum\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.871161\tvalid_0's auc: 0.842109\n",
      "[40]\ttraining's auc: 0.875385\tvalid_0's auc: 0.840929\n",
      "[60]\ttraining's auc: 0.877326\tvalid_0's auc: 0.838242\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's auc: 0.871593\tvalid_0's auc: 0.842578\n",
      "*****\n",
      "0.8425781436839336\n",
      "********************\n",
      "\n",
      "\n",
      "voc_calltype_id_1_30s_cnt\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.834636\tvalid_0's auc: 0.79265\n",
      "[40]\ttraining's auc: 0.835822\tvalid_0's auc: 0.789616\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.832448\tvalid_0's auc: 0.796971\n",
      "*****\n",
      "0.7969714090974315\n",
      "********************\n",
      "\n",
      "\n",
      "voc_calltype_id_1_60s_cnt\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.847963\tvalid_0's auc: 0.805301\n",
      "[40]\ttraining's auc: 0.849242\tvalid_0's auc: 0.803713\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's auc: 0.845279\tvalid_0's auc: 0.809218\n",
      "*****\n",
      "0.809217606543263\n",
      "********************\n",
      "\n",
      "\n",
      "voc_calltype_id_1_300s_cnt\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.673736\tvalid_0's auc: 0.677967\n",
      "[40]\ttraining's auc: 0.673824\tvalid_0's auc: 0.678297\n",
      "[60]\ttraining's auc: 0.674068\tvalid_0's auc: 0.677983\n",
      "[80]\ttraining's auc: 0.675288\tvalid_0's auc: 0.679825\n",
      "[100]\ttraining's auc: 0.675358\tvalid_0's auc: 0.679711\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.674412\tvalid_0's auc: 0.68007\n",
      "*****\n",
      "0.680069773281676\n",
      "********************\n",
      "\n",
      "\n",
      "voc_calltype_id_1_30s_rate\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.826582\tvalid_0's auc: 0.807132\n",
      "[40]\ttraining's auc: 0.830502\tvalid_0's auc: 0.805287\n",
      "[60]\ttraining's auc: 0.833161\tvalid_0's auc: 0.805013\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.825464\tvalid_0's auc: 0.80734\n",
      "*****\n",
      "0.8073402448940546\n",
      "********************\n",
      "\n",
      "\n",
      "voc_calltype_id_1_60s_rate\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.838754\tvalid_0's auc: 0.803644\n",
      "[40]\ttraining's auc: 0.843232\tvalid_0's auc: 0.804324\n",
      "[60]\ttraining's auc: 0.845851\tvalid_0's auc: 0.805738\n",
      "[80]\ttraining's auc: 0.84763\tvalid_0's auc: 0.804828\n",
      "[100]\ttraining's auc: 0.848725\tvalid_0's auc: 0.804526\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's auc: 0.845851\tvalid_0's auc: 0.805738\n",
      "*****\n",
      "0.8057379107475965\n",
      "********************\n",
      "\n",
      "\n",
      "voc_calltype_id_1_300s_rate\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.692395\tvalid_0's auc: 0.659198\n",
      "[40]\ttraining's auc: 0.69605\tvalid_0's auc: 0.659794\n",
      "[60]\ttraining's auc: 0.698068\tvalid_0's auc: 0.663522\n",
      "[80]\ttraining's auc: 0.700019\tvalid_0's auc: 0.663241\n",
      "[100]\ttraining's auc: 0.700791\tvalid_0's auc: 0.662949\n",
      "[120]\ttraining's auc: 0.701316\tvalid_0's auc: 0.663175\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's auc: 0.698872\tvalid_0's auc: 0.664111\n",
      "*****\n",
      "0.6641107045487158\n",
      "********************\n",
      "\n",
      "\n",
      "call_type_id_1_rate\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.8837\tvalid_0's auc: 0.844424\n",
      "[40]\ttraining's auc: 0.885721\tvalid_0's auc: 0.841468\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's auc: 0.881258\tvalid_0's auc: 0.84604\n",
      "*****\n",
      "0.8460399029033339\n",
      "********************\n",
      "\n",
      "\n",
      "city_name_call\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.793948\tvalid_0's auc: 0.78005\n",
      "[40]\ttraining's auc: 0.793949\tvalid_0's auc: 0.780047\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.793948\tvalid_0's auc: 0.78005\n",
      "*****\n",
      "0.7800497441048453\n",
      "********************\n",
      "\n",
      "\n",
      "county_name_call\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.810776\tvalid_0's auc: 0.78237\n",
      "[40]\ttraining's auc: 0.811117\tvalid_0's auc: 0.781527\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's auc: 0.810765\tvalid_0's auc: 0.782407\n",
      "*****\n",
      "0.7824069091691778\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_cnt_mean\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.912267\tvalid_0's auc: 0.860654\n",
      "[40]\ttraining's auc: 0.915663\tvalid_0's auc: 0.861347\n",
      "[60]\ttraining's auc: 0.917863\tvalid_0's auc: 0.861566\n",
      "[80]\ttraining's auc: 0.919117\tvalid_0's auc: 0.860799\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.916138\tvalid_0's auc: 0.862737\n",
      "*****\n",
      "0.862737360692591\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_cnt_median\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.854833\tvalid_0's auc: 0.856806\n",
      "[40]\ttraining's auc: 0.854862\tvalid_0's auc: 0.856851\n",
      "[60]\ttraining's auc: 0.854882\tvalid_0's auc: 0.856936\n",
      "[80]\ttraining's auc: 0.854888\tvalid_0's auc: 0.856895\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's auc: 0.85487\tvalid_0's auc: 0.856941\n",
      "*****\n",
      "0.8569408571291912\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_cnt_min\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.797037\tvalid_0's auc: 0.793966\n",
      "[40]\ttraining's auc: 0.797037\tvalid_0's auc: 0.793966\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's auc: 0.797037\tvalid_0's auc: 0.793966\n",
      "*****\n",
      "0.7939655378581336\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_cnt_max\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.866109\tvalid_0's auc: 0.826266\n",
      "[40]\ttraining's auc: 0.86691\tvalid_0's auc: 0.825695\n",
      "[60]\ttraining's auc: 0.867644\tvalid_0's auc: 0.824782\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.86646\tvalid_0's auc: 0.826673\n",
      "*****\n",
      "0.8266728846797723\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_cnt_std\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.88897\tvalid_0's auc: 0.84447\n",
      "[40]\ttraining's auc: 0.892458\tvalid_0's auc: 0.84336\n",
      "[60]\ttraining's auc: 0.894148\tvalid_0's auc: 0.842913\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.889139\tvalid_0's auc: 0.844802\n",
      "*****\n",
      "0.8448022791409576\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_call_dur_mean\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.877641\tvalid_0's auc: 0.816108\n",
      "[40]\ttraining's auc: 0.881257\tvalid_0's auc: 0.813699\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.872121\tvalid_0's auc: 0.81801\n",
      "*****\n",
      "0.8180095183431386\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_call_dur_median\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.882125\tvalid_0's auc: 0.845068\n",
      "[40]\ttraining's auc: 0.885876\tvalid_0's auc: 0.843047\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.874094\tvalid_0's auc: 0.84962\n",
      "*****\n",
      "0.8496197445831539\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_call_dur_min\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.887222\tvalid_0's auc: 0.862247\n",
      "[40]\ttraining's auc: 0.888666\tvalid_0's auc: 0.862604\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.885868\tvalid_0's auc: 0.864395\n",
      "*****\n",
      "0.8643949992825369\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_call_dur_max\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.857833\tvalid_0's auc: 0.789625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\ttraining's auc: 0.863595\tvalid_0's auc: 0.78828\n",
      "[60]\ttraining's auc: 0.866085\tvalid_0's auc: 0.786771\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.854489\tvalid_0's auc: 0.792704\n",
      "*****\n",
      "0.7927039986607356\n",
      "********************\n",
      "\n",
      "\n",
      "phone2opposite_call_dur_std\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.858365\tvalid_0's auc: 0.790863\n",
      "[40]\ttraining's auc: 0.86129\tvalid_0's auc: 0.794028\n",
      "[60]\ttraining's auc: 0.862985\tvalid_0's auc: 0.795716\n",
      "[80]\ttraining's auc: 0.863998\tvalid_0's auc: 0.796097\n",
      "[100]\ttraining's auc: 0.864723\tvalid_0's auc: 0.796459\n",
      "[120]\ttraining's auc: 0.865349\tvalid_0's auc: 0.796689\n",
      "[140]\ttraining's auc: 0.865742\tvalid_0's auc: 0.796752\n",
      "[160]\ttraining's auc: 0.866047\tvalid_0's auc: 0.79639\n",
      "[180]\ttraining's auc: 0.866295\tvalid_0's auc: 0.796276\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's auc: 0.865588\tvalid_0's auc: 0.796859\n",
      "*****\n",
      "0.796859305495767\n",
      "********************\n",
      "\n",
      "\n",
      "call_dur_mean\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.858665\tvalid_0's auc: 0.814983\n",
      "[40]\ttraining's auc: 0.862998\tvalid_0's auc: 0.810799\n",
      "[60]\ttraining's auc: 0.865091\tvalid_0's auc: 0.810094\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's auc: 0.858039\tvalid_0's auc: 0.815631\n",
      "*****\n",
      "0.8156314272731621\n",
      "********************\n",
      "\n",
      "\n",
      "call_dur_median\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.854\tvalid_0's auc: 0.815549\n",
      "[40]\ttraining's auc: 0.857873\tvalid_0's auc: 0.810742\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.84408\tvalid_0's auc: 0.819624\n",
      "*****\n",
      "0.8196238102071076\n",
      "********************\n",
      "\n",
      "\n",
      "call_dur_max\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.860567\tvalid_0's auc: 0.800926\n",
      "[40]\ttraining's auc: 0.865413\tvalid_0's auc: 0.801453\n",
      "[60]\ttraining's auc: 0.867985\tvalid_0's auc: 0.803485\n",
      "[80]\ttraining's auc: 0.869533\tvalid_0's auc: 0.804841\n",
      "[100]\ttraining's auc: 0.870609\tvalid_0's auc: 0.805394\n",
      "[120]\ttraining's auc: 0.871461\tvalid_0's auc: 0.805375\n",
      "[140]\ttraining's auc: 0.872034\tvalid_0's auc: 0.805179\n",
      "[160]\ttraining's auc: 0.872612\tvalid_0's auc: 0.804976\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's auc: 0.871083\tvalid_0's auc: 0.805886\n",
      "*****\n",
      "0.8058858875017937\n",
      "********************\n",
      "\n",
      "\n",
      "call_dur_min\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.841844\tvalid_0's auc: 0.835699\n",
      "[40]\ttraining's auc: 0.842867\tvalid_0's auc: 0.834982\n",
      "[60]\ttraining's auc: 0.843829\tvalid_0's auc: 0.835109\n",
      "[80]\ttraining's auc: 0.844141\tvalid_0's auc: 0.834472\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.842635\tvalid_0's auc: 0.836465\n",
      "*****\n",
      "0.8364647606064954\n",
      "********************\n",
      "\n",
      "\n",
      "call_dur_std\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.854039\tvalid_0's auc: 0.796592\n",
      "[40]\ttraining's auc: 0.85758\tvalid_0's auc: 0.799379\n",
      "[60]\ttraining's auc: 0.859515\tvalid_0's auc: 0.799094\n",
      "[80]\ttraining's auc: 0.861115\tvalid_0's auc: 0.798308\n",
      "[100]\ttraining's auc: 0.861929\tvalid_0's auc: 0.797521\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's auc: 0.859992\tvalid_0's auc: 0.799508\n",
      "*****\n",
      "0.7995079399244273\n",
      "********************\n",
      "\n",
      "\n",
      "city_name_nunique\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.815802\tvalid_0's auc: 0.804855\n",
      "[40]\ttraining's auc: 0.815802\tvalid_0's auc: 0.804855\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's auc: 0.815802\tvalid_0's auc: 0.804855\n",
      "*****\n",
      "0.8048545343664801\n",
      "********************\n",
      "\n",
      "\n",
      "county_name_nunique\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.834119\tvalid_0's auc: 0.812679\n",
      "[40]\ttraining's auc: 0.834345\tvalid_0's auc: 0.811155\n",
      "[60]\ttraining's auc: 0.834473\tvalid_0's auc: 0.811957\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.83414\tvalid_0's auc: 0.812895\n",
      "*****\n",
      "0.8128946046778591\n",
      "********************\n",
      "\n",
      "\n",
      "calltype_id_unique\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.825684\tvalid_0's auc: 0.808216\n",
      "[40]\ttraining's auc: 0.825684\tvalid_0's auc: 0.808216\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.825684\tvalid_0's auc: 0.808216\n",
      "*****\n",
      "0.8082161477017267\n",
      "********************\n",
      "\n",
      "\n",
      "voc_hour_mode\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.846164\tvalid_0's auc: 0.822017\n",
      "[40]\ttraining's auc: 0.846345\tvalid_0's auc: 0.822926\n",
      "[60]\ttraining's auc: 0.846369\tvalid_0's auc: 0.823189\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's auc: 0.846121\tvalid_0's auc: 0.823404\n",
      "*****\n",
      "0.8234039436552351\n",
      "********************\n",
      "\n",
      "\n",
      "voc_hour_mode_count\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.872006\tvalid_0's auc: 0.854768\n",
      "[40]\ttraining's auc: 0.872411\tvalid_0's auc: 0.854685\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's auc: 0.871536\tvalid_0's auc: 0.855521\n",
      "*****\n",
      "0.855520878174774\n",
      "********************\n",
      "\n",
      "\n",
      "voc_hour_nunique\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.863728\tvalid_0's auc: 0.840329\n",
      "[40]\ttraining's auc: 0.86382\tvalid_0's auc: 0.840332\n",
      "[60]\ttraining's auc: 0.863851\tvalid_0's auc: 0.840332\n",
      "[80]\ttraining's auc: 0.863861\tvalid_0's auc: 0.840332\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.863789\tvalid_0's auc: 0.840332\n",
      "*****\n",
      "0.8403315875065768\n",
      "********************\n",
      "\n",
      "\n",
      "voc_day_mode\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.83638\tvalid_0's auc: 0.817896\n",
      "[40]\ttraining's auc: 0.836382\tvalid_0's auc: 0.81773\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.836324\tvalid_0's auc: 0.818742\n",
      "*****\n",
      "0.8187419285406802\n",
      "********************\n",
      "\n",
      "\n",
      "voc_day_mode_count\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.90221\tvalid_0's auc: 0.887091\n",
      "[40]\ttraining's auc: 0.90292\tvalid_0's auc: 0.886311\n",
      "[60]\ttraining's auc: 0.90333\tvalid_0's auc: 0.885266\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.902129\tvalid_0's auc: 0.887739\n",
      "*****\n",
      "0.8877394532931554\n",
      "********************\n",
      "\n",
      "\n",
      "voc_day_nunique\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.873946\tvalid_0's auc: 0.859906\n",
      "[40]\ttraining's auc: 0.873954\tvalid_0's auc: 0.858926\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's auc: 0.873703\tvalid_0's auc: 0.860168\n",
      "*****\n",
      "0.8601679461424403\n",
      "********************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "useful_cols = []\n",
    "useless_cols = []\n",
    "\n",
    "for i in train_cols:\n",
    "    print(i)\n",
    "    lgb_train = lgb.Dataset(X_train[[i]].values, y_train) \n",
    "    lgb_eval= lgb.Dataset(X_valid[[i]].values, y_valid, reference=lgb_train)\n",
    "    lgb_test = lgb.train(params,\n",
    "                         lgb_train,\n",
    "                         num_boost_round=1000,\n",
    "                         valid_sets=[lgb_eval, lgb_train],\n",
    "                         early_stopping_rounds=50,\n",
    "                         verbose_eval=20)\n",
    "    \n",
    "    print('*' * 5)\n",
    "    print(lgb_test.best_score['valid_0']['auc'])\n",
    "    if lgb_test.best_score['valid_0']['auc'] > 0.50:\n",
    "        useful_cols.append(i)\n",
    "    else:\n",
    "        useless_cols.append(i)\n",
    "    print('*' * 20)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:41.284896Z",
     "start_time": "2020-06-17T08:43:41.278912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['opposite_cnt', 'opposite_nunique', 'voc_calltype_id_1_cnt', 'imeis', 'voc_calltype_id_1_call_dur_sum', 'voc_calltype_id_1_30s_cnt', 'voc_calltype_id_1_60s_cnt', 'voc_calltype_id_1_300s_cnt', 'voc_calltype_id_1_30s_rate', 'voc_calltype_id_1_60s_rate', 'voc_calltype_id_1_300s_rate', 'call_type_id_1_rate', 'city_name_call', 'county_name_call', 'phone2opposite_cnt_mean', 'phone2opposite_cnt_median', 'phone2opposite_cnt_min', 'phone2opposite_cnt_max', 'phone2opposite_cnt_std', 'phone2opposite_call_dur_mean', 'phone2opposite_call_dur_median', 'phone2opposite_call_dur_min', 'phone2opposite_call_dur_max', 'phone2opposite_call_dur_std', 'call_dur_mean', 'call_dur_median', 'call_dur_max', 'call_dur_min', 'call_dur_std', 'city_name_nunique', 'county_name_nunique', 'calltype_id_unique', 'voc_hour_mode', 'voc_hour_mode_count', 'voc_hour_nunique', 'voc_day_mode', 'voc_day_mode_count', 'voc_day_nunique']\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(useful_cols)\n",
    "print(len(useful_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:41.300870Z",
     "start_time": "2020-06-17T08:43:41.287397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(useless_cols)\n",
    "print(len(useless_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:42.181534Z",
     "start_time": "2020-06-17T08:43:41.303863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.966572\tvalid_0's auc: 0.920698\n",
      "[20]\ttraining's auc: 0.976932\tvalid_0's auc: 0.919152\n",
      "[30]\ttraining's auc: 0.983382\tvalid_0's auc: 0.920974\n",
      "[40]\ttraining's auc: 0.98606\tvalid_0's auc: 0.919749\n",
      "[50]\ttraining's auc: 0.987515\tvalid_0's auc: 0.917118\n",
      "[60]\ttraining's auc: 0.988128\tvalid_0's auc: 0.915791\n",
      "[70]\ttraining's auc: 0.988405\tvalid_0's auc: 0.914194\n",
      "[80]\ttraining's auc: 0.988534\tvalid_0's auc: 0.912174\n",
      "[90]\ttraining's auc: 0.988673\tvalid_0's auc: 0.910954\n",
      "[100]\ttraining's auc: 0.988734\tvalid_0's auc: 0.910054\n",
      "[110]\ttraining's auc: 0.988766\tvalid_0's auc: 0.909764\n",
      "[120]\ttraining's auc: 0.988809\tvalid_0's auc: 0.909148\n",
      "[130]\ttraining's auc: 0.988867\tvalid_0's auc: 0.908787\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's auc: 0.984624\tvalid_0's auc: 0.92203\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train[useful_cols].values, y_train) \n",
    "\n",
    "lgb_eval= lgb.Dataset(X_valid[useful_cols].values, y_valid, reference=lgb_train)  \n",
    "\n",
    "print('Start training...')\n",
    "\n",
    "lgb_valid = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      num_boost_round=10000,\n",
    "                      valid_sets=[lgb_eval, lgb_train],\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:42.218436Z",
     "start_time": "2020-06-17T08:43:42.184526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_05:  0.846\n",
      "auc_05:  0.9220297029702971\n"
     ]
    }
   ],
   "source": [
    "# 验证集结果\n",
    "X_valid['prob'] = lgb_valid.predict(X_valid[useful_cols])\n",
    "X_valid['pred'] = np.where(X_valid['prob'] > 0.5, 1, 0)\n",
    "\n",
    "f1_05 = np.round(f1_score(y_valid, X_valid['pred']), 4)\n",
    "auc_05 = roc_auc_score(y_valid, X_valid['prob'])\n",
    "\n",
    "print('f1_05: ', f1_05)\n",
    "print('auc_05: ', auc_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:42.595427Z",
     "start_time": "2020-06-17T08:43:42.221431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "lgb_train_all = lgb.Dataset(df_voc_train[useful_cols].values, df_voc_train['label'])   \n",
    "\n",
    "print('Start training...')\n",
    "\n",
    "lgb_train = lgb.train(params,\n",
    "                      lgb_train_all,\n",
    "                      num_boost_round=lgb_valid.best_iteration + 20,\n",
    "                      verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T08:43:42.655268Z",
     "start_time": "2020-06-17T08:43:42.598420Z"
    }
   },
   "outputs": [],
   "source": [
    "df_voc_test['label'] = np.where(lgb_train.predict(df_voc_test[useful_cols]) > 0.5, 1, 0)\n",
    "df_voc_test[['phone_no_m', 'label']].to_csv('../sub/sub_{}_{}.csv'.format(time.strftime('%Y%m%d'), f1_05), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
