{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T15:28:55.085245Z",
     "start_time": "2020-08-18T15:28:52.775029Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T15:28:55.219115Z",
     "start_time": "2020-08-18T15:28:55.088190Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '../../input/Round1/'\n",
    "\n",
    "train_user_reply_data = pd.read_csv(data_path + 'train_user_reply_data.csv', encoding='utf-8')\n",
    "train_search_data = pd.read_csv(data_path + 'train_search_data.csv', encoding='utf-8')\n",
    "train_sales_data = pd.read_csv(data_path + 'train_sales_data.csv', encoding='utf-8')\n",
    "evaluation_public = pd.read_csv(data_path + 'evaluation_public.csv', encoding='utf-8')\n",
    "\n",
    "train_sales_data = train_sales_data.merge(train_search_data, on=['province', 'adcode', 'model', 'regYear', 'regMonth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 固定车型和省份顺序-样本顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T15:28:55.231110Z",
     "start_time": "2020-08-18T15:28:55.222114Z"
    }
   },
   "outputs": [],
   "source": [
    "cars = ['f8a6975573af1b33', '2a2ab41f8f6ff1cb', 'd4efbebb087fd03f', '3e21824be728cbec',\n",
    "        'ea489c253676aafc', '6155b214590c66e6', 'fc32b1a017b34efe', '9c1c7ee8ebdda299',\n",
    "        'fde95ea242abd896', '7a7885e2d7c00bcf', '7245e0ee27b195cd', 'b25c4e2e3856af22',\n",
    "        '7aab7fca2470987e', 'feabbf46658382b9', '04e66e578f653ab9', '5d7fb682edd0f937',\n",
    "        'b4be3a4917289c82', '54fc07138d70374c', 'ef76a85c4b39f693', 'bb9fbec9a2833839',\n",
    "        '3c974920a76ac9c1', '212083a9246d2fd3', '4f79773e600518a6', 'af6f4f548684e14d',\n",
    "        '936168bd4850913d', 'cd5841d44fd7625e', '0797526c057dcf5b', 'a207df29ec9583f0',\n",
    "        '3d7554f1f56dd664', '7023efdab9cedc03', 'da457d15788fe8ee', '12f8b7e14947c34d',\n",
    "        '28e29f2c03dcd84c', '63065128401bb3ff', 'a432c483b5beb856', '37aa9169b575ef79',\n",
    "        '17bc272c93f19d56', '61e73e32ad101892', '4a103c30d593fbbe', '2d0d2c3403909fdb',\n",
    "        '6858d6dfe680bdf7', '17363f08d683d52b', '346393c2c6305fb1', '5b1c11c3efed5312',\n",
    "        '97f15de12cfabbd5', 'a9a43d1a7ecbe75d', '7cf283430b3b5e38', 'c6833cb891626c17',\n",
    "        'a28bb927b6fcb33c', 'dff803b4024d261d', '02aab221aabc03b9', 'f5d69960089c3614',\n",
    "        '06880909932890ca', '79de4e4b24c35b04', 'd0f245b8781e3631', 'c06a2a387c0ee510',\n",
    "        'cc21c7e91a3b5a0c', 'f270f6a489c6a9d7', '8c915fe4632fb9fa', 'c6cd4e0e073f5ac2']\n",
    "provinces = ['浙江', '福建', '四川', '陕西', '安徽', '湖南', '广东', '云南', '上海', '山东',\n",
    "             '湖北', '黑龙江', '江苏', '广西', '内蒙古', '辽宁', '北京', '重庆', '河北', '山西',\n",
    "             '江西', '河南']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T15:28:55.244100Z",
     "start_time": "2020-08-18T15:28:55.235106Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred, model):\n",
    "    data = pd.DataFrame({'model': model, 'salesVolume': y_true, 'label': y_pred})\n",
    "    data['label'] = data['label'].map(lambda index: -index if index < 0 else index)\n",
    "    res, count = 0, 0\n",
    "    for index, cars in data.groupby('model'):\n",
    "        a = np.array(cars['salesVolume'])\n",
    "        b = np.array(cars['label'])\n",
    "        temp = np.sqrt(np.sum((a - b) ** 2) / len(a)) / np.mean(a)\n",
    "        res += temp\n",
    "        count += 1\n",
    "        print(temp)\n",
    "    return 1 - (res / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取训练/测试数据索引下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T15:28:55.261090Z",
     "start_time": "2020-08-18T15:28:55.248099Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_feature(windows_size, before):\n",
    "    features = pd.DataFrame()\n",
    "    for car in cars:\n",
    "        for province in provinces:\n",
    "            car_province_part = train_sales_data[(train_sales_data['model'] == car) & (train_sales_data['province'] == province)]\n",
    "            car_province_part['label'] = car_province_part['salesVolume'].shift(-windows_size)\n",
    "            car_province_part = car_province_part[before: 24-windows_size]\n",
    "            features = pd.concat([features, car_province_part], axis=0)\n",
    "    features.index = range(len(features))\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_test_feature(windows_size, before):\n",
    "    features = pd.DataFrame()\n",
    "    for car in cars:\n",
    "        for province in provinces:\n",
    "            car_province_part = train_sales_data[(train_sales_data['model'] == car) & (train_sales_data['province'] == province)]\n",
    "            car_province_part['label'] = car_province_part['salesVolume'].shift(-windows_size)\n",
    "            car_province_part = car_province_part[-1:]\n",
    "            features = pd.concat([features, car_province_part], axis=0)\n",
    "    features.index = range(len(features))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T15:28:55.297070Z",
     "start_time": "2020-08-18T15:28:55.264090Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_basic_feature(windows_size, before, data_set_name):\n",
    "    features = pd.DataFrame()\n",
    "    for car in cars:\n",
    "        for province in provinces:\n",
    "            car_province_part = train_sales_data[(train_sales_data['model'] == car) & (train_sales_data['province'] == province)].copy()\n",
    "            car_province_part['popularity'] = car_province_part['popularity'].apply(lambda index: np.log(index))     ###\n",
    "            car_province_part['salesVolume'] = car_province_part['salesVolume'].apply(lambda index: np.log(index))   ###\n",
    "            \n",
    "            # 春节标记特征\n",
    "            car_province_part['is_pring_festival'] = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "            car_province_part['distance_spring_festival'] = [1, 0, 1, 2, 3, 4, 5, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 6, 5, 4, 3, 2]\n",
    "            \n",
    "            # 一阶差分\n",
    "            for index in range(1, before, 1):\n",
    "                car_province_part['salesVolume_' + str(index)] = car_province_part['salesVolume'].shift(index)\n",
    "                car_province_part['salesVolume_diff_' + str(index)] = car_province_part['salesVolume'].diff(index)\n",
    "                car_province_part['salesVolume_qoq_' + str(index)] = (car_province_part['salesVolume']\n",
    "                                                                      / car_province_part['salesVolume_' + str(index)])\n",
    "\n",
    "                car_province_part['popularity_' + str(index)] = car_province_part['popularity'].shift(index)\n",
    "                car_province_part['popularity_diff_' + str(index)] = car_province_part['popularity'].diff(index)\n",
    "                car_province_part['popularity_hb_' + str(index)] = (car_province_part['popularity']\n",
    "                                                                    / car_province_part['popularity_' + str(index)])\n",
    "\n",
    "            # 二阶差分\n",
    "            for index in range(1, before - 1, 1):   \n",
    "                car_province_part['salesVolume_diff2_{}'.format(str(index))] = car_province_part['salesVolume_diff_' + str(index)].diff(1)\n",
    "\n",
    "            # 历史统计特征\n",
    "            salesVolume = list(car_province_part['salesVolume'])\n",
    "            popularity = list(car_province_part['popularity'])\n",
    "            car_province_part['index'] = 1\n",
    "            car_province_part['index'] = car_province_part['index'].cumsum()\n",
    "            car_province_part['salesVolume_his'] = car_province_part['index'].map(lambda index: salesVolume[index - 7: index])\n",
    "            car_province_part['popularity_his'] = car_province_part['index'].map(lambda index: popularity[index - 7: index])\n",
    "\n",
    "            car_province_part['salesVolume_his_diff'] = car_province_part['salesVolume_his'].map(lambda index: np.diff(index))\n",
    "            car_province_part['popularity_his_diff'] = car_province_part['popularity_his'].map(lambda index: np.diff(index))\n",
    "\n",
    "            def pth(array):\n",
    "                return np.max(array) - np.min(array)\n",
    "\n",
    "            fea_name = ['max', 'min', 'aver', 'var', 'pth']\n",
    "            fun_name = [np.max, np.min, np.average, np.var, pth]\n",
    "            for i in range(len(fun_name)):\n",
    "                car_province_part['salesVolume_his_' + fea_name[i]] = car_province_part['salesVolume_his'].apply(lambda index: 0 if len(index) == 0 else fun_name[i](index))                \n",
    "                car_province_part['salesVolume_his_diff_' + fea_name[i]] = car_province_part['salesVolume_his_diff'].apply(lambda index: 0 if len(index) == 0 else fun_name[i](index))\n",
    "            \n",
    "            car_province_part.drop(['index', 'salesVolume_his', 'popularity_his', 'salesVolume_his_diff', 'popularity_his_diff'], axis=1, inplace=True)\n",
    "            \n",
    "            # 数据集划分\n",
    "            if data_set_name == 'train':\n",
    "                car_province_part = car_province_part[before: 24-windows_size]\n",
    "            else:\n",
    "                car_province_part = car_province_part[-1:]\n",
    "\n",
    "            car_province_part.drop(['popularity'], axis=1, inplace=True)    ###  , 'day_count', 'day_salesVolume', 'popularity'\n",
    "            features = pd.concat([features, car_province_part], axis=0, ignore_index=True)\n",
    "\n",
    "    print(features.columns)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T15:28:55.306064Z",
     "start_time": "2020-08-18T15:28:55.301068Z"
    }
   },
   "outputs": [],
   "source": [
    "test_prob_collection = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 一月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T15:32:31.902664Z",
     "start_time": "2020-08-18T15:28:55.313061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['province', 'adcode', 'model', 'bodyType', 'regYear', 'regMonth',\n",
      "       'salesVolume', 'is_pring_festival', 'distance_spring_festival',\n",
      "       'salesVolume_1', 'salesVolume_diff_1', 'salesVolume_qoq_1',\n",
      "       'popularity_1', 'popularity_diff_1', 'popularity_hb_1', 'salesVolume_2',\n",
      "       'salesVolume_diff_2', 'salesVolume_qoq_2', 'popularity_2',\n",
      "       'popularity_diff_2', 'popularity_hb_2', 'salesVolume_3',\n",
      "       'salesVolume_diff_3', 'salesVolume_qoq_3', 'popularity_3',\n",
      "       'popularity_diff_3', 'popularity_hb_3', 'salesVolume_4',\n",
      "       'salesVolume_diff_4', 'salesVolume_qoq_4', 'popularity_4',\n",
      "       'popularity_diff_4', 'popularity_hb_4', 'salesVolume_5',\n",
      "       'salesVolume_diff_5', 'salesVolume_qoq_5', 'popularity_5',\n",
      "       'popularity_diff_5', 'popularity_hb_5', 'salesVolume_6',\n",
      "       'salesVolume_diff_6', 'salesVolume_qoq_6', 'popularity_6',\n",
      "       'popularity_diff_6', 'popularity_hb_6', 'salesVolume_7',\n",
      "       'salesVolume_diff_7', 'salesVolume_qoq_7', 'popularity_7',\n",
      "       'popularity_diff_7', 'popularity_hb_7', 'salesVolume_8',\n",
      "       'salesVolume_diff_8', 'salesVolume_qoq_8', 'popularity_8',\n",
      "       'popularity_diff_8', 'popularity_hb_8', 'salesVolume_9',\n",
      "       'salesVolume_diff_9', 'salesVolume_qoq_9', 'popularity_9',\n",
      "       'popularity_diff_9', 'popularity_hb_9', 'salesVolume_diff2_1',\n",
      "       'salesVolume_diff2_2', 'salesVolume_diff2_3', 'salesVolume_diff2_4',\n",
      "       'salesVolume_diff2_5', 'salesVolume_diff2_6', 'salesVolume_diff2_7',\n",
      "       'salesVolume_diff2_8', 'salesVolume_his_max',\n",
      "       'salesVolume_his_diff_max', 'salesVolume_his_min',\n",
      "       'salesVolume_his_diff_min', 'salesVolume_his_aver',\n",
      "       'salesVolume_his_diff_aver', 'salesVolume_his_var',\n",
      "       'salesVolume_his_diff_var', 'salesVolume_his_pth',\n",
      "       'salesVolume_his_diff_pth'],\n",
      "      dtype='object')\n",
      "Index(['province', 'adcode', 'model', 'bodyType', 'regYear', 'regMonth',\n",
      "       'salesVolume', 'is_pring_festival', 'distance_spring_festival',\n",
      "       'salesVolume_1', 'salesVolume_diff_1', 'salesVolume_qoq_1',\n",
      "       'popularity_1', 'popularity_diff_1', 'popularity_hb_1', 'salesVolume_2',\n",
      "       'salesVolume_diff_2', 'salesVolume_qoq_2', 'popularity_2',\n",
      "       'popularity_diff_2', 'popularity_hb_2', 'salesVolume_3',\n",
      "       'salesVolume_diff_3', 'salesVolume_qoq_3', 'popularity_3',\n",
      "       'popularity_diff_3', 'popularity_hb_3', 'salesVolume_4',\n",
      "       'salesVolume_diff_4', 'salesVolume_qoq_4', 'popularity_4',\n",
      "       'popularity_diff_4', 'popularity_hb_4', 'salesVolume_5',\n",
      "       'salesVolume_diff_5', 'salesVolume_qoq_5', 'popularity_5',\n",
      "       'popularity_diff_5', 'popularity_hb_5', 'salesVolume_6',\n",
      "       'salesVolume_diff_6', 'salesVolume_qoq_6', 'popularity_6',\n",
      "       'popularity_diff_6', 'popularity_hb_6', 'salesVolume_7',\n",
      "       'salesVolume_diff_7', 'salesVolume_qoq_7', 'popularity_7',\n",
      "       'popularity_diff_7', 'popularity_hb_7', 'salesVolume_8',\n",
      "       'salesVolume_diff_8', 'salesVolume_qoq_8', 'popularity_8',\n",
      "       'popularity_diff_8', 'popularity_hb_8', 'salesVolume_9',\n",
      "       'salesVolume_diff_9', 'salesVolume_qoq_9', 'popularity_9',\n",
      "       'popularity_diff_9', 'popularity_hb_9', 'salesVolume_diff2_1',\n",
      "       'salesVolume_diff2_2', 'salesVolume_diff2_3', 'salesVolume_diff2_4',\n",
      "       'salesVolume_diff2_5', 'salesVolume_diff2_6', 'salesVolume_diff2_7',\n",
      "       'salesVolume_diff2_8', 'salesVolume_his_max',\n",
      "       'salesVolume_his_diff_max', 'salesVolume_his_min',\n",
      "       'salesVolume_his_diff_min', 'salesVolume_his_aver',\n",
      "       'salesVolume_his_diff_aver', 'salesVolume_his_var',\n",
      "       'salesVolume_his_diff_var', 'salesVolume_his_pth',\n",
      "       'salesVolume_his_diff_pth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "size, pre = 1, 10  # 4\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "categorial_name = [0, 1, 2, 3, 4, 6, 7]\n",
    "drop_cols = ['salesVolume', 'popularity']\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 1\n",
    "###############################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 11)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T15:32:55.057747Z",
     "start_time": "2020-08-18T15:32:31.902664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.504982\n",
      "[200]\tvalid_0's rmse: 0.477841\n",
      "[300]\tvalid_0's rmse: 0.467237\n",
      "[400]\tvalid_0's rmse: 0.462656\n",
      "[500]\tvalid_0's rmse: 0.459201\n",
      "[600]\tvalid_0's rmse: 0.457963\n",
      "[700]\tvalid_0's rmse: 0.457999\n",
      "Early stopping, best iteration is:\n",
      "[636]\tvalid_0's rmse: 0.45705\n",
      "importance:\n",
      " [1276 2810   82  164 1650  664  206  157  191  129  138   68  199  172\n",
      "  203  269  233   74  143  153  122  215  151   49   82  110  118  125\n",
      "  150   58  104   80  140  134  131   63   99   98  142  149  141   48\n",
      "  118   96  134  157  167   50  101   99  186  146  147   76  102   85\n",
      "  313  246  170   63  100   97  219  285  231  298  243  220  158  260\n",
      "   85  184  127   95  237   34  172  127  160  143]\n",
      "0.235664444383198\n",
      "0.2639890713606915\n",
      "0.3146114751514538\n",
      "0.20079176350543748\n",
      "0.3653391928575023\n",
      "0.8147338099487671\n",
      "0.2289502493130332\n",
      "0.1838861452194883\n",
      "0.1919407442466147\n",
      "0.15769741247671323\n",
      "0.32897853943959576\n",
      "0.21132295023313058\n",
      "0.11076351612083812\n",
      "0.23377895135917043\n",
      "0.22591865378874315\n",
      "0.30857059317318536\n",
      "0.1140949732527063\n",
      "0.16362335439951958\n",
      "0.13444826175348848\n",
      "0.3450380333995316\n",
      "0.2061555182936783\n",
      "0.24005495683482417\n",
      "0.10661458387994648\n",
      "0.3116174142269199\n",
      "0.11792326567692105\n",
      "0.4422901597090634\n",
      "0.3039270514826982\n",
      "0.3168709697428295\n",
      "0.17405706732798948\n",
      "0.3499579174340662\n",
      "0.37140867656977244\n",
      "0.25055681122771195\n",
      "0.18430615794594246\n",
      "0.12926472780110246\n",
      "0.7827337944393014\n",
      "0.21460281413453708\n",
      "0.11490109395722349\n",
      "0.36137097333525514\n",
      "0.15701799391239216\n",
      "0.15147494953884655\n",
      "1.0461093092641303\n",
      "0.3518451053474527\n",
      "0.10169862502143034\n",
      "0.32256782961156855\n",
      "0.3560722934944002\n",
      "0.9513733349548299\n",
      "0.2750524148698886\n",
      "0.12407046904648082\n",
      "0.8255419037671777\n",
      "0.2846419284325196\n",
      "0.1667339130230932\n",
      "0.16538327048692222\n",
      "0.5383796912201192\n",
      "0.24298373898371878\n",
      "0.2365393928984854\n",
      "0.9363286844067059\n",
      "0.0912766899766409\n",
      "0.2799993100105596\n",
      "0.24186450325009137\n",
      "0.24673216721212138\n",
      "predict:\n",
      " [856.81785681 445.93041706 657.34449898 ... 140.69711785 278.33409934\n",
      " 977.37245736]\n",
      "model train over, rmse: 0.6965592731977972\n",
      "train_feature.shape:  (17160, 80)\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'rmse',\n",
    "    'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 2 ** 5 - 1,    # 2 ** 5 - 1\n",
    "    # 'min_child_samples': 100,\n",
    "    'max_depth': 6,    # 6\n",
    "    'subsample': 0.8,   # 0.8\n",
    "    'subsample_freq': 5,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 2020,\n",
    "    'nthread': -1,\n",
    "    'verbose': 1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# num_boost_round: 5000   early_stopping_rounds:100\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "# feature importance\n",
    "importance = module.feature_importance()\n",
    "print('importance:\\n', importance)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params,\n",
    "                  lgb_data,\n",
    "                  num_boost_round=iters,\n",
    "                  categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "print('predict:\\n', predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)   \n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)\n",
    "print('train_feature.shape: ', train_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 二月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.185Z"
    }
   },
   "outputs": [],
   "source": [
    "size, pre = 2, 9  # 4\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 2\n",
    "######################################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 10)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.189Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "      'boosting_type': 'gbdt',\n",
    "      'objective': 'rmse',\n",
    "      'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "      'learning_rate': 0.03,\n",
    "      'num_leaves': 2 ** 5 - 1,\n",
    "      # 'min_child_samples': 100,\n",
    "      'max_depth': 6,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 5,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'seed': 2020,\n",
    "      'nthread': -1,\n",
    "      'verbose': 1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# categorial_name = ['adcode', 'model', 'bodyType', 'regYear', 'regMonth']\n",
    "\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params, lgb_data, num_boost_round=iters, categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "print('predict: \\n', predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)   \n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 三月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.242Z"
    }
   },
   "outputs": [],
   "source": [
    "size, pre = 3, 8   # 5\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 3\n",
    "##############################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 9)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.246Z"
    }
   },
   "outputs": [],
   "source": [
    "# LightGBM model\n",
    "params = {\n",
    "      'boosting_type': 'gbdt',\n",
    "      'objective': 'rmse',\n",
    "      'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "      'learning_rate': 0.03,\n",
    "      'num_leaves': 2 ** 5 - 1,\n",
    "      # 'min_child_samples': 100,\n",
    "      'max_depth': 6,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 5,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'seed': 2020,\n",
    "      'nthread': -1,\n",
    "      'verbose': 1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# categorial_name = ['adcode', 'model', 'bodyType', 'regYear', 'regMonth']\n",
    "\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params, lgb_data, num_boost_round=iters, categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "print('predict:\\n', predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)\n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 四月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.336Z"
    }
   },
   "outputs": [],
   "source": [
    "size, pre = 4, 7   # 5\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 4\n",
    "###############################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 8)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.341Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "      'boosting_type': 'gbdt',\n",
    "      'objective': 'rmse',\n",
    "      'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "      'learning_rate': 0.03,\n",
    "      'num_leaves': 2 ** 5 - 1,\n",
    "      # 'min_child_samples': 100,\n",
    "      'max_depth': 6,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 5,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'seed': 2020,\n",
    "      'nthread': -1,\n",
    "      'verbose': 1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# categorial_name = ['adcode', 'model', 'bodyType', 'regYear', 'regMonth']\n",
    "\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params, lgb_data, num_boost_round=iters, categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "print(predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)\n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.345Z"
    }
   },
   "outputs": [],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.349Z"
    }
   },
   "outputs": [],
   "source": [
    "test_prob_collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.354Z"
    }
   },
   "outputs": [],
   "source": [
    "test_prob_collection.index = range(len(test_prob_collection))\n",
    "evaluation_public = evaluation_public.merge(test_prob_collection, on=['province', 'adcode', 'model', 'regYear', 'regMonth'], how='left')\n",
    "evaluation_public['forecastVolum'] = evaluation_public['forecastVolum_y']\n",
    "evaluation_public['forecastVolum'] = evaluation_public['forecastVolum'].apply(lambda index: int(np.round(index)))\n",
    "evaluation_public['forecastVolum'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.359Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation_public[['id', 'forecastVolum']].to_csv('./submit/sub_method_one.csv', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T15:28:53.364Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation_public.describe()\n",
    "evaluation_public.groupby(['regMonth'], as_index=False)['forecastVolum'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
