{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data63881\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting lightgbm==2.3.1\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 14.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn (from lightgbm==2.3.1)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8MB 14.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy (from lightgbm==2.3.1)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/dc/7e/8f6a79b102ca1ea928bae8998b05bf5dc24a90571db13cd119f275ba6252/scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9MB 11.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy (from lightgbm==2.3.1)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/a5/bb/87d668b353848b93baab0a64cddf6408c40717f099539668c3d26fe39f7e/numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5MB 8.6MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting joblib>=0.11 (from scikit-learn->lightgbm==2.3.1)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 18.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn->lightgbm==2.3.1)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Installing collected packages: numpy, scipy, joblib, threadpoolctl, scikit-learn, lightgbm\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "# !pip install beautifulsoup4 -t /home/aistudio/external-libraries\n",
    "!pip install lightgbm==2.3.1 -t /home/aistudio/external-libraries\n",
    "# !pip install catboost==0.23 -t /home/aistudio/external-libraries\n",
    "# !pip install jieba -t /home/aistudio/external-libraries\n",
    "# !pip install gensim -t /home/aistudio/external-libraries\n",
    "!pip uninstall --yes pandas\n",
    "!pip install pandas==1.0.5 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "import lightgbm as lgb\r\n",
    "import gc\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "pd.set_option('max_columns', None)\r\n",
    "pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('data/data63881/train_transaction.csv')\r\n",
    "test_transaction = pd.read_csv('data/data63881/test_transaction.csv')\r\n",
    "train_identity = pd.read_csv('data/data63881/train_identity.csv')\r\n",
    "test_identity = pd.read_csv('data/data63881/test_identity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train_transaction.merge(train_identity, on='TransactionID', how='left')\r\n",
    "test = test_transaction.merge(test_identity, on='TransactionID', how='left')\r\n",
    "data = pd.concat([train, test], axis=0, ignore_index=True)\r\n",
    "del train, test\r\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "object_cols = ['ProductCD', 'card4', 'card6', 'DeviceType', 'DeviceInfo', 'P_emaildomain', 'R_emaildomain']\r\n",
    "M_cols = ['M{}'.format(i) for i in range(1, 10)]\r\n",
    "id_cols = ['id_12', 'id_16', 'id_27', 'id_28', 'id_29', 'id_35', 'id_36', 'id_37', 'id_38', 'id_15',\r\n",
    "           'id_23', 'id_34', 'id_30', 'id_31', 'id_33']\r\n",
    "cat_cols = object_cols + M_cols + id_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in cat_cols:\r\n",
    "    le = LabelEncoder()\r\n",
    "    data[i] = le.fit_transform(data[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data[data['isFraud'].notnull()]\r\n",
    "test = data[data['isFraud'].isnull()]\r\n",
    "\r\n",
    "y = train['isFraud']\r\n",
    "train.drop(['isFraud', 'TransactionID'], axis=1, inplace=True)\r\n",
    "test.drop(['isFraud', 'TransactionID'], axis=1, inplace=True)\r\n",
    "used_cols = train.columns\r\n",
    "test = test[used_cols]\r\n",
    "\r\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train, y, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def auc_select(X_train, y_train, X_valid, y_valid, cols, threshold=0.52):\r\n",
    "    useful_dict = dict()\r\n",
    "    useless_dict = dict()\r\n",
    "    params = {\r\n",
    "        'objective': 'binary',\r\n",
    "        'boosting': 'gbdt',\r\n",
    "        'metric': 'auc',\r\n",
    "        'learning_rate': 0.1,\r\n",
    "        'num_leaves': 31,\r\n",
    "        'lambda_l1': 0,\r\n",
    "        'lambda_l2': 1,\r\n",
    "        'num_threads': 23,\r\n",
    "        'min_data_in_leaf': 20,\r\n",
    "        'first_metric_only': True,\r\n",
    "        'is_unbalance': True,\r\n",
    "        'max_depth': -1,\r\n",
    "        'seed': 2020\r\n",
    "    }\r\n",
    "    for i in cols:\r\n",
    "        print(i)\r\n",
    "        try:\r\n",
    "            lgb_train = lgb.Dataset(X_train[[i]].values, y_train)\r\n",
    "            lgb_valid = lgb.Dataset(X_valid[[i]].values, y_valid, reference=lgb_train)\r\n",
    "            lgb_model = lgb.train(\r\n",
    "                params,\r\n",
    "                lgb_train,\r\n",
    "                valid_sets=[lgb_valid, lgb_train],\r\n",
    "                num_boost_round=1000,\r\n",
    "                early_stopping_rounds=50,\r\n",
    "                verbose_eval=500\r\n",
    "            )\r\n",
    "            print('*' * 10)\r\n",
    "            print(lgb_model.best_score['valid_0']['auc'])\r\n",
    "            if lgb_model.best_score['valid_0']['auc'] > threshold:\r\n",
    "                useful_dict[i] = lgb_model.best_score['valid_0']['auc']\r\n",
    "            else:\r\n",
    "                useless_dict[i] = lgb_model.best_score['valid_0']['auc']\r\n",
    "        except:\r\n",
    "            print('Error: ', i)\r\n",
    "    useful_cols = list(useful_dict.keys())\r\n",
    "    useless_cols = list(useless_dict.keys())\r\n",
    "    return useful_dict, useless_dict, useful_cols, useless_cols\r\n",
    "\r\n",
    "\r\n",
    "useful_dict, useless_dict, useful_cols, useless_cols = auc_select(X_train, y_train, X_valid, y_valid, used_cols, threshold=0.52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train[useful_cols]\r\n",
    "X_valid = X_valid[useful_cols]\r\n",
    "test = test[useful_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X_train, y_train)\r\n",
    "dvalid = lgb.Dataset(X_valid, y_valid, reference=dtrain)\r\n",
    "params = {\r\n",
    "    'objective': 'binary',\r\n",
    "    'boosting': 'gbdt',\r\n",
    "    'metric': 'auc',\r\n",
    "    # 'metric': 'None',  # 用自定义评估函数是将metric设置为'None'\r\n",
    "    'learning_rate': 0.1,\r\n",
    "    'num_leaves': 31,\r\n",
    "    'lambda_l1': 0,\r\n",
    "    'lambda_l2': 1,\r\n",
    "    'num_threads': 23,\r\n",
    "    'min_data_in_leaf': 20,\r\n",
    "    'first_metric_only': True,\r\n",
    "    'is_unbalance': True,\r\n",
    "    'max_depth': -1,\r\n",
    "    'seed': 2020\r\n",
    "}\r\n",
    "valid_model = lgb.train(\r\n",
    "    params,\r\n",
    "    dtrain,\r\n",
    "    valid_sets=[dtrain, dvalid],\r\n",
    "    num_boost_round=1000000,\r\n",
    "    early_stopping_rounds=200,\r\n",
    "    verbose_eval=300\r\n",
    ")\r\n",
    "pred = valid_model.predict(test)\r\n",
    "sub = pd.DataFrame({'id': range(len(test))})\r\n",
    "sub['isFraud'] = pred\r\n",
    "sub.to_csv('./sub/basline.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
