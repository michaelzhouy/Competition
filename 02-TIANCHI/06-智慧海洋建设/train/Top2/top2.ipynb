{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:04.480843Z",
     "start_time": "2020-11-09T01:39:03.301003Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pyproj import Proj\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:04.513684Z",
     "start_time": "2020-11-09T01:39:04.483764Z"
    }
   },
   "outputs": [],
   "source": [
    "def geohash_encode(latitude, longitude, precision=12):\n",
    "    \"\"\"\n",
    "    Encode a position given in float arguments latitude, longitude to\n",
    "    a geohash which will have the character count precision.\n",
    "    \"\"\"\n",
    "    lat_interval, lon_interval = (-90.0, 90.0), (-180.0, 180.0)\n",
    "    base32 = '0123456789bcdefghjkmnpqrstuvwxyz'\n",
    "    geohash = []\n",
    "    bits = [16, 8, 4, 2, 1]\n",
    "    bit = 0\n",
    "    ch = 0\n",
    "    even = True\n",
    "    while len(geohash) < precision:\n",
    "        if even:\n",
    "            mid = (lon_interval[0] + lon_interval[1]) / 2\n",
    "            if longitude > mid:\n",
    "                ch |= bits[bit]\n",
    "                lon_interval = (mid, lon_interval[1])\n",
    "            else:\n",
    "                lon_interval = (lon_interval[0], mid)\n",
    "        else:\n",
    "            mid = (lat_interval[0] + lat_interval[1]) / 2\n",
    "            if latitude > mid:\n",
    "                ch |= bits[bit]\n",
    "                lat_interval = (mid, lat_interval[1])\n",
    "            else:\n",
    "                lat_interval = (lat_interval[0], mid)\n",
    "        even = not even\n",
    "        if bit < 4:\n",
    "            bit += 1\n",
    "        else:\n",
    "            geohash += base32[ch]\n",
    "            bit = 0\n",
    "            ch = 0\n",
    "    return ''.join(geohash)\n",
    "\n",
    "\n",
    "def hashfxn(astring):\n",
    "    return ord(astring[0])\n",
    "\n",
    "\n",
    "def tfidf(input_values, output_num, output_prefix, seed=1024):\n",
    "    tfidf_enc = TfidfVectorizer()\n",
    "    tfidf_vec = tfidf_enc.fit_transform(input_values)\n",
    "    svd_tmp = TruncatedSVD(n_components=output_num, n_iter=20, random_state=seed)\n",
    "    svd_tmp = svd_tmp.fit_transform(tfidf_vec)\n",
    "    svd_tmp = pd.DataFrame(svd_tmp)\n",
    "    svd_tmp.columns = ['{}_tfidf_{}'.format(output_prefix, i) for i in range(output_num)]\n",
    "    return svd_tmp\n",
    "\n",
    "\n",
    "def count2vec(input_values, output_num, output_prefix, seed=1024):\n",
    "    count_enc = CountVectorizer()\n",
    "    count_vec = count_enc.fit_transform(input_values)\n",
    "    svd_tmp = TruncatedSVD(n_components=output_num, n_iter=20, random_state=seed)\n",
    "    svd_tmp = svd_tmp.fit_transform(count_vec)\n",
    "    svd_tmp = pd.DataFrame(svd_tmp)\n",
    "    svd_tmp.columns = ['{}_countvec_{}'.format(output_prefix, i) for i in range(output_num)]\n",
    "    return svd_tmp\n",
    "\n",
    "\n",
    "def get_geohash_tfidf(df, group_id, group_target, num):\n",
    "    # tfidf_df = get_geohash_tfidf(df, 'ID', 'lat_lon', 30)\n",
    "    df[group_target] = df.apply(lambda x: geohash_encode(x['lat'], x['lon'], 7), axis=1)\n",
    "    tmp = df.groupby(group_id)[group_target].agg(list).reset_index()\n",
    "    tmp[group_target] = tmp[group_target].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    tfidf_tmp = tfidf(tmp[group_target], num, group_target)\n",
    "    count_tmp = count2vec(tmp[group_target], num, group_target)\n",
    "    return pd.concat([tmp[[group_id]], tfidf_tmp, count_tmp], axis=1)\n",
    "\n",
    "\n",
    "def get_grad_tfidf(df, group_id, group_target, num):\n",
    "    # grad_tfidf = get_grad_tfidf(df, 'ID', 'grad', 30)\n",
    "    grad_df = df.groupby(group_id)['lat'].apply(lambda x: np.gradient(x)).reset_index()\n",
    "    grad_df['lon'] = df.groupby(group_id)['lon'].apply(lambda x: np.gradient(x))\n",
    "    grad_df['lat'] = grad_df['lat'].apply(lambda x: np.round(x, 4))\n",
    "    grad_df['lon'] = grad_df['lon'].apply(lambda x: np.round(x, 4))\n",
    "    # grad_df[group_target] = grad_df.apply(\n",
    "    #     lambda x: ' '.join(['{}_{}'.format(z[0], z[1]) for z in zip(x['lat'], x['lon'])]), axis=1)\n",
    "    grad_df[group_target] = grad_df.apply(lambda x: str(x['lat']) + ' ' + str(x['lon']), axis=1)\n",
    "\n",
    "    tfidf_tmp = tfidf(grad_df[group_target], num, group_target)\n",
    "    return pd.concat([grad_df[[group_id]], tfidf_tmp], axis=1)\n",
    "\n",
    "\n",
    "def get_sample_tfidf(df, group_id, group_target, num):\n",
    "    # sample_tfidf = get_sample_tfidf(df, 'ID', 'sample', 30)\n",
    "    tmp = df.groupby(group_id)['lat_lon'].apply(lambda x: x.sample(frac=0.1, random_state=1)).reset_index()\n",
    "    del tmp['level_1']\n",
    "    tmp.columns = [group_id, group_target]\n",
    "    tmp = tmp.groupby(group_id)[group_target].agg(list).reset_index()\n",
    "    tmp[group_target] = tmp[group_target].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    tfidf_tmp = tfidf(tmp[group_target], num, group_target)\n",
    "    return pd.concat([tmp[[group_id]], tfidf_tmp], axis=1)\n",
    "\n",
    "\n",
    "# workers设为1可复现训练好的词向量，但速度稍慢，若不考虑复现的话，可对此参数进行调整\n",
    "def w2v_feat(df, group_id, feat, length):\n",
    "    # w2v_df = w2v_feat(df, 'ID', 'lat_lon', 30)\n",
    "    print('start word2vec ...')\n",
    "    data_frame = df.groupby(group_id)[feat].agg(list).reset_index()\n",
    "    model = Word2Vec(data_frame[feat].values, size=length, window=5, min_count=1, sg=1, hs=1,\n",
    "                     workers=1, iter=10, seed=1, hashfxn=hashfxn)\n",
    "    data_frame[feat] = data_frame[feat].apply(lambda x: pd.DataFrame([model[c] for c in x]))\n",
    "    for m in range(length):\n",
    "        data_frame['w2v_{}_mean'.format(m)] = data_frame[feat].apply(lambda x: x[m].mean())\n",
    "    del data_frame[feat]\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def d2v_feat(df, group_id, feat, length):\n",
    "    print('start doc2vec ...')\n",
    "    data_frame = df.groupby(group_id)[feat].agg(list).reset_index()\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in zip(data_frame[group_id].values, data_frame[feat])]\n",
    "    model = Doc2Vec(documents, vector_size=length, window=5, min_count=1, workers=1, seed=1, hashfxn=hashfxn, \n",
    "                    epochs=10, sg=1, hs=1)\n",
    "    doc_df = data_frame[group_id].apply(lambda x: ','.join([str(i) for i in model[x]])).str.split(',', expand=True).apply(pd.to_numeric)\n",
    "    doc_df.columns = ['{}_d2v_{}'.format(feat, i) for i in range(length)]\n",
    "    return pd.concat([data_frame[[group_id]], doc_df], axis=1)\n",
    "\n",
    "\n",
    "def q10(x):\n",
    "    return x.quantile(0.1)\n",
    "\n",
    "\n",
    "def q20(x):\n",
    "    return x.quantile(0.2)\n",
    "\n",
    "\n",
    "def q30(x):\n",
    "    return x.quantile(0.3)\n",
    "\n",
    "\n",
    "def q40(x):\n",
    "    return x.quantile(0.4)\n",
    "\n",
    "\n",
    "def q60(x):\n",
    "    return x.quantile(0.6)\n",
    "\n",
    "\n",
    "def q70(x):\n",
    "    return x.quantile(0.7)\n",
    "\n",
    "\n",
    "def q80(x):\n",
    "    return x.quantile(0.8)\n",
    "\n",
    "\n",
    "def q90(x):\n",
    "    return x.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:09.173400Z",
     "start_time": "2020-11-09T01:39:04.514835Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../input/round2_train.csv')\n",
    "test = pd.read_csv('../../input/round2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:09.192283Z",
     "start_time": "2020-11-09T01:39:09.174290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>speed</th>\n",
       "      <th>direction</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.295</td>\n",
       "      <td>115.563</td>\n",
       "      <td>2.32</td>\n",
       "      <td>50</td>\n",
       "      <td>0912 23:59:55</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.289</td>\n",
       "      <td>115.557</td>\n",
       "      <td>3.29</td>\n",
       "      <td>30</td>\n",
       "      <td>0912 23:49:54</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.282</td>\n",
       "      <td>115.551</td>\n",
       "      <td>3.08</td>\n",
       "      <td>40</td>\n",
       "      <td>0912 23:39:26</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.274</td>\n",
       "      <td>115.547</td>\n",
       "      <td>3.51</td>\n",
       "      <td>20</td>\n",
       "      <td>0912 23:29:49</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.267</td>\n",
       "      <td>115.543</td>\n",
       "      <td>3.08</td>\n",
       "      <td>10</td>\n",
       "      <td>0912 23:19:48</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID     lat      lon  speed  direction           time type\n",
       "0  20000  21.295  115.563   2.32         50  0912 23:59:55   拖网\n",
       "1  20000  21.289  115.557   3.29         30  0912 23:49:54   拖网\n",
       "2  20000  21.282  115.551   3.08         40  0912 23:39:26   拖网\n",
       "3  20000  21.274  115.547   3.51         20  0912 23:29:49   拖网\n",
       "4  20000  21.267  115.543   3.08         10  0912 23:19:48   拖网"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:09.203215Z",
     "start_time": "2020-11-09T01:39:09.193241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>speed</th>\n",
       "      <th>direction</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>6.392512e+06</td>\n",
       "      <td>5.475100e+06</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>1120 23:47:31</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>6.392512e+06</td>\n",
       "      <td>5.475100e+06</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>1120 23:37:31</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>6.392512e+06</td>\n",
       "      <td>5.475100e+06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1120 23:27:31</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>6.392512e+06</td>\n",
       "      <td>5.475100e+06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1120 23:17:31</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>6.392512e+06</td>\n",
       "      <td>5.475100e+06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1120 23:07:31</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID           lat           lon  speed  direction           time     type\n",
       "0  10000  6.392512e+06  5.475100e+06   0.27          0  1120 23:47:31  unknown\n",
       "1  10000  6.392512e+06  5.475100e+06   0.27          0  1120 23:37:31  unknown\n",
       "2  10000  6.392512e+06  5.475100e+06   0.05          0  1120 23:27:31  unknown\n",
       "3  10000  6.392512e+06  5.475100e+06   0.05          0  1120 23:17:31  unknown\n",
       "4  10000  6.392512e+06  5.475100e+06   0.05          0  1120 23:07:31  unknown"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:09.469462Z",
     "start_time": "2020-11-09T01:39:09.204212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>speed</th>\n",
       "      <th>direction</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.295</td>\n",
       "      <td>115.563</td>\n",
       "      <td>2.32</td>\n",
       "      <td>50</td>\n",
       "      <td>0912 23:59:55</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.289</td>\n",
       "      <td>115.557</td>\n",
       "      <td>3.29</td>\n",
       "      <td>30</td>\n",
       "      <td>0912 23:49:54</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.282</td>\n",
       "      <td>115.551</td>\n",
       "      <td>3.08</td>\n",
       "      <td>40</td>\n",
       "      <td>0912 23:39:26</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.274</td>\n",
       "      <td>115.547</td>\n",
       "      <td>3.51</td>\n",
       "      <td>20</td>\n",
       "      <td>0912 23:29:49</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>21.267</td>\n",
       "      <td>115.543</td>\n",
       "      <td>3.08</td>\n",
       "      <td>10</td>\n",
       "      <td>0912 23:19:48</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID     lat      lon  speed  direction           time type\n",
       "0  20000  21.295  115.563   2.32         50  0912 23:59:55   拖网\n",
       "1  20000  21.289  115.557   3.29         30  0912 23:49:54   拖网\n",
       "2  20000  21.282  115.551   3.08         40  0912 23:39:26   拖网\n",
       "3  20000  21.274  115.547   3.51         20  0912 23:29:49   拖网\n",
       "4  20000  21.267  115.543   3.08         10  0912 23:19:48   拖网"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "del train, test\n",
    "gc.collect()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:19.413333Z",
     "start_time": "2020-11-09T01:39:09.471457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>speed</th>\n",
       "      <th>direction</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5291016</th>\n",
       "      <td>9000</td>\n",
       "      <td>6.265080e+06</td>\n",
       "      <td>5.251556e+06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>242</td>\n",
       "      <td>1028 00:01:38</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291015</th>\n",
       "      <td>9000</td>\n",
       "      <td>6.265080e+06</td>\n",
       "      <td>5.251556e+06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104</td>\n",
       "      <td>1028 00:11:39</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291014</th>\n",
       "      <td>9000</td>\n",
       "      <td>6.265080e+06</td>\n",
       "      <td>5.251556e+06</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>1028 00:21:45</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291013</th>\n",
       "      <td>9000</td>\n",
       "      <td>6.265080e+06</td>\n",
       "      <td>5.251556e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1028 00:31:39</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291012</th>\n",
       "      <td>9000</td>\n",
       "      <td>6.265080e+06</td>\n",
       "      <td>5.251556e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>301</td>\n",
       "      <td>1028 00:41:42</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID           lat           lon  speed  direction           time  \\\n",
       "5291016  9000  6.265080e+06  5.251556e+06   0.32        242  1028 00:01:38   \n",
       "5291015  9000  6.265080e+06  5.251556e+06   0.00        104  1028 00:11:39   \n",
       "5291014  9000  6.265080e+06  5.251556e+06   0.22          0  1028 00:21:45   \n",
       "5291013  9000  6.265080e+06  5.251556e+06   0.11          0  1028 00:31:39   \n",
       "5291012  9000  6.265080e+06  5.251556e+06   0.11        301  1028 00:41:42   \n",
       "\n",
       "            type  \n",
       "5291016  unknown  \n",
       "5291015  unknown  \n",
       "5291014  unknown  \n",
       "5291013  unknown  \n",
       "5291012  unknown  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['ID', 'time'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:28.423016Z",
     "start_time": "2020-11-09T01:39:19.415302Z"
    }
   },
   "outputs": [],
   "source": [
    "df['time'] = df['time'].apply(lambda x: '2019-' + x.split(' ')[0][:2] + '-' + x.split(' ')[0][2:] + ' ' + x.split(' ')[1])\n",
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:35.453854Z",
     "start_time": "2020-11-09T01:39:28.423979Z"
    }
   },
   "outputs": [],
   "source": [
    "df['lat_diff'] = df.groupby('ID')['lat'].diff(1)\n",
    "df['lon_diff'] = df.groupby('ID')['lon'].diff(1)\n",
    "df['speed_diff'] = df.groupby('ID')['speed'].diff(1)\n",
    "df['diff_minutes'] = df.groupby('ID')['time'].diff(1).dt.seconds // 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:40:57.057694Z",
     "start_time": "2020-11-09T01:39:35.454852Z"
    }
   },
   "outputs": [],
   "source": [
    "df['anchor'] = df.apply(lambda x: 1 if x['lat_diff'] < 0.01 and x['lon_diff'] < 0.01 and x['speed'] < 0.1 and x['diff_minutes'] < 10 else 0 , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:40:57.775204Z",
     "start_time": "2020-11-09T01:40:57.058656Z"
    }
   },
   "outputs": [],
   "source": [
    "lat_lon_neq_zero = df[(df['lat_diff'] != 0) & (df['lon_diff'] != 0)]\n",
    "speed_neg_zero = df[df['speed_diff'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:40:58.324378Z",
     "start_time": "2020-11-09T01:40:57.776163Z"
    }
   },
   "outputs": [],
   "source": [
    "df['type'] = df['type'].map({'围网': 0, '刺网': 1, '拖网': 2, 'unknown': -1})\n",
    "group_df = df.groupby('ID', as_index=False)['type'].agg({'label': 'mean', 'cnt': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:40:58.688421Z",
     "start_time": "2020-11-09T01:40:58.325342Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取锚点位置信息\n",
    "anchor_df = df.groupby('ID', as_index=False)['anchor'].agg('sum')\n",
    "anchor_df.columns = ['ID', 'anchor_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:40:58.706388Z",
     "start_time": "2020-11-09T01:40:58.689368Z"
    }
   },
   "outputs": [],
   "source": [
    "group_df = group_df.merge(anchor_df, on='ID', how='left')\n",
    "group_df['anchor_ratio'] = group_df['anchor_cnt'] / group_df['cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:40:58.712324Z",
     "start_time": "2020-11-09T01:40:58.707338Z"
    }
   },
   "outputs": [],
   "source": [
    "stat_functions = ['min', 'max', 'mean', 'median', 'nunique', q10, q20, q30, q40, q60, q70, q80, q90]\n",
    "stat_ways = ['min', 'max', 'mean', 'median', 'nunique', 'q_10', 'q_20', 'q_30', 'q_40', 'q_60', 'q_70', 'q_80', 'q_90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:40:58.718308Z",
     "start_time": "2020-11-09T01:40:58.713322Z"
    }
   },
   "outputs": [],
   "source": [
    "stat_cols = ['lat', 'lon', 'speed', 'direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:43:40.176232Z",
     "start_time": "2020-11-09T01:40:58.719306Z"
    }
   },
   "outputs": [],
   "source": [
    "group_tmp = df.groupby('ID')[stat_cols].agg(stat_functions).reset_index()\n",
    "group_tmp.columns = ['ID'] + ['{}_{}'.format(i, j) for i in stat_cols for j in stat_ways]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:46:11.908885Z",
     "start_time": "2020-11-09T01:43:40.177228Z"
    }
   },
   "outputs": [],
   "source": [
    "lat_lon_neq_group = lat_lon_neq_zero.groupby('ID', as_index=True)[stat_cols].agg(stat_functions).reset_index()\n",
    "lat_lon_neq_group.columns = ['ID'] + ['pos_neq_zero_{}_{}'.format(i, j) for i in stat_cols for j in stat_ways]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:48:52.322554Z",
     "start_time": "2020-11-09T01:46:11.909857Z"
    }
   },
   "outputs": [],
   "source": [
    "speed_neg_zero_group = speed_neg_zero.groupby('ID')[stat_cols].agg(stat_functions).reset_index()\n",
    "speed_neg_zero_group.columns = ['ID'] + ['speed_neq_zero_{}_{}'.format(i, j) for i in stat_cols for j in stat_ways]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:48:52.431410Z",
     "start_time": "2020-11-09T01:48:52.323594Z"
    }
   },
   "outputs": [],
   "source": [
    "group_df = group_df.merge(group_tmp, on='ID', how='left')\n",
    "group_df = group_df.merge(lat_lon_neq_group, on='ID', how='left')\n",
    "group_df = group_df.merge(speed_neg_zero_group, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:48:54.742153Z",
     "start_time": "2020-11-09T01:48:52.433336Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取TOP频次的位置信息，这里选Top3\n",
    "mode_df = df.groupby(['ID', 'lat', 'lon'], as_index=False)['time'].agg({'mode_cnt': 'count'})\n",
    "mode_df['rank'] = mode_df.groupby('ID')['mode_cnt'].rank(method='first', ascending=False)\n",
    "for i in range(1, 4):\n",
    "    tmp_df = mode_df[mode_df['rank'] == i]\n",
    "    del tmp_df['rank']\n",
    "    tmp_df.columns = ['ID', 'rank{}_mode_lat'.format(i), 'rank{}_mode_lon'.format(i), 'rank{}_mode_cnt'.format(i)]\n",
    "    group_df = group_df.merge(tmp_df, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:53:51.716992Z",
     "start_time": "2020-11-09T01:48:54.744817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geohash tfidf finished.\n"
     ]
    }
   ],
   "source": [
    "tfidf_df = get_geohash_tfidf(df, 'ID', 'lat_lon', 30)\n",
    "group_df = group_df.merge(tfidf_df, on='ID', how='left')\n",
    "print('geohash tfidf finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:54:53.013889Z",
     "start_time": "2020-11-09T01:53:51.717951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient tfidf finished.\n"
     ]
    }
   ],
   "source": [
    "grad_tfidf = get_grad_tfidf(df, 'ID', 'grad', 30)\n",
    "group_df = group_df.merge(grad_tfidf, on='ID', how='left')\n",
    "print('gradient tfidf finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:55:07.883272Z",
     "start_time": "2020-11-09T01:54:53.014888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample tfidf finished.\n"
     ]
    }
   ],
   "source": [
    "sample_tfidf = get_sample_tfidf(df, 'ID', 'sample', 30)\n",
    "group_df = group_df.merge(sample_tfidf, on='ID', how='left')\n",
    "print('sample tfidf finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T02:16:12.704142Z",
     "start_time": "2020-11-09T01:55:07.885267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start word2vec ...\n",
      "word2vec finished.\n"
     ]
    }
   ],
   "source": [
    "w2v_df = w2v_feat(df, 'ID', 'lat_lon', 30)\n",
    "group_df = group_df.merge(w2v_df, on='ID', how='left')\n",
    "print('word2vec finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T02:16:12.774365Z",
     "start_time": "2020-11-09T02:16:12.705139Z"
    }
   },
   "outputs": [],
   "source": [
    "use_train = group_df[group_df['label'] != -1]\n",
    "use_test = group_df[group_df['label'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T02:16:12.780351Z",
     "start_time": "2020-11-09T02:16:12.775364Z"
    }
   },
   "outputs": [],
   "source": [
    "use_feats = [c for c in use_train.columns if c not in ['ID', 'label']]\n",
    "label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T02:16:12.786334Z",
     "start_time": "2020-11-09T02:16:12.782344Z"
    }
   },
   "outputs": [],
   "source": [
    "n_class = 3\n",
    "train_pred = np.zeros((use_train.shape[0], n_class))\n",
    "test_pred = np.zeros((use_test.shape[0], n_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T02:16:12.802291Z",
     "start_time": "2020-11-09T02:16:12.787332Z"
    }
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "folds = KFold(n_splits=n_splits, shuffle=True, random_state=1024)\n",
    "kf_way = folds.split(use_train[use_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T02:16:12.808277Z",
     "start_time": "2020-11-09T02:16:12.803289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 318 features ...\n"
     ]
    }
   ],
   "source": [
    "print('Use {} features ...'.format(len(use_feats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T02:16:12.815260Z",
     "start_time": "2020-11-09T02:16:12.809272Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'None',\n",
    "    'num_leaves': 63,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'seed': 1,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction_seed': 7,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'num_class': n_class,\n",
    "    'nthread': 8,\n",
    "    'verbose': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T02:16:12.823236Z",
     "start_time": "2020-11-09T02:16:12.817253Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_score_eval(preds, valid_df):\n",
    "    labels = valid_df.get_label()\n",
    "    preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "    scores = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    return 'macro_f1_score', scores, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T02:21:00.930345Z",
     "start_time": "2020-11-09T02:16:12.824234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 training start ...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's macro_f1_score: 0.91087\n",
      "[200]\tvalid_0's macro_f1_score: 0.919444\n",
      "[300]\tvalid_0's macro_f1_score: 0.91997\n",
      "[400]\tvalid_0's macro_f1_score: 0.920005\n",
      "Early stopping, best iteration is:\n",
      "[329]\tvalid_0's macro_f1_score: 0.922449\n",
      "the 2 training start ...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's macro_f1_score: 0.915903\n",
      "[200]\tvalid_0's macro_f1_score: 0.926406\n",
      "[300]\tvalid_0's macro_f1_score: 0.927409\n",
      "[400]\tvalid_0's macro_f1_score: 0.929315\n",
      "[500]\tvalid_0's macro_f1_score: 0.930324\n",
      "Early stopping, best iteration is:\n",
      "[479]\tvalid_0's macro_f1_score: 0.933301\n",
      "the 3 training start ...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's macro_f1_score: 0.893104\n",
      "[200]\tvalid_0's macro_f1_score: 0.903951\n",
      "[300]\tvalid_0's macro_f1_score: 0.906737\n",
      "[400]\tvalid_0's macro_f1_score: 0.910411\n",
      "[500]\tvalid_0's macro_f1_score: 0.910055\n",
      "Early stopping, best iteration is:\n",
      "[443]\tvalid_0's macro_f1_score: 0.911892\n",
      "the 4 training start ...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's macro_f1_score: 0.926341\n",
      "[200]\tvalid_0's macro_f1_score: 0.930184\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's macro_f1_score: 0.932328\n",
      "the 5 training start ...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's macro_f1_score: 0.908382\n",
      "[200]\tvalid_0's macro_f1_score: 0.914766\n",
      "[300]\tvalid_0's macro_f1_score: 0.917875\n",
      "[400]\tvalid_0's macro_f1_score: 0.922164\n",
      "[500]\tvalid_0's macro_f1_score: 0.922798\n",
      "Early stopping, best iteration is:\n",
      "[411]\tvalid_0's macro_f1_score: 0.923131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9320    0.9797    0.9553      3541\n",
      "           1     0.9481    0.8080    0.8724      1333\n",
      "           2     0.9438    0.9484    0.9461      3292\n",
      "\n",
      "    accuracy                         0.9390      8166\n",
      "   macro avg     0.9413    0.9120    0.9246      8166\n",
      "weighted avg     0.9394    0.9390    0.9380      8166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_fold, (train_idx, valid_idx) in enumerate(kf_way, start=1):\n",
    "    print('the {} training start ...'.format(n_fold))\n",
    "    train_x, train_y = use_train[use_feats].iloc[train_idx], use_train[label].iloc[train_idx]\n",
    "    valid_x, valid_y = use_train[use_feats].iloc[valid_idx], use_train[label].iloc[valid_idx]\n",
    "\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    clf = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=3000,\n",
    "        valid_sets=[dvalid],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "        feval=f1_score_eval\n",
    "    )\n",
    "    train_pred[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration)\n",
    "    test_pred += clf.predict(use_test[use_feats], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(classification_report(use_train[label], np.argmax(train_pred, axis=1), digits=4))\n",
    "\n",
    "use_test['label'] = np.argmax(test_pred, axis=1)\n",
    "sub = use_test[['ID', 'label']]\n",
    "\n",
    "sub['label'] = sub['label'].map({0: '围网', 1: '刺网', 2: '拖网'})\n",
    "sub.to_csv('../../sub/result.csv', encoding='utf-8', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
