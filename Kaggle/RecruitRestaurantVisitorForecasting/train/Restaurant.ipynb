{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mp.weixin.qq.com/s/0qOGevwTltu2SJ-QanW0VA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具包导入&数据读取\n",
    "## 工具包导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:30.156107Z",
     "start_time": "2020-07-10T10:02:28.501324Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import gc\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from itertools import combinations, product\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### air_reserve\n",
    "- air_store_id - the restaurant's id in the air system\n",
    "- visit_datetime - the time of the reservation\n",
    "- reserve_datetime - the time the reservation was made\n",
    "- reserve_visitors - the number of visitors for that reservation\n",
    "\n",
    "### hpg_reserve\n",
    "- hpg_store_id - the restaurant's id in the hpg system\n",
    "- visit_datetime - the time of the reservation\n",
    "- reserve_datetime - the time the reservation was made\n",
    "- reserve_visitors - the number of visitors for that reservation\n",
    "\n",
    "### air_store_info\n",
    "- air_store_id\n",
    "- air_genre_name\n",
    "- air_area_name\n",
    "- latitude\n",
    "- longitude\n",
    "\n",
    "### hpg_store_info\n",
    "- hpg_store_id\n",
    "- hpg_genre_name\n",
    "- hpg_area_name\n",
    "- latitude\n",
    "- longitude\n",
    "\n",
    "### date_info\n",
    "- calendar_date\n",
    "- day_of_week\n",
    "- holiday_flg - is the day a holiday in Japan\n",
    "\n",
    "### store_id_relation\n",
    "This file allows you to join select restaurants that have both the air and hpg system.\n",
    "- hpg_store_id\n",
    "- air_store_id\n",
    "\n",
    "### air_visit_data\n",
    "- air_store_id\n",
    "- visit_date - the date\n",
    "- visitors - the number of visitors to the restaurant on the date\n",
    "\n",
    "### sample_submission\n",
    "This file shows a submission in the correct format, including the days for which you must forecast.\n",
    "\n",
    "- id - the id is formed by concatenating the air_store_id and visit_date with an underscore\n",
    "- visitors - the number of visitors forecasted for the store and date combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.650107Z",
     "start_time": "2020-07-10T10:02:30.157080Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '../input/'\n",
    "\n",
    "air_visit_data      =  pd.read_csv(path + 'air_visit_data.csv') \n",
    "\n",
    "hpg_store_info      =  pd.read_csv(path + 'hpg_store_info.csv')\n",
    "air_store_info      =  pd.read_csv(path + 'air_store_info.csv')\n",
    "\n",
    "hpg_reserve         =  pd.read_csv(path + 'hpg_reserve.csv')\n",
    "air_reserve         =  pd.read_csv(path + 'air_reserve.csv') \n",
    "\n",
    "date_info           =  pd.read_csv(path + 'date_info.csv')  \n",
    "\n",
    "store_id_relation   =  pd.read_csv(path + 'store_id_relation.csv')     \n",
    "\n",
    "sample_submission   =  pd.read_csv(path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**air_visit_data.csv**\n",
    "\n",
    "- air_store_id\n",
    "- visit_date - the date\n",
    "- visitors - the number of visitors to the restaurant on the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.665577Z",
     "start_time": "2020-07-10T10:02:31.652102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25\n",
       "1  air_ba937bf13d40fb24  2016-01-14        32\n",
       "2  air_ba937bf13d40fb24  2016-01-15        29\n",
       "3  air_ba937bf13d40fb24  2016-01-16        22\n",
       "4  air_ba937bf13d40fb24  2016-01-18         6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_visit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hpg_store_info.csv**\n",
    "\n",
    "- hpg_store_id\n",
    "- hpg_genre_name\n",
    "- hpg_area_name\n",
    "- latitude\n",
    "- longitude\n",
    "\n",
    "Note: latitude and longitude are the latitude and longitude of the area to which the store belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.686521Z",
     "start_time": "2020-07-10T10:02:31.667571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpg_store_id</th>\n",
       "      <th>hpg_genre_name</th>\n",
       "      <th>hpg_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_6622b62385aec8bf</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_e9e068dd49c5fa00</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_2976f7acb4b3a3bc</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_e51a522e098f024c</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_e3d0e1519894f275</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hpg_store_id  hpg_genre_name                  hpg_area_name  \\\n",
       "0  hpg_6622b62385aec8bf  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "1  hpg_e9e068dd49c5fa00  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "2  hpg_2976f7acb4b3a3bc  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "3  hpg_e51a522e098f024c  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "4  hpg_e3d0e1519894f275  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "\n",
       "    latitude   longitude  \n",
       "0  35.643675  139.668221  \n",
       "1  35.643675  139.668221  \n",
       "2  35.643675  139.668221  \n",
       "3  35.643675  139.668221  \n",
       "4  35.643675  139.668221  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpg_store_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**air_store_info.csv**\n",
    "\n",
    "- air_store_id\n",
    "- air_genre_name\n",
    "- air_area_name\n",
    "- latitude\n",
    "- longitude\n",
    "\n",
    "Note: latitude and longitude are the latitude and longitude of the area to which the store belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.697511Z",
     "start_time": "2020-07-10T10:02:31.687520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  air_genre_name                 air_area_name  \\\n",
       "0  air_0f0cdeee6c9bf3d7  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "1  air_7cc17a324ae5c7dc  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "2  air_fee8dcf4d619598e  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "3  air_a17f0778617c76e2  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "4  air_83db5aff8f50478e  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "\n",
       "    latitude   longitude  \n",
       "0  34.695124  135.197852  \n",
       "1  34.695124  135.197852  \n",
       "2  34.695124  135.197852  \n",
       "3  34.695124  135.197852  \n",
       "4  35.658068  139.751599  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_store_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hpg_reserve.csv**\n",
    "\n",
    "This file contains reservations made in the hpg system.\n",
    "\n",
    "- hpg_store_id - the restaurant's id in the hpg system\n",
    "- visit_datetime - the time of the reservation\n",
    "- reserve_datetime - the time the reservation was made\n",
    "- reserve_visitors - the number of visitors for that reservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.708464Z",
     "start_time": "2020-07-10T10:02:31.698490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpg_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_c63f6f42e088e50f</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>2016-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_dac72789163a3f47</td>\n",
       "      <td>2016-01-01 13:00:00</td>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_c8e24dcf51ca1eb5</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2016-01-01 14:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_24bb207e5fd49d4a</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_25291c542ebb3bc2</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hpg_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  hpg_c63f6f42e088e50f  2016-01-01 11:00:00  2016-01-01 09:00:00   \n",
       "1  hpg_dac72789163a3f47  2016-01-01 13:00:00  2016-01-01 06:00:00   \n",
       "2  hpg_c8e24dcf51ca1eb5  2016-01-01 16:00:00  2016-01-01 14:00:00   \n",
       "3  hpg_24bb207e5fd49d4a  2016-01-01 17:00:00  2016-01-01 11:00:00   \n",
       "4  hpg_25291c542ebb3bc2  2016-01-01 17:00:00  2016-01-01 03:00:00   \n",
       "\n",
       "   reserve_visitors  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 2  \n",
       "3                 5  \n",
       "4                13  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpg_reserve.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**air_reserve.csv**\n",
    "- air_store_id - the restaurant's id in the air system\n",
    "- visit_datetime - the time of the reservation\n",
    "- reserve_datetime - the time the reservation was made\n",
    "- reserve_visitors - the number of visitors for that reservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.717469Z",
     "start_time": "2020-07-10T10:02:31.709461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "2  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "3  air_877f79706adbfb06  2016-01-01 20:00:00  2016-01-01 16:00:00   \n",
       "4  air_db80363d35f10926  2016-01-01 20:00:00  2016-01-01 01:00:00   \n",
       "\n",
       "   reserve_visitors  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 6  \n",
       "3                 2  \n",
       "4                 5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_reserve.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**date_info.csv**\n",
    "- calendar_date\n",
    "- day_of_week\n",
    "- holiday_flg - is the day a holiday in Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.728409Z",
     "start_time": "2020-07-10T10:02:31.719433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calendar_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  calendar_date day_of_week  holiday_flg\n",
       "0    2016-01-01      Friday            1\n",
       "1    2016-01-02    Saturday            1\n",
       "2    2016-01-03      Sunday            1\n",
       "3    2016-01-04      Monday            0\n",
       "4    2016-01-05     Tuesday            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**store_id_relation.csv**\n",
    "\n",
    "This file allows you to join select restaurants that have both the air and hpg system.\n",
    "\n",
    "- hpg_store_id\n",
    "- air_store_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.739381Z",
     "start_time": "2020-07-10T10:02:31.730406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>hpg_store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_63b13c56b7201bd9</td>\n",
       "      <td>hpg_4bc649e72e2a239a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_a24bf50c3e90d583</td>\n",
       "      <td>hpg_c34b496d0305a809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_c7f78b4f3cba33ff</td>\n",
       "      <td>hpg_cd8ae0d9bbd58ff9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_947eb2cae4f3e8f2</td>\n",
       "      <td>hpg_de24ea49dc25d6b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_965b2e0cf4119003</td>\n",
       "      <td>hpg_653238a84804d8e7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id          hpg_store_id\n",
       "0  air_63b13c56b7201bd9  hpg_4bc649e72e2a239a\n",
       "1  air_a24bf50c3e90d583  hpg_c34b496d0305a809\n",
       "2  air_c7f78b4f3cba33ff  hpg_cd8ae0d9bbd58ff9\n",
       "3  air_947eb2cae4f3e8f2  hpg_de24ea49dc25d6b8\n",
       "4  air_965b2e0cf4119003  hpg_653238a84804d8e7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_id_relation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sample_submission.csv**\n",
    "\n",
    "This file shows a submission in the correct format, including the days for which you must forecast.\n",
    "\n",
    "- id - the id is formed by concatenating the air_store_id and visit_date with an underscore\n",
    "- visitors - the number of visitors forecasted for the store and date combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.747396Z",
     "start_time": "2020-07-10T10:02:31.740378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0\n",
       "1  air_00a91d42b08b08d9_2017-04-24         0\n",
       "2  air_00a91d42b08b08d9_2017-04-25         0\n",
       "3  air_00a91d42b08b08d9_2017-04-26         0\n",
       "4  air_00a91d42b08b08d9_2017-04-27         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.800218Z",
     "start_time": "2020-07-10T10:02:31.748357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['air_store_id'] = sample_submission['id'].apply(lambda x: x[:-11]).values\n",
    "sample_submission['visit_date'] = sample_submission['id'].apply(lambda x: x[-10:]).values\n",
    "\n",
    "del sample_submission['id']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:31.980734Z",
     "start_time": "2020-07-10T10:02:31.801216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.concat([air_visit_data, sample_submission],\n",
    "                    axis=0,\n",
    "                    ignore_index=True)\n",
    "\n",
    "# 合并date_info\n",
    "df_meta = df_meta.merge(date_info,\n",
    "                        left_on=['visit_date'],\n",
    "                        right_on=['calendar_date'],\n",
    "                        how='left')\n",
    "# 合并air_store_info\n",
    "df_meta = df_meta.merge(air_store_info,\n",
    "                        on=['air_store_id'],\n",
    "                        how='left')\n",
    "\n",
    "del df_meta['calendar_date'], df_meta['day_of_week']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:32.142359Z",
     "start_time": "2020-07-10T10:02:31.981742Z"
    }
   },
   "outputs": [],
   "source": [
    "df_meta['visit_date'] = pd.to_datetime(df_meta['visit_date'])\n",
    "# Monday=0, Sunday=6\n",
    "df_meta['weekday'] = df_meta['visit_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类别层次特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:33.150770Z",
     "start_time": "2020-07-10T10:02:32.143320Z"
    }
   },
   "outputs": [],
   "source": [
    "df_meta['air_store_id_weekday'] = df_meta['air_store_id'].astype(str) + '_' + df_meta['weekday'].astype(str)\n",
    "\n",
    "df_meta['air_store_id_holiday'] = df_meta['air_store_id'].astype(str) + '_' + df_meta['holiday_flg'].astype(str)\n",
    "df_meta['air_store_id_weekday_holiday'] = df_meta['air_store_id_holiday'].astype(str) + '_' + df_meta['weekday'].astype(str)\n",
    "\n",
    "df_meta['air_genre_name_weekday'] = df_meta['air_area_name'].astype(str) + df_meta['weekday'].astype(str)\n",
    "df_meta['air_genre_name_weekday_holiday'] = df_meta['air_genre_name_weekday'].astype(str) + df_meta['holiday_flg'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:33.174374Z",
     "start_time": "2020-07-10T10:02:33.152438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>weekday</th>\n",
       "      <th>air_store_id_weekday</th>\n",
       "      <th>air_store_id_holiday</th>\n",
       "      <th>air_store_id_weekday_holiday</th>\n",
       "      <th>air_genre_name_weekday</th>\n",
       "      <th>air_genre_name_weekday_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>2</td>\n",
       "      <td>air_ba937bf13d40fb24_2</td>\n",
       "      <td>air_ba937bf13d40fb24_0</td>\n",
       "      <td>air_ba937bf13d40fb24_0_2</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen2</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>3</td>\n",
       "      <td>air_ba937bf13d40fb24_3</td>\n",
       "      <td>air_ba937bf13d40fb24_0</td>\n",
       "      <td>air_ba937bf13d40fb24_0_3</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen3</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>4</td>\n",
       "      <td>air_ba937bf13d40fb24_4</td>\n",
       "      <td>air_ba937bf13d40fb24_0</td>\n",
       "      <td>air_ba937bf13d40fb24_0_4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>5</td>\n",
       "      <td>air_ba937bf13d40fb24_5</td>\n",
       "      <td>air_ba937bf13d40fb24_0</td>\n",
       "      <td>air_ba937bf13d40fb24_0_5</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen5</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0</td>\n",
       "      <td>air_ba937bf13d40fb24_0</td>\n",
       "      <td>air_ba937bf13d40fb24_0</td>\n",
       "      <td>air_ba937bf13d40fb24_0_0</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen0</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id visit_date  visitors  holiday_flg air_genre_name  \\\n",
       "0  air_ba937bf13d40fb24 2016-01-13  3.258097            0     Dining bar   \n",
       "1  air_ba937bf13d40fb24 2016-01-14  3.496508            0     Dining bar   \n",
       "2  air_ba937bf13d40fb24 2016-01-15  3.401197            0     Dining bar   \n",
       "3  air_ba937bf13d40fb24 2016-01-16  3.135494            0     Dining bar   \n",
       "4  air_ba937bf13d40fb24 2016-01-18  1.945910            0     Dining bar   \n",
       "\n",
       "                  air_area_name   latitude   longitude  weekday  \\\n",
       "0  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599        2   \n",
       "1  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599        3   \n",
       "2  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599        4   \n",
       "3  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599        5   \n",
       "4  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599        0   \n",
       "\n",
       "     air_store_id_weekday    air_store_id_holiday  \\\n",
       "0  air_ba937bf13d40fb24_2  air_ba937bf13d40fb24_0   \n",
       "1  air_ba937bf13d40fb24_3  air_ba937bf13d40fb24_0   \n",
       "2  air_ba937bf13d40fb24_4  air_ba937bf13d40fb24_0   \n",
       "3  air_ba937bf13d40fb24_5  air_ba937bf13d40fb24_0   \n",
       "4  air_ba937bf13d40fb24_0  air_ba937bf13d40fb24_0   \n",
       "\n",
       "  air_store_id_weekday_holiday         air_genre_name_weekday  \\\n",
       "0     air_ba937bf13d40fb24_0_2  Tōkyō-to Minato-ku Shibakōen2   \n",
       "1     air_ba937bf13d40fb24_0_3  Tōkyō-to Minato-ku Shibakōen3   \n",
       "2     air_ba937bf13d40fb24_0_4  Tōkyō-to Minato-ku Shibakōen4   \n",
       "3     air_ba937bf13d40fb24_0_5  Tōkyō-to Minato-ku Shibakōen5   \n",
       "4     air_ba937bf13d40fb24_0_0  Tōkyō-to Minato-ku Shibakōen0   \n",
       "\n",
       "   air_genre_name_weekday_holiday  \n",
       "0  Tōkyō-to Minato-ku Shibakōen20  \n",
       "1  Tōkyō-to Minato-ku Shibakōen30  \n",
       "2  Tōkyō-to Minato-ku Shibakōen40  \n",
       "3  Tōkyō-to Minato-ku Shibakōen50  \n",
       "4  Tōkyō-to Minato-ku Shibakōen00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta['visitors'] = df_meta['visitors'].apply(np.log1p).values\n",
    "\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预定表，包括air_reserve和hpg_reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.252823Z",
     "start_time": "2020-07-10T10:02:33.175366Z"
    }
   },
   "outputs": [],
   "source": [
    "# air系统\n",
    "air_reserve['visit_date'] = air_reserve['visit_datetime'].apply(lambda x: x.split(' ')[0]).values\n",
    "air_reserve['air_store_id_visit_date'] = air_reserve['air_store_id'] + '_' + air_reserve['visit_datetime'].astype(str)\n",
    "\n",
    "air_reserve['visit_datetime'] = pd.to_datetime(air_reserve['visit_datetime'])\n",
    "air_reserve['reserve_datetime'] = pd.to_datetime(air_reserve['reserve_datetime'])\n",
    "\n",
    "# hpg系统\n",
    "hpg_reserve['visit_date'] = hpg_reserve['visit_datetime'].apply(lambda x: x.split(' ')[0]).values\n",
    "\n",
    "\n",
    "# hpg系统关联得到air_store_id\n",
    "hpg_to_air_storeid = store_id_relation.set_index('hpg_store_id')\n",
    "hpg_reserve['air_store_id'] = hpg_reserve['hpg_store_id'].map(hpg_to_air_storeid['air_store_id']).values\n",
    "hpg_air_reserve = hpg_reserve.loc[hpg_reserve.air_store_id.notnull()]\n",
    "\n",
    "hpg_air_reserve['air_store_id_visit_date'] = hpg_air_reserve['air_store_id'] + '_' + hpg_air_reserve['visit_date'].astype(str)\n",
    "hpg_air_reserve['visit_datetime'] = pd.to_datetime(hpg_air_reserve['visit_datetime'])\n",
    "hpg_air_reserve['reserve_datetime'] = pd.to_datetime(hpg_air_reserve['reserve_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程\n",
    "## 一阶特征\n",
    "### store_id的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. store_id的基础信息，包括类型，地址，经纬度\n",
    "2. store_id的营业天数，开业到现在的时间，最后一天到现在的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.262499Z",
     "start_time": "2020-07-10T10:02:34.254480Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_storeid_fea(df_visit_data, df_store_info, df_store_id_relation):\n",
    "    df_storeid = df_store_info.copy()\n",
    "    \n",
    "    # 对air_genre_name和air_area_name做LabelEncoder\n",
    "    df_storeid['air_genre_name'] = LabelEncoder().fit_transform(df_storeid['air_genre_name'].values)\n",
    "    df_storeid['air_area_name'] = LabelEncoder().fit_transform(df_storeid['air_area_name'].values)\n",
    "    \n",
    "    # 每个air_store_id日期的最小值和最大值\n",
    "    first_day_dict = df_visit_data.groupby(['air_store_id'])['visit_date'].min().to_dict()\n",
    "    last_day_dict = df_visit_data.groupby(['air_store_id'])['visit_date'].max().to_dict()\n",
    "    \n",
    "    # 每个air_store_id的营业天数\n",
    "    run_days_dict = df_visit_data.groupby(['air_store_id'])['visit_date'].nunique().to_dict()\n",
    "    \n",
    "    # 每个air_store_id (2017-04-22 - first_day)相差的天数\n",
    "    df_storeid['first_day_to_now'] = df_storeid['air_store_id'].map(first_day_dict).values\n",
    "    df_storeid['first_day_to_now'] = df_storeid['first_day_to_now'].apply(lambda x: (parse('2017-04-22') - parse(x)).days)\n",
    "    \n",
    "    # 每个air_store_id (2017-04-22 - last_day)相差的天数\n",
    "    df_storeid['last_day_to_now'] = df_storeid['air_store_id'].map(last_day_dict).values\n",
    "    df_storeid['last_day_to_now'] = df_storeid['last_day_to_now'].apply(lambda x: (parse('2017-04-22') - parse(x)).days)\n",
    "    \n",
    "    # 每个air_store_id的营业天数\n",
    "    df_storeid['run_days'] = df_storeid['air_store_id'].map(run_days_dict).values\n",
    "    \n",
    "    # air_store_id是否在store_id_relation里面\n",
    "    df_storeid['two_systems'] = df_storeid['air_store_id'].isin(df_store_id_relation['air_store_id']).values\n",
    "    df_storeid['two_systems'] = df_storeid['two_systems'].astype(int)\n",
    "    \n",
    "    return df_storeid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.709657Z",
     "start_time": "2020-07-10T10:02:34.263486Z"
    }
   },
   "outputs": [],
   "source": [
    "df_storeid = get_storeid_fea(air_visit_data, air_store_info, store_id_relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date的特征\n",
    "1. 星期几\n",
    "2. 是否节假日\n",
    "3. 距离月末，月初的时间\n",
    "4. 距离最近的节假日的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.718361Z",
     "start_time": "2020-07-10T10:02:34.711340Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_last_next_holiday(dates, holiday_flags):\n",
    "    last_holiday = []\n",
    "    next_holiday = []\n",
    "    len_ = len(dates)\n",
    "    for i, (d, f) in enumerate(zip(dates, holiday_flags)):\n",
    "        if i == 0:\n",
    "            last_holiday.append(dates[i])\n",
    "        else:\n",
    "            # last holiday\n",
    "            last_flag = 0\n",
    "            for j in range(i - 1, 0, -1):\n",
    "                if holiday_flags[j] == 1:\n",
    "                    last_holiday.append(dates[j])\n",
    "                    last_flag = 1\n",
    "                    break\n",
    "            if last_flag == 0:\n",
    "                last_holiday.append(dates[0])\n",
    "                \n",
    "        # next holiday\n",
    "        next_flag = 0\n",
    "        for j in range(i + 1, len_):\n",
    "            if holiday_flags[j] == 1:\n",
    "                next_holiday.append(dates[j])\n",
    "                next_flag = 1\n",
    "                break\n",
    "        if next_flag == 0:\n",
    "            next_holiday.append(dates[-1])\n",
    "    return last_holiday, next_holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.730892Z",
     "start_time": "2020-07-10T10:02:34.719845Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_days_to_month_end(x):\n",
    "    \"\"\"\n",
    "    计算每个日期距离月底的天数\n",
    "    \"\"\"\n",
    "    month = int(x.split('-')[1])\n",
    "    day = int(x.split('-')[2])\n",
    "    if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        return 31 - day\n",
    "    elif month in [2]:\n",
    "        return 28 - day\n",
    "    else:\n",
    "        return 30 - day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.743831Z",
     "start_time": "2020-07-10T10:02:34.731861Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_time_fea(df_date_info):\n",
    "    \"\"\"\n",
    "    date特征\n",
    "    1. 每个日期距月底、月初的天数\n",
    "    2. 每个日期是周几，是否是周末\n",
    "    3. 每个日期距离上一个和下一个节假日的天数\n",
    "    4. 每个日期的前几天、后几天是否是节假日\n",
    "    \"\"\"\n",
    "    df_date = df_date_info.copy()\n",
    "    \n",
    "    # 每个日期距离月底的天数\n",
    "    df_date['day_to_month_end'] = df_date['calendar_date'].apply(lambda x: get_days_to_month_end(x)).values\n",
    "    # 每个日期距离月初的天数\n",
    "    # df_date['day_to_month_start'] = df_date['calendar_date'].apply(lambda x: int(x.split('-')[2])).values\n",
    "    df_date['day_to_month_start'] = df_date['calendar_date'].apply(lambda x: int(x.split('-')[0])).values\n",
    "    \n",
    "    # 每个日期是周几\n",
    "    df_date['day_of_week'] = df_date['calendar_date'].apply(lambda x: parse(x).weekday()).values\n",
    "    # 每个日期是否是周末\n",
    "    df_date['is_weekend'] = df_date['day_of_week'].apply(lambda x: x > 4).values\n",
    "    \n",
    "    # 每个日期的上一个和下一个节假日日期\n",
    "    last_holiday, next_holiday = get_last_next_holiday(df_date['calendar_date'].values, df_date['holiday_flg'].values)\n",
    "    df_date['last_holiday'] = last_holiday\n",
    "    df_date['next_holiday'] = next_holiday\n",
    "\n",
    "    # 每个日期距离上一个节假日的天数\n",
    "    df_date['day_to_last_holiday'] = (df_date['calendar_date'].apply(lambda x: parse(x))\n",
    "                                      - df_date['last_holiday'].apply(lambda x: parse(x)))\n",
    "    df_date['day_to_last_holiday'] = df_date['day_to_last_holiday'].apply(lambda x: x.days).values\n",
    "    \n",
    "    # 每个日期距离下一个节假日的天数\n",
    "    df_date['day_to_next_holiday'] = (df_date['next_holiday'].apply(lambda x: parse(x))\n",
    "                                      - df_date['calendar_date'].apply(lambda x: parse(x)))\n",
    "    df_date['day_to_next_holiday'] = df_date['day_to_next_holiday'].apply(lambda x: x.days).values\n",
    "    \n",
    "    df_date.rename(columns={'calendar_date': 'visit_date'}, inplace=True)\n",
    "    \n",
    "    df_date['visit_date'] = pd.to_datetime(df_date['visit_date'])\n",
    "    \n",
    "    # 每个日期的前几天，后几天是否是节假日\n",
    "    for i in [3, 2, 1, -1]:\n",
    "        date_info_temp = df_date.copy()\n",
    "        # visit_date = visit_date + i\n",
    "        date_info_temp['visit_date'] = date_info_temp['visit_date'].apply(lambda x: x + timedelta(i))\n",
    "        date_info_temp.rename(columns={'holiday_flg': 'ahead_holiday_{}'.format(i)},\n",
    "                              inplace=True)\n",
    "        \n",
    "        df_date = df_date.merge(date_info_temp[['visit_date', 'ahead_holiday_{}'.format(i)]],\n",
    "                                on=['visit_date'],\n",
    "                                how='left')\n",
    "    del df_date['last_holiday'], df_date['next_holiday']\n",
    "    gc.collect()\n",
    "    return df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.929617Z",
     "start_time": "2020-07-10T10:02:34.744825Z"
    }
   },
   "outputs": [],
   "source": [
    "df_date = get_time_fea(date_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二阶特征：store_id & day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为day这个东西只有一个,而且未来和之前的是不一致的,那么做特征的时候就需要找day相关的属性,同样的store_id的属性也可以构建特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store_id+day(related特征/holiday/weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.939306Z",
     "start_time": "2020-07-10T10:02:34.933359Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_st_date(en_date, days):\n",
    "    \"\"\"\n",
    "    对每个日期减几天\n",
    "    \"\"\"\n",
    "    # st_date <= date < end_date\n",
    "    st_date = en_date - timedelta(days)\n",
    "    return st_date\n",
    "\n",
    "def get_label_st_date(st_date, days):\n",
    "    \"\"\"\n",
    "    对每个日期加几天\n",
    "    \"\"\"\n",
    "    # st_date <= date < end_date\n",
    "    end_date = st_date + timedelta(days)\n",
    "    return st_date, end_date\n",
    "\n",
    "def get_df_label(df, date, days=39, is_te=False):\n",
    "    \"\"\"\n",
    "    时间窗口，窗口在date和date+days之间\n",
    "    \"\"\"\n",
    "    st_date, en_date = get_label_st_date(date, days)  # 对date加days，返回st_date和en_date\n",
    "    print('label date, ', st_date, en_date)\n",
    "    ind1 = df['visit_date'] < en_date\n",
    "    ind2 = df['visit_date'] >= st_date\n",
    "    if is_te:\n",
    "        return df.loc[(ind2), ['air_store_id', 'visit_date', 'air_store_id_holiday',\n",
    "                               'air_genre_name', 'air_genre_name_weekday', 'air_genre_name_weekday_holiday']].copy()\n",
    "    return df.loc[(ind1 & ind2), ['air_store_id', 'visit_date', 'air_store_id_holiday',\n",
    "                                  'air_genre_name', 'air_genre_name_weekday', 'air_genre_name_weekday_holiday',\n",
    "                                  'visitors']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程1：visitors相关特征\n",
    "#### air_store_id+visitors特征（recent days）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近$N(N=14,28,56,1000)$天air_store_id的统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.950317Z",
     "start_time": "2020-07-10T10:02:34.942338Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_store_id_visitors_sts_features(df, en_date, key='air_store_id', date_col='visit_date', days_list=[1000, 56, 28, 14,]):\n",
    "    \"\"\"\n",
    "    时间滑窗\n",
    "    计算每个窗口内，每个店铺的visitors的统计量\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    df_features       = pd.DataFrame()\n",
    "    df_features[key]  = df[key].unique()\n",
    "\n",
    "    df_tmp            = df.copy()\n",
    "    #######################  Recent days sts features #######################\n",
    "    for days in days_list:\n",
    "        # 时间窗口\n",
    "        st_date           = get_st_date(en_date, days)  # 对日期减几天 \n",
    "        df_tmp            = df_tmp.loc[((df[date_col] >= st_date) &  (df[date_col] < en_date))].copy() \n",
    "        df_features_tmp   = df_tmp.groupby([key], as_index=False)['visitors'].agg({\n",
    "            '{}_visitors_min_{}'.format(key,days): 'min',\n",
    "            '{}_visitors_mean_{}'.format(key,days): 'mean',\n",
    "            '{}_visitors_sum_{}'.format(key,days): 'sum',\n",
    "            '{}_visitors_median_{}'.format(key,days): 'median',\n",
    "            '{}_visitors_max_{}'.format(key,days): 'max',\n",
    "            '{}_visitors_count_{}'.format(key,days): 'count',\n",
    "            '{}_visitors_std_{}'.format(key,days): 'std',\n",
    "            '{}_visitors_quantile_{}'.format(key,days): 'quantile',\n",
    "            '{}_visitors_skew_{}'.format(key,days): 'skew'\n",
    "        }) \n",
    "        df_features  = df_features.merge(df_features_tmp, on =key, how = 'left')\n",
    "    print('For store id sts features, we spend {} seconds.'.format(time() - t0)) \n",
    "\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_store_id + visitors diff特征(recent days)\n",
    "最近N(N=28,56,1000)天的趋势统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.963289Z",
     "start_time": "2020-07-10T10:02:34.951274Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_store_id_visitors_diff_sts_features(df, en_date, key='air_store_id', date_col='visit_date', days_list=[1000, 56, 28]):\n",
    "    \"\"\"\n",
    "    visitors_diff的统计量\n",
    "    1. 时间窗口\n",
    "    2. 对每个日期减1，在用日期去关联，相当于得到昨天的visitors\n",
    "    3. visitors_diff = 当天的vistors - 昨天的visitors\n",
    "    4. visitors_diff的统计量\n",
    "    5. visitors_diff的绝对值\n",
    "    6. visitors_diff的绝对值的平均值\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    df_features = pd.DataFrame()\n",
    "    df_features[key] = df[key].unique()\n",
    "    \n",
    "    for days in days_list:\n",
    "        df_tmp = df.copy()\n",
    "        st_date = get_st_date(en_date, days)  # 对日期减几天\n",
    "        # 时间窗口\n",
    "        df_tmp = df_tmp.loc[((df[date_col] >= st_date) & (df[date_col] < en_date))].copy()\n",
    "        df_old_tmp = df_tmp.copy()\n",
    "        \n",
    "        # 每个air_store_id昨天的visitors\n",
    "        df_old_tmp[date_col] = df_tmp[date_col].apply(lambda x: x + timedelta(1)).values  # 用昨天的日期去关联\n",
    "        df_old_tmp.rename(columns={'visitors': 'visitors_yesterday'},\n",
    "                          inplace=True)\n",
    "        df_tmp = df_tmp.merge(df_old_tmp[[key, date_col, 'visitors_yesterday']],\n",
    "                              on=[key, date_col],\n",
    "                              how='left')\n",
    "        \n",
    "        # 当天的visitors - 昨天的visitors\n",
    "        df_tmp['visitors_diff'] = df_tmp['visitors'].values - df_tmp['visitors_yesterday'].values\n",
    "        \n",
    "        df_tmp = df_tmp.loc[df_tmp['visitors_diff'].notnull()]\n",
    "        \n",
    "        df_features_tmp = df_tmp.groupby([key], as_index=False)['visitors_diff'].agg({\n",
    "            '{}_visitors_diff_min_{}'.format(key, days): 'min',\n",
    "            '{}_visitors_diff_mean_{}'.format(key, days): 'mean',\n",
    "            '{}_visitors_diff_median_{}'.format(key, days): 'median',\n",
    "            '{}_visitors_diff_sum_{}'.format(key, days): 'sum',\n",
    "            '{}_visitors_diff_max_{}'.format(key, days): 'max',\n",
    "            '{}_visitors_diff_count_{}'.format(key, days): 'count',\n",
    "            '{}_visitors_diff_std_{}'.format(key, days): 'std',\n",
    "            '{}_visitors_diff_quantile_{}'.format(key, days): 'quantile',\n",
    "            '{}_visitors_diff_skew_{}'.format(key, days): 'skew',\n",
    "        })\n",
    "        \n",
    "        df_tmp['visitors_diff_abs'] = df_tmp['visitors_diff'].map(abs).values\n",
    "        \n",
    "        # 绝对值的平均值\n",
    "        df_features_tmp2 = df_tmp.groupby([key], as_index=False)['visitors_diff_abs'].agg({\n",
    "            '{}_visitors_diff_abs_mean_{}'.format(key, days): 'mean'\n",
    "        })\n",
    "        \n",
    "        df_features = df_features.merge(df_features_tmp, on=key, how='left')\n",
    "        df_features = df_features.merge(df_features_tmp2, on=key, how='left')\n",
    "    print('For store id diff sts features, we spend {} seconds.'.format(time() - t0))\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_store_id + weekday + visitors特征(周期特征)\n",
    "过去每段时间的工作日的的统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.976207Z",
     "start_time": "2020-07-10T10:02:34.964239Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weekday_visitors_sts_features(df, key, end_date, date_col='visit_date', val_name='visitor'):\n",
    "    \"\"\"\n",
    "    时间滑窗，groupby对象不同，这里用的是key=air_store_id_weekday\n",
    "    1. 时间滑窗，前4、8、12、100周\n",
    "    2. 时间窗内的visitor的统计量\n",
    "    3. 最大值-最小值\n",
    "    \"\"\"\n",
    "    df_features = pd.DataFrame()\n",
    "    df_features[key] = df[key].unique()\n",
    "    \n",
    "    # 日期小于end_date\n",
    "    ind1 = df[date_col] < end_date\n",
    "    \n",
    "    # 时间滑窗，日期前4周，8周，12周，100周\n",
    "    for i in [4, 8, 12, 100]:\n",
    "        t_st_date = end_date - timedelta(7 * i)\n",
    "        ind2 = df[date_col] >= t_st_date\n",
    "        df_grp = df.loc[(ind1 & ind2)].groupby(key)\n",
    "        dic_mean = df_grp[val_name].mean().to_dict()\n",
    "        dic_std = df_grp[val_name].std().to_dict()\n",
    "        dic_max = df_grp[val_name].max().to_dict()\n",
    "        dic_min = df_grp[val_name].min().to_dict()\n",
    "        dic_count = df_grp[val_name].count().to_dict()\n",
    "        dic_sum = df_grp[val_name].sum().to_dict()\n",
    "        dic_quantile = df_grp[val_name].quantile().to_dict()\n",
    "        \n",
    "        df_features['{}_weekdays_mean_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_mean).values\n",
    "        df_features['{}_weekdays_std_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_std).values\n",
    "        df_features['{}_weekdays_max_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_max).values\n",
    "        df_features['{}_weekdays_min_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_min).values\n",
    "        df_features['{}_weekdays_count_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_count).values\n",
    "        df_features['{}_weekdays_sum_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_sum).values\n",
    "        df_features['{}_weekdays_quantile_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_quantile).values\n",
    "        \n",
    "        # 最大值 - 最小值\n",
    "        df_features['{}_weekdays_gap_{}_{}'.format(key, i + 1, val_name)] = (df_features['{}_weekdays_max_{}_{}'.format(key, i + 1, val_name)] -\n",
    "                                                                             df_features['{}_weekdays_min_{}_{}'.format(key, i + 1, val_name)])\n",
    "        \n",
    "        return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_store_id + weekday + visitors diff特征(周期特征)\n",
    "过去每段时间的工作日的差值统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:34.992166Z",
     "start_time": "2020-07-10T10:02:34.977204Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weekday_visitors_diff_sts_features(df, key, end_date, date_col='visit_date', val_name='visitors'): \n",
    "    \"\"\"\n",
    "    时间滑窗，groupby对象不同，这里用的是key=air_store_id_weekday\n",
    "    1. 时间滑窗，前4周、8周、12周、100周\n",
    "    2. 前1周那天的visitors_diff\n",
    "    3. visitors_diff的统计量\n",
    "    \"\"\"\n",
    "    df_features = pd.DataFrame() \n",
    "    df_features[key] = df[key].unique()\n",
    "\n",
    "    ind1 = df[date_col] < end_date  \n",
    "    # 时间滑窗，前4周，8周，12周，100周\n",
    "    for i in [4, 8, 12, 100]:\n",
    "        t_st_date = end_date - timedelta(7 * i) \n",
    "        ind2 = df[date_col] >= t_st_date \n",
    "\n",
    "        df_tmp = df.loc[ind1 & ind2].copy() \n",
    "\n",
    "        df_old_tmp = df_tmp.copy()\n",
    "        # 每个air_store_id 前1周的那天的visitors\n",
    "        df_old_tmp[date_col] = df_tmp[date_col].apply(lambda x: x + timedelta(7)).values\n",
    "        df_old_tmp.rename(columns={'visitors': 'visitors_lastweek'},\n",
    "                          inplace=True)\n",
    "        df_tmp = df_tmp.merge(df_old_tmp[[key, date_col, 'visitors_lastweek']],\n",
    "                              on=[key, date_col],\n",
    "                              how='left')\n",
    "        # 当天visitors - 前1周的那天的visitors\n",
    "        df_tmp['visitors_diff'] = df_tmp['visitors'].values - df_tmp['visitors_lastweek'].values\n",
    "        df_tmp = df_tmp.loc[df_tmp['visitors_diff'].notnull()]\n",
    "\n",
    "        df_tmp['visitors_diff_abs'] = df_tmp['visitors_diff'].map(abs).values\n",
    "\n",
    "        df_grp              = df_tmp.groupby(key) \n",
    "        dic_mean            = df_grp['visitors_diff'].mean().to_dict()\n",
    "        dic_std             = df_grp['visitors_diff'].std().to_dict()\n",
    "        dic_max             = df_grp['visitors_diff'].max().to_dict()\n",
    "        dic_min             = df_grp['visitors_diff'].min().to_dict()\n",
    "        dic_count           = df_grp['visitors_diff'].count().to_dict()\n",
    "        dic_sum             = df_grp['visitors_diff'].sum().to_dict()   \n",
    "        dic_quantile        = df_grp['visitors_diff'].quantile().to_dict()   \n",
    "        dic_abs_mean        = df_grp['visitors_diff_abs'].mean().to_dict()   \n",
    "        \n",
    "        df_features['{}_weekday_quantile_{}_{}'.format(key, i + 1, 'visitorsdiff')]  = df_features[key].map(dic_quantile).values \n",
    "        df_features['{}_weekday_mean_{}_{}'.format(key, i + 1, 'visitorsdiff')]      = df_features[key].map(dic_mean).values \n",
    "        df_features['{}_weekday_std_{}_{}'.format(key, i + 1, 'visitorsdiff')]       = df_features[key].map(dic_std).values \n",
    "        df_features['{}_weekday_max_{}_{}'.format(key, i + 1, 'visitorsdiff')]       = df_features[key].map(dic_max).values \n",
    "        df_features['{}_weekday_min_{}_{}'.format(key, i + 1, 'visitorsdiff')]       = df_features[key].map(dic_min).values \n",
    "        df_features['{}_weekday_count_{}_{}'.format(key, i + 1, 'visitorsdiff')]     = df_features[key].map(dic_count).values \n",
    "        df_features['{}_weekday_sum_{}_{}'.format(key, i + 1, 'visitorsdiff')]       = df_features[key].map(dic_sum).values  \n",
    "        df_features['{}_weekday_absmean_{}_{}'.format(key, i + 1, 'visitorsdiff')]   = df_features[key].map(dic_abs_mean).values  \n",
    "\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_store_id + visitors exp特征(周期特征)\n",
    "加权指数衰减统计特征\n",
    "\n",
    "权重可以表示为店铺的运营的时间信息，所以记录一次即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.008123Z",
     "start_time": "2020-07-10T10:02:34.993162Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_store_id_visitors_exp_features(df, en_date, key='air_store_id', date_col='visit_date', days_list=[1000]): #, 56, 28, 14,\n",
    "    \"\"\"\n",
    "    时间窗口，groupby对象不同，这里用的是key=air_store_id\n",
    "    1. 时间窗口\n",
    "    2. day_lags = visit_date与en_date相差的天数\n",
    "    3. day_lags的权重 = weight ** day_lags\n",
    "    4. visitors_weight = visitors * weight\n",
    "    5. 对weight(加权日期差之和)求和\n",
    "    6. 加权平均每天的visitors\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    df_features       = pd.DataFrame()\n",
    "    df_features[key]  = df[key].unique()\n",
    "\n",
    "    df_tmp            = df.copy()\n",
    "    for weight in [0.9, 0.95, 0.975, 0.985]:\n",
    "        for days in days_list:\n",
    "            st_date            = get_st_date(en_date, days) \n",
    "            df_tmp             = df_tmp.loc[((df[date_col] >= st_date) & (df[date_col] < en_date))].copy()\n",
    "\n",
    "            # en_date与visit_date两个日期相差的天数\n",
    "            df_tmp['day_lags']        = df_tmp['visit_date'].apply(lambda x: (en_date - (x)).days)\n",
    "            # 相差的天数做一个权重，weight ** day_lags\n",
    "            df_tmp['weight']          = df_tmp['day_lags'].apply(lambda x: weight ** x)\n",
    "            # visitors * weight\n",
    "            df_tmp['visitors_weight'] = df_tmp['visitors'] * df_tmp['weight']\n",
    "            \n",
    "            # groupby(air_store_id), 对visitors_weight(加权visitors之和)求和\n",
    "            result1 = df_tmp.groupby([key], as_index=False)['visitors_weight'].agg({\n",
    "                '{}_exp_mean{}_w_{}'.format(key, days, weight): 'sum'\n",
    "            })\n",
    "            \n",
    "            # groupby(air_store_id), 对weight(加权日期差之和)求和\n",
    "            result2 = df_tmp.groupby([key], as_index=False)['weight'].agg({\n",
    "                '{}_exp_weight_sum{}_w_{}'.format(key, days, weight): 'sum'\n",
    "            })\n",
    "\n",
    "            result = result1.merge(result2, on=key, how='left')\n",
    "            # 加权平均每天的visitors\n",
    "            result['{}_exp_mean2{}_w_{}'.format(key, days, weight)] = (result['{}_exp_mean{}_w_{}'.format(key, days, weight)]\n",
    "                                                                       / result['{}_exp_weight_sum{}_w_{}'.format(key, days, weight)])\n",
    "\n",
    "            if weight == 0.9:\n",
    "                df_features = df_features.merge(result[[\n",
    "                    '{}_exp_mean2{}_w_{}'.format(key, days, weight),  # 加权平均每天的visitors\n",
    "                    '{}_exp_weight_sum{}_w_{}'.format(key, days, weight),  # 对weight(加权日期差之和)求和，只需记录一次\n",
    "                    key  # air_store_id\n",
    "                ]], on=key, how='left')\n",
    "            else:\n",
    "                df_features = df_features.merge(result[[\n",
    "                    '{}_exp_mean2{}_w_{}'.format(key, days, weight),  # 加权平均每天的visitors\n",
    "                    key  # air_store_id\n",
    "                ]], on=key, how='left')\n",
    "    print('For store id exp features, we spend {} seconds.'.format(time() - t0)) \n",
    "\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_store_id + weekday + visitors exp特征(7)(周期特征)\n",
    "加权指数衰减(按周进行衰减)统计特征\n",
    "\n",
    "权重可以表示为店铺的运营的时间信息(周)，所以记录一次即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.019094Z",
     "start_time": "2020-07-10T10:02:35.009120Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weekday_visitors_exp_sts_features(df, en_date, key, date_col='visit_date', days_list=[1000]): #, 56, 28, 14,\n",
    "    \"\"\"\n",
    "    时间窗口\n",
    "    1. 时间窗口\n",
    "    2. day_lags = (visit_date与en_date相差的天数) // 7\n",
    "    3. weight = weight ** day_lags\n",
    "    4. visitors_weight = visitors * weight\n",
    "    5. visitors_weight求和\n",
    "    6. weight求和\n",
    "    7. 加权平均每天的visitors\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    df_features       = pd.DataFrame()\n",
    "    df_features[key]  = df[key].unique()\n",
    "    \n",
    "    df_tmp            = df.copy()\n",
    "    for weight in [0.95, 0.975, 0.985]:   \n",
    "        for days in days_list:\n",
    "            # 时间窗口\n",
    "            st_date            = get_st_date(en_date, days) \n",
    "            df_tmp             = df_tmp.loc[((df[date_col] >= st_date) & (df[date_col] < en_date))].copy()\n",
    "\n",
    "            # day_lags = (en_date - visit_date) / 7\n",
    "            df_tmp['day_lags']        = df_tmp['visit_date'].apply(lambda x: (en_date - (x)).days // 7)\n",
    "            # day_lags加权\n",
    "            df_tmp['weight']          = df_tmp['day_lags'].apply(lambda x: weight ** x)\n",
    "            # visitors_weight = visitors * weight\n",
    "            df_tmp['visitors_weight'] = df_tmp['visitors'] * df_tmp['weight']\n",
    "            \n",
    "            # visitors_weight求和\n",
    "            result1 = df_tmp.groupby([key], as_index=False)['visitors_weight'].agg({\n",
    "                '{}_exp_mean{}_{}'.format(key, days, weight): 'sum'\n",
    "            })\n",
    "            # weight求和\n",
    "            result2 = df_tmp.groupby([key], as_index=False)['weight'].agg({\n",
    "                '{}_exp_weight_sum{}_{}'.format(key,days,weight): 'sum'\n",
    "            })\n",
    "\n",
    "            result = result1.merge(result2, on=key, how='left')\n",
    "            \n",
    "            # 加权平均每天的visitors\n",
    "            result['{}_exp_mean2{}_{}'.format(key,days,weight)] = (result['{}_exp_mean{}_{}'.format(key,days,weight)]\n",
    "                                                                   / result['{}_exp_weight_sum{}_{}'.format(key,days,weight)])\n",
    "            \n",
    "            df_features = df_features.merge(result, on=key, how='left')\n",
    "    print('For store id exp features, we spend {} seconds.'.format(time() - t0)) \n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_store_id + holiday +visitors特征\n",
    "过去每个节假日的的统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.030063Z",
     "start_time": "2020-07-10T10:02:35.020093Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_holiday_visitors_sts_features(df, key, end_date, date_col='visit_date', val_name='visitors'): \n",
    "    \"\"\"\n",
    "    时间窗口，groupby('air_store_id_holiday')\n",
    "    时间窗口内的统计量\n",
    "    \"\"\"\n",
    "    df_features      = pd.DataFrame() \n",
    "    df_features[key] = df[key].unique() \n",
    "    ind1    = df[date_col] < end_date  \n",
    "    for i in [4, 8, 12, 100]: \n",
    "        # 时间窗口，前4、8、12、100周\n",
    "        t_st_date           = end_date - timedelta(7 * i) \n",
    "        ind2                = df[date_col]  >= t_st_date \n",
    "        df_grp              = df.loc[(ind1 & ind2)].groupby(key) \n",
    "        \n",
    "        # 统计量\n",
    "        dic_mean            = df_grp[val_name].mean().to_dict()\n",
    "        dic_std             = df_grp[val_name].std().to_dict()\n",
    "        dic_max             = df_grp[val_name].max().to_dict()\n",
    "        dic_min             = df_grp[val_name].min().to_dict()\n",
    "        dic_count           = df_grp[val_name].count().to_dict()\n",
    "        dic_sum             = df_grp[val_name].sum().to_dict()   \n",
    "        df_features['{}_holiday_mean_{}_{}'.format(key, i + 1, val_name)]  = df_features[key].map(dic_mean).values \n",
    "        df_features['{}_holiday_std_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_std).values \n",
    "        df_features['{}_holiday_max_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_max).values \n",
    "        df_features['{}_holiday_min_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_min).values \n",
    "        df_features['{}_holiday_count_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_count).values \n",
    "        df_features['{}_holiday_sum_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_sum).values  \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_store_id + weekday + holiday +visitors特征\n",
    "过去每个节假日与工作日的交叉统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.042030Z",
     "start_time": "2020-07-10T10:02:35.031060Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weekday_holiday_visitors_sts_features(df, key, end_date, date_col='visit_date', val_name='visitors'): \n",
    "    \"\"\"\n",
    "    时间窗口，groupby(air_store_id_weekday_holiday)\n",
    "    窗口内的统计量\n",
    "    \"\"\"\n",
    "    df_features      = pd.DataFrame() \n",
    "    df_features[key] = df[key].unique() \n",
    "    ind1    = df[date_col] < end_date  \n",
    "    for i in [4, 8, 12, 100]: \n",
    "        t_st_date           = end_date - timedelta(7 * i) \n",
    "        ind2                = df[date_col] >= t_st_date \n",
    "        df_grp              = df.loc[(ind1 & ind2)].groupby(key) \n",
    "        dic_mean            = df_grp[val_name].mean().to_dict()\n",
    "        dic_std             = df_grp[val_name].std().to_dict()\n",
    "        dic_max             = df_grp[val_name].max().to_dict()\n",
    "        dic_min             = df_grp[val_name].min().to_dict()\n",
    "        dic_quantile        = df_grp[val_name].quantile().to_dict()\n",
    "        # dic_count           = df_grp[val_name].count().to_dict()\n",
    "        dic_sum             = df_grp[val_name].sum().to_dict()   \n",
    "        df_features['{}_weekday_holiday_mean_{}_{}'.format(key, i + 1, val_name)]       = df_features[key].map(dic_mean).values \n",
    "        df_features['{}_weekday_holiday_std_{}_{}'.format(key, i + 1, val_name)]        = df_features[key].map(dic_std).values \n",
    "        df_features['{}_weekday_holiday_max_{}_{}'.format(key, i + 1, val_name)]        = df_features[key].map(dic_max).values \n",
    "        df_features['{}_weekday_holiday_min_{}_{}'.format(key, i + 1, val_name)]        = df_features[key].map(dic_min).values \n",
    "        # df_features['{}_weekday_holiday_count_{}_{}'.format(key, i + 1, val_name)]    = df_features[key].map(dic_count).values \n",
    "        df_features['{}_weekday_holiday_sum_{}_{}'.format(key, i + 1, val_name)]        = df_features[key].map(dic_sum).values  \n",
    "        df_features['{}_weekday_holiday_quantile_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_quantile).values  \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_store_id + timediff\n",
    "过去每个商店关于时间的差值统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.052005Z",
     "start_time": "2020-07-10T10:02:35.043030Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_store_id_time_diff_sts_features(df, en_date, key='air_store_id', date_col='visit_date', days_list=[1000, 56, 28]): #, 14,\n",
    "    \"\"\"\n",
    "    时间窗口，时间差\n",
    "    1. 时间窗口\n",
    "    2. 窗口内visit_date的diff\n",
    "    3. diff的统计量\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    df_features       = pd.DataFrame()\n",
    "    df_features[key]  = df[key].unique()\n",
    "    df = df.sort_values([key, date_col])\n",
    "    for days in days_list:    \n",
    "        df_tmp                = df.copy()       \n",
    "        # 时间窗口\n",
    "        st_date               = get_st_date(en_date, days) \n",
    "        df_tmp                = df_tmp.loc[((df[date_col] >= st_date) & (df[date_col] < en_date))].copy()\n",
    "        \n",
    "        # 根据值排序\n",
    "        df_tmp                = df_tmp.sort_values([key, date_col])\n",
    "        # 当前项减前一项\n",
    "        df_tmp['time_diff']   = df_tmp.groupby(key)[date_col].diff().values\n",
    "        df_tmp['time_diff']   = df_tmp['time_diff'].apply(lambda x: x.days) \n",
    "        \n",
    "        df_tmp                = df_tmp.loc[df_tmp['time_diff'].notnull()] \n",
    "        # 统计量\n",
    "        df_features_tmp   = df_tmp.groupby([key], as_index=False)['time_diff'].agg({\n",
    "            '{}_time_diff_min{}'.format(key,days): 'min',\n",
    "            '{}_time_diff_mean{}'.format(key,days): 'mean',\n",
    "            '{}_time_diff_median{}'.format(key,days): 'median',\n",
    "            '{}_time_diff_max{}'.format(key,days): 'max',\n",
    "            '{}_time_diff_std{}'.format(key,days): 'std',\n",
    "            '{}_time_diff_quantile{}'.format(key,days): 'quantile',\n",
    "            '{}_time_diff_skew{}'.format(key,days): 'skew'\n",
    "        }) \n",
    "        df_features  = df_features.merge(df_features_tmp, on=key, how='left')\n",
    "    print('For store id diff sts features, we spend {} seconds.'.format(time() - t0)) \n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程2（reserve相关特征）\n",
    "####  air_store_id + visit_date + timediff & reserve_visitors特征\n",
    "每天的预定的统计信息,包括预定人数以及时间差的统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.067999Z",
     "start_time": "2020-07-10T10:02:35.053002Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_store_date_reserve_features(df_air_reserves, df_hpg_reserves, en_date, days, key='air_store_id_visit_date'):\n",
    "    \"\"\"\n",
    "    时间窗口，预定信息相关特征，分为air系统和hpg系统\n",
    "    1. 时间窗口\n",
    "    2. 预定入店日期与预定日期相差的天数，相差天数的统计量\n",
    "    3. 预定人数的统计量\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    st_date, en_date = get_label_st_date(en_date, days)\n",
    "    \n",
    "    # 时间窗口\n",
    "    # st_date <= 预定入店时间 < en_date and 预定时间 < st_date\n",
    "    df_air_reserve = df_air_reserves.loc[((df_air_reserves['visit_datetime'] < en_date)\n",
    "                                          & (df_air_reserves['visit_datetime'] >= st_date)\n",
    "                                          & (df_air_reserves['reserve_datetime'] < st_date))].copy()\n",
    "    \n",
    "    df_hpg_reserve = df_hpg_reserves.loc[((df_hpg_reserves['visit_datetime'] < en_date)\n",
    "                                          & (df_hpg_reserves['visit_datetime'] >= st_date)\n",
    "                                          & (df_hpg_reserves['reserve_datetime'] < st_date))].copy()\n",
    "    \n",
    "    df_features       = pd.DataFrame()\n",
    "    df_features[key]  = df_air_reserve[key].unique()  \n",
    "    \n",
    "    # air系统\n",
    "    try:  \n",
    "        # 预定入店日期与预定日期相差的天数\n",
    "        df_air_reserve['time_diff'] = df_air_reserve['visit_datetime'] - df_air_reserve['reserve_datetime']\n",
    "        df_air_reserve['time_diff'] = df_air_reserve['time_diff'].apply(lambda x: x.days).values\n",
    "        \n",
    "        # time_diff的统计量\n",
    "        df_air_timediff_fea = df_air_reserve.groupby(key, as_index=False)['time_diff'].agg({\n",
    "            'store_air_timediff_mean': 'mean',\n",
    "            'store_air_timediff_median': 'median',\n",
    "            'store_air_timediff_max': 'max',\n",
    "            'store_air_timediff_std': 'std'\n",
    "        }) \n",
    "        \n",
    "        # reserve_visitors的统计量\n",
    "        df_air_reserve_fea = df_air_reserve.groupby(['air_store_id', 'visit_date'])['reserve_visitors'].agg({\n",
    "            'store_air_reserve_visitors_sum': 'sum',\n",
    "            'store_air_reserve_visitors_mean': 'mean',\n",
    "            # 'store_air_reserve_visitors_std': 'std',\n",
    "            'store_air_reserve_visitors_max': 'max',\n",
    "            'store_air_reserve_visitors_count': 'count',\n",
    "        }) \n",
    "\n",
    "        df_air_reserve_fea          = df_air_reserve_fea.unstack().fillna(0).stack().reset_index()    \n",
    "        df_air_reserve_fea[key]     = df_air_reserve_fea['air_store_id'].astype(str) + '_' + df_air_reserve_fea['visit_date'].astype(str)\n",
    "        del df_air_reserve_fea['air_store_id']\n",
    "        del df_air_reserve_fea['visit_date']\n",
    "        df_features = df_features.merge(df_air_timediff_fea, on=key, how='left')\n",
    "        df_features = df_features.merge(df_air_reserve_fea,  on=key, how='left')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # hpg系统\n",
    "    try:\n",
    "        df_hpg_reserve['time_diff'] = df_hpg_reserve['visit_datetime'] - df_hpg_reserve['reserve_datetime']\n",
    "        df_hpg_reserve['time_diff'] = df_hpg_reserve['time_diff'].apply(lambda x: x.days).values\n",
    "        \n",
    "        df_hpg_timediff_fea = df_hpg_reserve.groupby(key, as_index=False)['time_diff'].agg({\n",
    "            'store_hpg_timediff_mean': 'mean',\n",
    "            'store_hpg_timediff_median': 'median',\n",
    "            'store_hpg_timediff_max': 'max',\n",
    "            'store_hpg_timediff_std': 'std',\n",
    "        }) \n",
    "\n",
    "        df_hpg_reserve_fea = df_hpg_reserve.groupby(['air_store_id', 'visit_date'])['reserve_visitors'].agg({\n",
    "            'store_hpg_reserve_visitors_sum': 'sum',\n",
    "            'store_hpg_reserve_visitors_mean': 'mean',\n",
    "            # 'store_hpg_reserve_visitors_std': 'std',\n",
    "            'store_hpg_reserve_visitors_max': 'max',\n",
    "            'store_hpg_reserve_visitors_count': 'count',\n",
    "        }) \n",
    "\n",
    "        df_hpg_reserve_fea = df_hpg_reserve_fea.unstack().fillna(0).stack().reset_index()    \n",
    "        df_hpg_reserve_fea[key] = df_hpg_reserve_fea['air_store_id'].astype(str) + '_' + df_hpg_reserve_fea['visit_date'].astype(str)\n",
    "        del df_hpg_reserve_fea['air_store_id']\n",
    "        del df_hpg_reserve_fea['visit_date']\n",
    "        df_features = df_features.merge(df_hpg_timediff_fea, on=key, how='left')\n",
    "        df_features = df_features.merge(df_hpg_reserve_fea, on=key, how='left')\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print('For store id reserve visitors features, we spend {} seconds.'.format(time() - t0)) \n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_store_id + timediff & reserve_visitors特征\n",
    "整体的预定统计信息,包括预定人数以及时间差的统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.081956Z",
     "start_time": "2020-07-10T10:02:35.068959Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_store_reserve_features(df_air_reserves, df_hpg_reserves, en_date, days, key='air_store_id'):\n",
    "    \"\"\"\n",
    "    时间窗口，预定信息相关特征，分为air系统和hpg系统\n",
    "    与上面不同的是groupby对象不同，这里groupby('air_store_id')，上面groupby('air_store_id_visit_date')\n",
    "    1. 时间窗口\n",
    "    2. 预定入店日期与预定日期相差的天数，相差天数的统计量\n",
    "    3. 预定人数的统计量\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    \n",
    "    st_date,en_date = get_label_st_date(en_date, days) \n",
    "   \n",
    "    df_air_reserve  = df_air_reserves.loc[((df_air_reserves['visit_datetime']   < en_date)\n",
    "                                           & (df_air_reserves['visit_datetime']   >= st_date)\n",
    "                                           & (df_air_reserves['reserve_datetime'] < st_date))].copy()\n",
    "    df_hpg_reserve  = df_hpg_reserves.loc[((df_hpg_reserves['visit_datetime']   < en_date)\n",
    "                                           & (df_hpg_reserves['visit_datetime']   >= st_date)\n",
    "                                           & (df_hpg_reserves['reserve_datetime'] < st_date))].copy()\n",
    "    \n",
    "    \n",
    "    df_features       = pd.DataFrame()\n",
    "    df_features[key]  = df_air_reserve[key].unique()\n",
    "    \n",
    "    df_air_reserve['time_diff']   = df_air_reserve['visit_datetime'] - df_air_reserve['reserve_datetime']\n",
    "    df_air_reserve['time_diff']   = df_air_reserve['time_diff'].apply(lambda x: x.days)\n",
    "    \n",
    "    df_hpg_reserve['time_diff']   = df_hpg_reserve['visit_datetime'] - df_hpg_reserve['reserve_datetime']\n",
    "    df_hpg_reserve['time_diff']   = df_hpg_reserve['time_diff'].apply(lambda x: x.days)\n",
    "    \n",
    "    try:\n",
    "        df_air_timediff_fea = df_air_reserve.groupby(key, as_index=False)['time_diff'].agg({\n",
    "            'store2_air_timediff_mean': 'mean',\n",
    "            'store2_air_timediff_median': 'median',\n",
    "            'store2_air_timediff_max': 'max',\n",
    "            'store2_air_timediff_count': 'count',\n",
    "            'store2_air_timediff_std': 'std',\n",
    "        }) \n",
    "\n",
    "        df_air_reserve_fea = df_air_reserve.groupby(key, as_index=False)['reserve_visitors'].agg({\n",
    "            'store2_air_reserve_visitors_sum': 'sum',\n",
    "            'store2_air_reserve_visitors_median': 'median',\n",
    "            'store2_air_reserve_visitors_mean': 'mean',\n",
    "            'store2_air_reserve_visitors_max': 'max',\n",
    "            'store2_air_reserve_visitors_count': 'count',\n",
    "            'store2_air_reserve_visitors_std': 'std',\n",
    "        }) \n",
    "        df_features = df_features.merge(df_air_timediff_fea, on=key, how='left')\n",
    "        df_features = df_features.merge(df_air_reserve_fea, on=key, how='left')\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        df_hpg_timediff_fea = df_hpg_reserve.groupby(key, as_index = False)['time_diff'].agg({\n",
    "            'store2_hpg_timediff_mean': 'mean',\n",
    "            'store2_hpg_timediff_median': 'median',\n",
    "            'store2_hpg_timediff_max': 'max',\n",
    "            'store2_hpg_timediff_count': 'count',\n",
    "            'store2_hpg_timediff_skew': 'skew',\n",
    "            'store2_hpg_timediff_std': 'std',\n",
    "        }) \n",
    "\n",
    "        df_hpg_reserve_fea = df_hpg_reserve.groupby(key, as_index = False)['reserve_visitors'].agg({\n",
    "            'store2_hpg_reserve_visitors_sum': 'sum',\n",
    "            'store2_hpg_reserve_visitors_mean': 'mean',\n",
    "            'store2_hpg_reserve_visitors_median': 'median',\n",
    "            'store2_hpg_reserve_visitors_max': 'max',\n",
    "            'store2_hpg_reserve_visitors_count': 'count',\n",
    "            'store2_hpg_reserve_visitors_std': 'std',\n",
    "        }) \n",
    "    \n",
    "        df_features = df_features.merge(df_hpg_timediff_fea, on=key, how='left')\n",
    "        df_features = df_features.merge(df_hpg_reserve_fea,  on=key, how='left')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print('For store id reserve visitors features, we spend {} seconds.'.format(time() - t0)) \n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visit_date + timediff & reserve_visitors特征\n",
    "每个时间段的统计信息,包括预定人数以及时间差的统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T14:44:10.402616Z",
     "start_time": "2020-07-11T14:44:10.377614Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_date_reserve_features(df_air_reserves, df_hpg_reserves, en_date, days, key='visit_date'):\n",
    "    \"\"\"\n",
    "    时间窗口，预定信息相关特征，分为air系统和hpg系统\n",
    "    groupby('visit_date')\n",
    "    1. 时间窗口\n",
    "    2. 预定入店日期与预定日期相差的天数，相差天数的统计量\n",
    "    3. 预定人数的统计量\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    st_date,en_date = get_label_st_date(en_date, days) \n",
    "\n",
    "    df_air_reserve  = df_air_reserves.loc[((df_air_reserves['visit_datetime'] < en_date)\n",
    "                                           & (df_air_reserves['visit_datetime'] >= st_date)\n",
    "                                           & (df_air_reserves['reserve_datetime'] < st_date))].copy()\n",
    "    \n",
    "    df_hpg_reserve  = df_hpg_reserves.loc[((df_hpg_reserves['visit_datetime'] < en_date)\n",
    "                                           & (df_hpg_reserves['visit_datetime'] >= st_date)\n",
    "                                           & (df_hpg_reserves['reserve_datetime'] < st_date))].copy()\n",
    "    \n",
    "    \n",
    "    df_features       = pd.DataFrame()\n",
    "    df_features[key]  = df_air_reserve[key].unique()\n",
    "    \n",
    "    df_air_reserve['time_diff'] = df_air_reserve['visit_datetime'] - df_air_reserve['reserve_datetime']\n",
    "    df_air_reserve['time_diff'] = df_air_reserve['time_diff'].apply(lambda x: x.days)\n",
    "    \n",
    "    df_hpg_reserve['time_diff'] = df_hpg_reserve['visit_datetime'] - df_hpg_reserve['reserve_datetime']\n",
    "    df_hpg_reserve['time_diff'] = df_hpg_reserve['time_diff'].apply(lambda x: x.days)\n",
    "    try:\n",
    "        df_air_timediff_fea = df_air_reserve.groupby(key, as_index=False)['time_diff'].agg({\n",
    "            'date_air_timediff_mean': 'mean',\n",
    "            'date_air_timediff_median': 'median',\n",
    "            'date_air_timediff_max': 'max',\n",
    "            'date_air_timediff_count': 'count',\n",
    "            'date_air_timediff_std': 'std',\n",
    "        }) \n",
    "\n",
    "        df_air_reserve_fea = df_air_reserve.groupby(key, as_index=False)['reserve_visitors'].agg({\n",
    "            'date_air_reserve_visitors_sum': 'sum',\n",
    "            'date_air_reserve_visitors_median': 'median',\n",
    "            'date_air_reserve_visitors_max': 'max',\n",
    "            'date_air_reserve_visitors_count': 'count',\n",
    "            'date_air_reserve_visitors_std': 'std',\n",
    "        }) \n",
    "        df_features = df_features.merge(df_air_timediff_fea, on=key, how='left')\n",
    "        df_features = df_features.merge(df_air_reserve_fea,  on=key, how='left')\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_hpg_timediff_fea = df_hpg_reserve.groupby(key, as_index=False)['time_diff'].agg({\n",
    "            'date_hpg_timediff_mean': 'mean',\n",
    "            'date_hpg_timediff_max': 'max',\n",
    "        }) \n",
    "\n",
    "        df_hpg_reserve_fea = df_hpg_reserve.groupby(key, as_index=False)['reserve_visitors'].agg({\n",
    "            'date_hpg_reserve_visitors_sum': 'sum',\n",
    "            'date_hpg_reserve_visitors_median': 'median',\n",
    "            'date_hpg_reserve_visitors_max': 'max',\n",
    "            'date_hpg_reserve_visitors_count': 'count',\n",
    "        }) \n",
    "    \n",
    "        df_features = df_features.merge(df_hpg_timediff_fea, on=key, how='left')\n",
    "        df_features = df_features.merge(df_hpg_reserve_fea,  on=key, how='left')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print('For store id reserve visitors features, we spend {} seconds.'.format(time() - t0)) \n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程3：基于其他属性的特征，例如air_genre_name\n",
    "#### air_genre_name + visitors特征\n",
    "最近N(N=14,28,56,1000)天air_genre_name的统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.104904Z",
     "start_time": "2020-07-10T10:02:35.095886Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_genre_visitors_features(df, en_date, key='air_genre_name', date_col='visit_date', days_list=[1000, 56, 28]): #, 14,\n",
    "    \"\"\"\n",
    "    时间窗口，groupby('air_genre_name')\n",
    "    1. 时间窗口，st_date <= visit_date < en_date\n",
    "    2. groupby('air_genre_name')，visitors的统计量\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    df_features       = pd.DataFrame()\n",
    "    df_features[key]  = df[key].unique()\n",
    "    \n",
    "    df_tmp            = df.copy()\n",
    "    for days in days_list:\n",
    "        st_date           = get_st_date(en_date, days) \n",
    "        df_tmp            = df_tmp.loc[((df[date_col] >= st_date) & (df[date_col] < en_date))].copy()\n",
    "        df_features_tmp   = df_tmp.groupby([key], as_index=False)['visitors'].agg({\n",
    "            '{}_visitors_min{}'.format(key,days): 'min',\n",
    "            '{}_visitors_mean{}'.format(key,days): 'mean',\n",
    "            '{}_visitors_median{}'.format(key,days): 'median',\n",
    "            '{}_visitors_max{}'.format(key,days): 'max',\n",
    "            '{}_visitors_sum{}'.format(key,days): 'sum',\n",
    "            '{}_visitors_std{}'.format(key,days): 'std',\n",
    "            '{}_visitors_quantile{}'.format(key,days): 'quantile',\n",
    "            '{}_visitors_skew{}'.format(key,days): 'skew'\n",
    "        }) \n",
    "        df_features  = df_features.merge(df_features_tmp, on=key, how='left')\n",
    "    print('For area sts features, we spend {} seconds.'.format(time() - t0)) \n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_genre_name + weekday + visitors特征\n",
    "过去每段时间的工作日的统计特征天air_genre_name对应的统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.116861Z",
     "start_time": "2020-07-10T10:02:35.105860Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_genre_weekday_visitors_sts_features(df, end_date, key='air_genre_name_weekday', date_col='visit_date', val_name='visitors'): \n",
    "    \"\"\"\n",
    "    时间窗口，groupby('air_genre_name_weekday')\n",
    "    1. 时间窗口，end_date的前4、8、12、100周\n",
    "    2. groupby('air_genre_name_weekday')的统计量\n",
    "    \"\"\"\n",
    "    df_features      = pd.DataFrame() \n",
    "    df_features[key] = df[key].unique()\n",
    "    t0 = time()\n",
    "    ind1 = df[date_col] < end_date  \n",
    "    \n",
    "    for i in [4, 8, 12, 100]:  #2,6\n",
    "        t_st_date    = end_date  - timedelta(7 * i) \n",
    "        ind2         = df[date_col]  >= t_st_date \n",
    "        df_grp       = df.loc[(ind1 & ind2)].groupby(key) \n",
    "        \n",
    "        dic_mean     = df_grp[val_name].mean().to_dict()\n",
    "        dic_std      = df_grp[val_name].std().to_dict()\n",
    "        dic_max      = df_grp[val_name].max().to_dict()\n",
    "        dic_min      = df_grp[val_name].min().to_dict()\n",
    "        dic_count    = df_grp[val_name].count().to_dict()\n",
    "        dic_sum      = df_grp[val_name].sum().to_dict()   \n",
    "        dic_quantile = df_grp[val_name].quantile().to_dict()   \n",
    "        \n",
    "        df_features['{}_mean_{}_{}'.format(key, i + 1, val_name)]  = df_features[key].map(dic_mean).values \n",
    "        df_features['{}_quantile_{}_{}'.format(key, i + 1, val_name)]  = df_features[key].map(dic_quantile).values \n",
    "        df_features['{}_std_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_std).values \n",
    "        df_features['{}_max_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_max).values \n",
    "        df_features['{}_min_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_min).values \n",
    "        df_features['{}_gap_{}_{}'.format(key, i + 1, val_name)]   = (df_features['{}_max_{}_{}'.format(key, i + 1, val_name)]\n",
    "                                                                      - df_features['{}_min_{}_{}'.format(key, i+1, val_name)])\n",
    "        df_features['{}_count_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_count).values \n",
    "        df_features['{}_sum_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_sum).values  \n",
    "    print('For area name sts features, we spend {} seconds.'.format(time() - t0)) \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### air_area_name + weekday + holiday + visitors特征\n",
    "最近N(N=14,28,56,1000)天air_area_name+weekday以及holiday的统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.130795Z",
     "start_time": "2020-07-10T10:02:35.117830Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_genre_weekday_holiday_visitors_sts_features(df, end_date, key='air_genre_name_weekday_holiday', date_col='visit_date', val_name='visitors'):\n",
    "    \"\"\"\n",
    "    时间窗口，groupby('air_genre_name_weekday_holiday')\n",
    "    1. 时间窗口，end_date的前4、8、12、100周\n",
    "    2. groupby('air_genre_name_weekday')的统计量\n",
    "    \"\"\"\n",
    "    df_features      = pd.DataFrame() \n",
    "    df_features[key] = df[key].unique()\n",
    "    t0 = time()\n",
    "    ind1    = df[date_col] < end_date  \n",
    "    for i in [4, 8, 12, 100]:  #2,6\n",
    "        t_st_date    = end_date  - timedelta(7 * i) \n",
    "        ind2         = df[date_col]  >= t_st_date \n",
    "        df_grp       = df.loc[(ind1 & ind2)].groupby(key) \n",
    "        \n",
    "        dic_mean     = df_grp[val_name].mean().to_dict()\n",
    "        dic_std      = df_grp[val_name].std().to_dict()\n",
    "        dic_max      = df_grp[val_name].max().to_dict()\n",
    "        dic_min      = df_grp[val_name].min().to_dict()\n",
    "        dic_count    = df_grp[val_name].count().to_dict()\n",
    "        dic_sum      = df_grp[val_name].sum().to_dict()   \n",
    "        dic_quantile = df_grp[val_name].quantile().to_dict()   \n",
    "          \n",
    "        df_features['{}_mean_{}_{}'.format(key, i + 1, val_name)]  = df_features[key].map(dic_mean).values \n",
    "        df_features['{}_quantile_{}_{}'.format(key, i + 1, val_name)]  = df_features[key].map(dic_quantile).values \n",
    "        df_features['{}_std_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_std).values \n",
    "        df_features['{}_max_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_max).values \n",
    "        df_features['{}_min_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_min).values \n",
    "        df_features['{}_gap_{}_{}'.format(key, i + 1, val_name)]   = (df_features['{}_max_{}_{}'.format(key, i+1, val_name)]\n",
    "                                                                    - df_features['{}_min_{}_{}'.format(key, i+1, val_name)])\n",
    "        df_features['{}_count_{}_{}'.format(key, i + 1, val_name)] = df_features[key].map(dic_count).values \n",
    "        df_features['{}_sum_{}_{}'.format(key, i + 1, val_name)]   = df_features[key].map(dic_sum).values  \n",
    "    print('For area name sts features, we spend {} seconds.'.format(time() - t0)) \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.148748Z",
     "start_time": "2020-07-10T10:02:35.131791Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_features(df_visitors, air_reserve, hpg_air_reserve, label_st_date, days=39, is_te=False):\n",
    "     \n",
    "    df_label = get_df_label(df_visitors, label_st_date, days, is_te) \n",
    "    df_label['visit_date']                   = pd.to_datetime(df_label['visit_date'])\n",
    "    df_label['weekday']                      = df_label['visit_date'].dt.weekday  \n",
    "    df_label['air_store_id_weekday']         = df_label['air_store_id'].astype(str) + '_' + df_label['weekday'].astype(str) \n",
    "    df_label['air_store_id_weekday_holiday'] = df_label['air_store_id_holiday'] + '_' + df_label['weekday'].astype(str) \n",
    "    \n",
    "    df_label['air_store_id_visit_date']  = df_label['air_store_id']  + '_' + df_label['visit_date'].astype(str)\n",
    "    \n",
    "    ####################\n",
    "    # 以下特征只是groupby对象不同\n",
    "    df_genre_visitors_fea             = get_genre_visitors_features(df=df_visitors,\n",
    "                                                                    key='air_genre_name',\n",
    "                                                                    en_date=label_st_date,\n",
    "                                                                    date_col='visit_date')\n",
    "    df_genre_dow_visitors_fea         = get_genre_weekday_visitors_sts_features(df=df_visitors,\n",
    "                                                                                key='air_genre_name_weekday',\n",
    "                                                                                end_date=label_st_date,\n",
    "                                                                                date_col='visit_date',\n",
    "                                                                                val_name='visitors')\n",
    "    df_genre_dow_holiday_visitors_fea = get_genre_weekday_holiday_visitors_sts_features(df=df_visitors,\n",
    "                                                                                        key='air_genre_name_weekday_holiday',\n",
    "                                                                                        end_date=label_st_date,\n",
    "                                                                                        date_col='visit_date',\n",
    "                                                                                        val_name='visitors')\n",
    "    \n",
    "    ####################\n",
    "    # 以下特征只是groupby对象不同\n",
    "    df_air_hpg_features  = get_store_date_reserve_features(df_air_reserves=air_reserve,\n",
    "                                                           df_hpg_reserves=hpg_air_reserve,\n",
    "                                                           en_date=label_st_date,\n",
    "                                                           days=days) \n",
    "    df_air_hpg_features2 = get_store_reserve_features(df_air_reserves=air_reserve,\n",
    "                                                      df_hpg_reserves=hpg_air_reserve,\n",
    "                                                      en_date=label_st_date,\n",
    "                                                      days=days) \n",
    "    df_air_hpg_features3 = get_date_reserve_features(df_air_reserves=air_reserve,\n",
    "                                                     df_hpg_reserves=hpg_air_reserve,\n",
    "                                                     en_date=label_st_date,\n",
    "                                                     days=days) \n",
    "    \n",
    "    ##################\n",
    "    # 店铺在时间窗口内每天的visitors的统计量\n",
    "    df_storeid_visitors_fea         = get_store_id_visitors_sts_features(df=df_visitors,\n",
    "                                                                         key='air_store_id',\n",
    "                                                                         en_date=label_st_date)\n",
    "    \n",
    "    # 店铺在时间窗口内的time_diff的统计量\n",
    "    df_storeid_timediff_fea         = get_store_id_time_diff_sts_features(df=df_visitors,\n",
    "                                                                          key='air_store_id',\n",
    "                                                                          en_date=label_st_date)\n",
    "    \n",
    "    # (当天的visitors - 昨天的visitors)的统计量\n",
    "    df_storeid_visitorsdiff_fea     = get_store_id_visitors_diff_sts_features(df=df_visitors,\n",
    "                                                                              key='air_store_id',\n",
    "                                                                              en_date=label_st_date)\n",
    "    # 加权平均每天的visitors\n",
    "    df_storeid_visitorsexp_fea      = get_store_id_visitors_exp_features(df=df_visitors,\n",
    "                                                                         key='air_store_id',\n",
    "                                                                         en_date=label_st_date)\n",
    "    \n",
    "    # 店铺在时间窗口内每周几的visitors的统计量\n",
    "    df_storeid_dow_visitors_fea     = get_weekday_visitors_sts_features(df=df_visitors,\n",
    "                                                                        key='air_store_id_weekday',\n",
    "                                                                        end_date=label_st_date,\n",
    "                                                                        date_col='visit_date',\n",
    "                                                                        val_name='visitors')\n",
    "    # (当天的visitors - 一周前那天的visitors)的统计量\n",
    "    df_storeid_dow_visitorsdiff_fea = get_weekday_visitors_diff_sts_features(df=df_visitors,\n",
    "                                                                             key='air_store_id_weekday',\n",
    "                                                                             end_date=label_st_date,\n",
    "                                                                             date_col='visit_date',\n",
    "                                                                             val_name='visitors')\n",
    "    # day_lags / 7，加权平均每天的visitors\n",
    "    df_storeid_dow_visitorsexp_fea  = get_weekday_visitors_exp_sts_features(df=df_visitors,\n",
    "                                                                            key='air_store_id_weekday',\n",
    "                                                                            en_date=label_st_date,\n",
    "                                                                            date_col='visit_date')\n",
    "     \n",
    "    # groupby('air_store_id_holiday') visitors的统计量\n",
    "    df_storeid_holiday_visitors_fea = get_holiday_visitors_sts_features(df=df_visitors,\n",
    "                                                                        key='air_store_id_holiday',\n",
    "                                                                        end_date=label_st_date,\n",
    "                                                                        date_col='visit_date',\n",
    "                                                                        val_name='visitors')\n",
    "    \n",
    "    # groupby('air_store_id_weekday_holiday') visitors的统计量\n",
    "    df_storeid_dow_holiday_visitorsdiff_fea = get_weekday_holiday_visitors_sts_features(df=df_visitors,\n",
    "                                                                                        key='air_store_id_weekday_holiday',\n",
    "                                                                                        end_date=label_st_date,\n",
    "                                                                                        date_col='visit_date',\n",
    "                                                                                        val_name='visitors')\n",
    "     \n",
    "    df_features             = df_label.merge(df_storeid_visitors_fea,            on=['air_store_id'], how='left')\n",
    "    df_features             = df_features.merge(df_storeid_timediff_fea,         on=['air_store_id'], how='left')   \n",
    "    df_features             = df_features.merge(df_storeid_visitorsdiff_fea,     on=['air_store_id'], how='left')  \n",
    "    df_features             = df_features.merge(df_storeid_visitorsexp_fea,      on=['air_store_id'], how='left')  \n",
    "    \n",
    "    df_features             = df_features.merge(df_storeid_dow_visitors_fea,     on=['air_store_id_weekday'], how='left')  \n",
    "    df_features             = df_features.merge(df_storeid_dow_visitorsdiff_fea, on=['air_store_id_weekday'], how='left')  \n",
    "    df_features             = df_features.merge(df_storeid_dow_visitorsexp_fea,  on=['air_store_id_weekday'], how='left')   \n",
    "     \n",
    "    \n",
    "    df_features             = df_features.merge(df_air_hpg_features,  on=['air_store_id_visit_date'], how='left')\n",
    "    df_features             = df_features.merge(df_air_hpg_features2, on=['air_store_id'], how='left') \n",
    "    df_features['visit_date']          = df_features['visit_date'].astype(str)\n",
    "    df_air_hpg_features3['visit_date'] = df_air_hpg_features3['visit_date'].astype(str)  \n",
    "    df_features             = df_features.merge(df_air_hpg_features3, on=['visit_date'], how='left') \n",
    "    \n",
    "    df_features             = df_features.merge(df_storeid_holiday_visitors_fea, on=['air_store_id_holiday'], how='left')  \n",
    "    df_features             = df_features.merge(df_storeid_dow_holiday_visitorsdiff_fea, on=['air_store_id_weekday_holiday'], how='left')  \n",
    "    \n",
    "    df_features             = df_features.merge(df_genre_visitors_fea, on=['air_genre_name'], how='left')   \n",
    "    df_features             = df_features.merge(df_genre_dow_visitors_fea, on=['air_genre_name_weekday'], how='left')  \n",
    "    df_features             = df_features.merge(df_genre_dow_holiday_visitors_fea, on=['air_genre_name_weekday_holiday'], how='left')\n",
    "    \n",
    "    del df_features['air_genre_name'] \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型验证\n",
    "### 模型验证的框架\n",
    "\n",
    "2020-07-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:02:35.163743Z",
     "start_time": "2020-07-10T10:02:35.149744Z"
    }
   },
   "outputs": [],
   "source": [
    "def lgb_model_test_weight_timebased(df_tr, df_val, features, ws = [1.01], test_df = None): \n",
    "    params = {\n",
    "        'num_leaves': 256,\n",
    "        'min_child_samples': 79,\n",
    "        'objective': 'rmse',\n",
    "        'max_depth': 13,\n",
    "        'learning_rate': 0.03,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'subsample_freq': 3,\n",
    "        'subsample': 0.9,\n",
    "        'bagging_seed': 11,\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'reg_alpha': 0.3,\n",
    "        'reg_lambda': 0.3,\n",
    "        'colsample_bytree': 0.9, \n",
    "    } \n",
    "\n",
    "    MAX_ROUNDS = 700\n",
    "    val_pred = []\n",
    "    test_pred = []\n",
    "    cate_vars = []\n",
    "    feature_importance = None\n",
    "    models = []  \n",
    "     \n",
    "    train_df, train_label = df_tr[features].copy(), df_tr['visitors'].values\n",
    "    val_df, val_label     = df_val[features].copy(), df_val['visitors'].values\n",
    "    \n",
    "    for i, w in enumerate(ws):\n",
    "    \n",
    "        train_weight = []\n",
    "        tmp = df_tr['day_to_now'].values\n",
    "        for d in tmp:\n",
    "            if d > 365:\n",
    "                train_weight.append(1) \n",
    "            else:\n",
    "                train_weight.append(w ** ((365 - d) // (60))) \n",
    "        \n",
    "        dtrain = lgb.Dataset(train_df, label = train_label, weight=train_weight)\n",
    "        dval   = lgb.Dataset(val_df,   label = val_label, reference=dtrain)  \n",
    "        \n",
    "        bst = lgb.train(params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "                        valid_sets=[dtrain,dval], early_stopping_rounds=1500,\n",
    "                        verbose_eval=100)\n",
    "        models.append(bst)\n",
    "        f_importance = pd.DataFrame()\n",
    "        f_importance['fea'] = features\n",
    "        f_importance['imp'] = bst.feature_importance(\"gain\") \n",
    "        f_importance['fold'] = i\n",
    "        if feature_importance is None:\n",
    "            feature_importance = f_importance\n",
    "        else:\n",
    "            feature_importance = pd.concat([feature_importance, f_importance],\n",
    "                                           axis=0,\n",
    "                                           ignore_index=True)\n",
    "  \n",
    "        if test_df is not None:\n",
    "            test_pred.append(bst.predict(test_df[features],\n",
    "                                         num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    if test_df is None:\n",
    "        return models, feature_importance\n",
    "    else:\n",
    "        return models, feature_importance, test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型验证\n",
    "#### 加入store date相关的reserve特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:25:26.031759Z",
     "start_time": "2020-07-10T10:02:35.164704Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-03-12 00:00:00 2017-04-20 00:00:00\n",
      "For area sts features, we spend 0.27629852294921875 seconds.\n",
      "For area name sts features, we spend 0.1984727382659912 seconds.\n",
      "For area name sts features, we spend 0.2064061164855957 seconds.\n",
      "For store id reserve visitors features, we spend 0.0469202995300293 seconds.\n",
      "For store id reserve visitors features, we spend 0.07256531715393066 seconds.\n",
      "For store id reserve visitors features, we spend 0.048873186111450195 seconds.\n",
      "For store id sts features, we spend 0.7879033088684082 seconds.\n",
      "For store id diff sts features, we spend 3.523646354675293 seconds.\n",
      "For store id diff sts features, we spend 3.1218926906585693 seconds.\n",
      "For store id exp features, we spend 14.643365621566772 seconds.\n",
      "For store id exp features, we spend 11.172038555145264 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▍                                                                                 | 1/58 [00:39<37:25, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-03-05 00:00:00 2017-04-13 00:00:00\n",
      "For area sts features, we spend 0.245375394821167 seconds.\n",
      "For area name sts features, we spend 0.1944746971130371 seconds.\n",
      "For area name sts features, we spend 0.20363354682922363 seconds.\n",
      "For store id reserve visitors features, we spend 0.03192901611328125 seconds.\n",
      "For store id reserve visitors features, we spend 0.06682157516479492 seconds.\n",
      "For store id reserve visitors features, we spend 0.04487872123718262 seconds.\n",
      "For store id sts features, we spend 0.7818658351898193 seconds.\n",
      "For store id diff sts features, we spend 3.426281213760376 seconds.\n",
      "For store id diff sts features, we spend 3.0157310962677 seconds.\n",
      "For store id exp features, we spend 14.197028875350952 seconds.\n",
      "For store id exp features, we spend 10.981896162033081 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▊                                                                                | 2/58 [01:17<36:31, 39.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-02-26 00:00:00 2017-04-06 00:00:00\n",
      "For area sts features, we spend 0.24440240859985352 seconds.\n",
      "For area name sts features, we spend 0.19565844535827637 seconds.\n",
      "For area name sts features, we spend 0.2082068920135498 seconds.\n",
      "For store id reserve visitors features, we spend 0.02995920181274414 seconds.\n",
      "For store id reserve visitors features, we spend 0.06482744216918945 seconds.\n",
      "For store id reserve visitors features, we spend 0.04388022422790527 seconds.\n",
      "For store id sts features, we spend 0.7802150249481201 seconds.\n",
      "For store id diff sts features, we spend 3.3900699615478516 seconds.\n",
      "For store id diff sts features, we spend 2.9964394569396973 seconds.\n",
      "For store id exp features, we spend 14.477341175079346 seconds.\n",
      "For store id exp features, we spend 10.713850021362305 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▎                                                                              | 3/58 [01:56<35:44, 38.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-02-19 00:00:00 2017-03-30 00:00:00\n",
      "For area sts features, we spend 0.24334311485290527 seconds.\n",
      "For area name sts features, we spend 0.1974506378173828 seconds.\n",
      "For area name sts features, we spend 0.2044227123260498 seconds.\n",
      "For store id reserve visitors features, we spend 0.03293156623840332 seconds.\n",
      "For store id reserve visitors features, we spend 0.06781673431396484 seconds.\n",
      "For store id reserve visitors features, we spend 0.046875 seconds.\n",
      "For store id sts features, we spend 0.7885739803314209 seconds.\n",
      "For store id diff sts features, we spend 3.4110066890716553 seconds.\n",
      "For store id diff sts features, we spend 3.0029780864715576 seconds.\n",
      "For store id exp features, we spend 13.681862115859985 seconds.\n",
      "For store id exp features, we spend 10.488358974456787 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▋                                                                             | 4/58 [02:34<34:43, 38.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-02-12 00:00:00 2017-03-23 00:00:00\n",
      "For area sts features, we spend 0.2425212860107422 seconds.\n",
      "For area name sts features, we spend 0.19249963760375977 seconds.\n",
      "For area name sts features, we spend 0.211472749710083 seconds.\n",
      "For store id reserve visitors features, we spend 0.03687644004821777 seconds.\n",
      "For store id reserve visitors features, we spend 0.06885600090026855 seconds.\n",
      "For store id reserve visitors features, we spend 0.047868967056274414 seconds.\n",
      "For store id sts features, we spend 0.7709441184997559 seconds.\n",
      "For store id diff sts features, we spend 3.2874913215637207 seconds.\n",
      "For store id diff sts features, we spend 2.893800735473633 seconds.\n",
      "For store id exp features, we spend 13.736128091812134 seconds.\n",
      "For store id exp features, we spend 10.371964454650879 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▏                                                                           | 5/58 [03:11<33:46, 38.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-02-05 00:00:00 2017-03-16 00:00:00\n",
      "For area sts features, we spend 0.23537826538085938 seconds.\n",
      "For area name sts features, we spend 0.18848252296447754 seconds.\n",
      "For area name sts features, we spend 0.1984875202178955 seconds.\n",
      "For store id reserve visitors features, we spend 0.03393721580505371 seconds.\n",
      "For store id reserve visitors features, we spend 0.06981420516967773 seconds.\n",
      "For store id reserve visitors features, we spend 0.04886794090270996 seconds.\n",
      "For store id sts features, we spend 0.7697651386260986 seconds.\n",
      "For store id diff sts features, we spend 3.322855234146118 seconds.\n",
      "For store id diff sts features, we spend 2.89680814743042 seconds.\n",
      "For store id exp features, we spend 13.469204187393188 seconds.\n",
      "For store id exp features, we spend 10.265994310379028 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▌                                                                          | 6/58 [03:49<33:00, 38.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-01-29 00:00:00 2017-03-09 00:00:00\n",
      "For area sts features, we spend 0.24632883071899414 seconds.\n",
      "For area name sts features, we spend 0.19858288764953613 seconds.\n",
      "For area name sts features, we spend 0.21242713928222656 seconds.\n",
      "For store id reserve visitors features, we spend 0.034923553466796875 seconds.\n",
      "For store id reserve visitors features, we spend 0.07081723213195801 seconds.\n",
      "For store id reserve visitors features, we spend 0.05128598213195801 seconds.\n",
      "For store id sts features, we spend 0.786168098449707 seconds.\n",
      "For store id diff sts features, we spend 3.9409008026123047 seconds.\n",
      "For store id diff sts features, we spend 3.3145041465759277 seconds.\n",
      "For store id exp features, we spend 17.1669020652771 seconds.\n",
      "For store id exp features, we spend 12.479012727737427 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████                                                                         | 7/58 [04:34<34:16, 40.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-01-22 00:00:00 2017-03-02 00:00:00\n",
      "For area sts features, we spend 0.25730037689208984 seconds.\n",
      "For area name sts features, we spend 0.20348691940307617 seconds.\n",
      "For area name sts features, we spend 0.22239470481872559 seconds.\n",
      "For store id reserve visitors features, we spend 0.04288530349731445 seconds.\n",
      "For store id reserve visitors features, we spend 0.08381342887878418 seconds.\n",
      "For store id reserve visitors features, we spend 0.05681133270263672 seconds.\n",
      "For store id sts features, we spend 0.8527216911315918 seconds.\n",
      "For store id diff sts features, we spend 3.4154980182647705 seconds.\n",
      "For store id diff sts features, we spend 3.0357630252838135 seconds.\n",
      "For store id exp features, we spend 14.959917068481445 seconds.\n",
      "For store id exp features, we spend 9.83201789855957 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▍                                                                       | 8/58 [05:15<33:39, 40.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-01-15 00:00:00 2017-02-23 00:00:00\n",
      "For area sts features, we spend 0.2502937316894531 seconds.\n",
      "For area name sts features, we spend 0.27127575874328613 seconds.\n",
      "For area name sts features, we spend 0.3361356258392334 seconds.\n",
      "For store id reserve visitors features, we spend 0.06183433532714844 seconds.\n",
      "For store id reserve visitors features, we spend 0.11768746376037598 seconds.\n",
      "For store id reserve visitors features, we spend 0.07579565048217773 seconds.\n",
      "For store id sts features, we spend 0.8527195453643799 seconds.\n",
      "For store id diff sts features, we spend 3.43707275390625 seconds.\n",
      "For store id diff sts features, we spend 2.797011375427246 seconds.\n",
      "For store id exp features, we spend 12.976984977722168 seconds.\n",
      "For store id exp features, we spend 9.63834524154663 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                      | 9/58 [05:52<32:11, 39.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-01-08 00:00:00 2017-02-16 00:00:00\n",
      "For area sts features, we spend 0.2334153652191162 seconds.\n",
      "For area name sts features, we spend 0.18466496467590332 seconds.\n",
      "For area name sts features, we spend 0.20245695114135742 seconds.\n",
      "For store id reserve visitors features, we spend 0.03790020942687988 seconds.\n",
      "For store id reserve visitors features, we spend 0.07507157325744629 seconds.\n",
      "For store id reserve visitors features, we spend 0.051868438720703125 seconds.\n",
      "For store id sts features, we spend 0.8527140617370605 seconds.\n",
      "For store id diff sts features, we spend 3.9350714683532715 seconds.\n",
      "For store id diff sts features, we spend 2.7557365894317627 seconds.\n",
      "For store id exp features, we spend 12.431140899658203 seconds.\n",
      "For store id exp features, we spend 9.366389989852905 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████▏                                                                   | 10/58 [06:29<30:52, 38.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-01-01 00:00:00 2017-02-09 00:00:00\n",
      "For area sts features, we spend 0.23640823364257812 seconds.\n",
      "For area name sts features, we spend 0.17948102951049805 seconds.\n",
      "For area name sts features, we spend 0.20944476127624512 seconds.\n",
      "For store id reserve visitors features, we spend 0.0339658260345459 seconds.\n",
      "For store id reserve visitors features, we spend 0.06881022453308105 seconds.\n",
      "For store id reserve visitors features, we spend 0.047873735427856445 seconds.\n",
      "For store id sts features, we spend 0.7759747505187988 seconds.\n",
      "For store id diff sts features, we spend 3.2162182331085205 seconds.\n",
      "For store id diff sts features, we spend 2.7504656314849854 seconds.\n",
      "For store id exp features, we spend 12.334747552871704 seconds.\n",
      "For store id exp features, we spend 9.531390190124512 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▌                                                                  | 11/58 [07:05<29:34, 37.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-12-25 00:00:00 2017-02-02 00:00:00\n",
      "For area sts features, we spend 0.2383263111114502 seconds.\n",
      "For area name sts features, we spend 0.19547176361083984 seconds.\n",
      "For area name sts features, we spend 0.19148707389831543 seconds.\n",
      "For store id reserve visitors features, we spend 0.048821449279785156 seconds.\n",
      "For store id reserve visitors features, we spend 0.08781075477600098 seconds.\n",
      "For store id reserve visitors features, we spend 0.06278562545776367 seconds.\n",
      "For store id sts features, we spend 0.7888884544372559 seconds.\n",
      "For store id diff sts features, we spend 3.1133313179016113 seconds.\n",
      "For store id diff sts features, we spend 2.6628928184509277 seconds.\n",
      "For store id exp features, we spend 11.537407875061035 seconds.\n",
      "For store id exp features, we spend 8.64224123954773 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▉                                                                 | 12/58 [07:39<28:05, 36.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-12-18 00:00:00 2017-01-26 00:00:00\n",
      "For area sts features, we spend 0.23035812377929688 seconds.\n",
      "For area name sts features, we spend 0.18546533584594727 seconds.\n",
      "For area name sts features, we spend 0.19349169731140137 seconds.\n",
      "For store id reserve visitors features, we spend 0.0558621883392334 seconds.\n",
      "For store id reserve visitors features, we spend 0.09970307350158691 seconds.\n",
      "For store id reserve visitors features, we spend 0.09470677375793457 seconds.\n",
      "For store id sts features, we spend 0.8357641696929932 seconds.\n",
      "For store id diff sts features, we spend 3.3783562183380127 seconds.\n",
      "For store id diff sts features, we spend 2.640892505645752 seconds.\n",
      "For store id exp features, we spend 11.32620644569397 seconds.\n",
      "For store id exp features, we spend 8.466153621673584 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▍                                                               | 13/58 [08:13<27:02, 36.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-12-11 00:00:00 2017-01-19 00:00:00\n",
      "For area sts features, we spend 0.26030397415161133 seconds.\n",
      "For area name sts features, we spend 0.2274322509765625 seconds.\n",
      "For area name sts features, we spend 0.22040963172912598 seconds.\n",
      "For store id reserve visitors features, we spend 0.07679343223571777 seconds.\n",
      "For store id reserve visitors features, we spend 0.16455936431884766 seconds.\n",
      "For store id reserve visitors features, we spend 0.09175610542297363 seconds.\n",
      "For store id sts features, we spend 1.1335132122039795 seconds.\n",
      "For store id diff sts features, we spend 3.5078186988830566 seconds.\n",
      "For store id diff sts features, we spend 2.849364995956421 seconds.\n",
      "For store id exp features, we spend 11.46633243560791 seconds.\n",
      "For store id exp features, we spend 9.010498762130737 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▊                                                              | 14/58 [08:49<26:25, 36.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-12-04 00:00:00 2017-01-12 00:00:00\n",
      "For area sts features, we spend 0.23237943649291992 seconds.\n",
      "For area name sts features, we spend 0.1874558925628662 seconds.\n",
      "For area name sts features, we spend 0.19443655014038086 seconds.\n",
      "For store id reserve visitors features, we spend 0.05489921569824219 seconds.\n",
      "For store id reserve visitors features, we spend 0.09773731231689453 seconds.\n",
      "For store id reserve visitors features, we spend 0.07076692581176758 seconds.\n",
      "For store id sts features, we spend 0.8471946716308594 seconds.\n",
      "For store id diff sts features, we spend 3.112044095993042 seconds.\n",
      "For store id diff sts features, we spend 2.561392307281494 seconds.\n",
      "For store id exp features, we spend 10.192061185836792 seconds.\n",
      "For store id exp features, we spend 7.5383148193359375 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▏                                                            | 15/58 [09:21<24:48, 34.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-11-27 00:00:00 2017-01-05 00:00:00\n",
      "For area sts features, we spend 0.18491578102111816 seconds.\n",
      "For area name sts features, we spend 0.15819501876831055 seconds.\n",
      "For area name sts features, we spend 0.1597127914428711 seconds.\n",
      "For store id reserve visitors features, we spend 0.031241655349731445 seconds.\n",
      "For store id reserve visitors features, we spend 0.07810854911804199 seconds.\n",
      "For store id reserve visitors features, we spend 0.04686307907104492 seconds.\n",
      "For store id sts features, we spend 0.7120773792266846 seconds.\n",
      "For store id diff sts features, we spend 2.7287437915802 seconds.\n",
      "For store id diff sts features, we spend 2.415954351425171 seconds.\n",
      "For store id exp features, we spend 9.705127000808716 seconds.\n",
      "For store id exp features, we spend 7.492562294006348 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▌                                                           | 16/58 [09:51<23:17, 33.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-11-20 00:00:00 2016-12-29 00:00:00\n",
      "For area sts features, we spend 0.2014174461364746 seconds.\n",
      "For area name sts features, we spend 0.157728910446167 seconds.\n",
      "For area name sts features, we spend 0.16167688369750977 seconds.\n",
      "For store id reserve visitors features, we spend 0.04686689376831055 seconds.\n",
      "For store id reserve visitors features, we spend 0.06246829032897949 seconds.\n",
      "For store id reserve visitors features, we spend 0.042232513427734375 seconds.\n",
      "For store id sts features, we spend 0.7169806957244873 seconds.\n",
      "For store id diff sts features, we spend 2.7650396823883057 seconds.\n",
      "For store id diff sts features, we spend 2.3126320838928223 seconds.\n",
      "For store id exp features, we spend 9.357306241989136 seconds.\n",
      "For store id exp features, we spend 7.0541534423828125 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████████████████                                                          | 17/58 [10:20<21:57, 32.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-11-13 00:00:00 2016-12-22 00:00:00\n",
      "For area sts features, we spend 0.19060564041137695 seconds.\n",
      "For area name sts features, we spend 0.1405951976776123 seconds.\n",
      "For area name sts features, we spend 0.16207051277160645 seconds.\n",
      "For store id reserve visitors features, we spend 0.031240224838256836 seconds.\n",
      "For store id reserve visitors features, we spend 0.09373188018798828 seconds.\n",
      "For store id reserve visitors features, we spend 0.046864986419677734 seconds.\n",
      "For store id sts features, we spend 0.6931092739105225 seconds.\n",
      "For store id diff sts features, we spend 2.627532958984375 seconds.\n",
      "For store id diff sts features, we spend 2.239640474319458 seconds.\n",
      "For store id exp features, we spend 9.13254189491272 seconds.\n",
      "For store id exp features, we spend 6.919930458068848 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▍                                                        | 18/58 [10:50<20:52, 31.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-11-06 00:00:00 2016-12-15 00:00:00\n",
      "For area sts features, we spend 0.2008669376373291 seconds.\n",
      "For area name sts features, we spend 0.15960311889648438 seconds.\n",
      "For area name sts features, we spend 0.16558241844177246 seconds.\n",
      "For store id reserve visitors features, we spend 0.031966447830200195 seconds.\n",
      "For store id reserve visitors features, we spend 0.07059049606323242 seconds.\n",
      "For store id reserve visitors features, we spend 0.04587435722351074 seconds.\n",
      "For store id sts features, we spend 0.7069859504699707 seconds.\n",
      "For store id diff sts features, we spend 2.714900016784668 seconds.\n",
      "For store id diff sts features, we spend 2.2248382568359375 seconds.\n",
      "For store id exp features, we spend 8.763129711151123 seconds.\n",
      "For store id exp features, we spend 6.631699323654175 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▊                                                       | 19/58 [11:18<19:49, 30.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-10-30 00:00:00 2016-12-08 00:00:00\n",
      "For area sts features, we spend 0.1785290241241455 seconds.\n",
      "For area name sts features, we spend 0.1405959129333496 seconds.\n",
      "For area name sts features, we spend 0.1714038848876953 seconds.\n",
      "For store id reserve visitors features, we spend 0.031240224838256836 seconds.\n",
      "For store id reserve visitors features, we spend 0.062482357025146484 seconds.\n",
      "For store id reserve visitors features, we spend 0.03241133689880371 seconds.\n",
      "For store id sts features, we spend 0.7116992473602295 seconds.\n",
      "For store id diff sts features, we spend 2.5378198623657227 seconds.\n",
      "For store id diff sts features, we spend 2.1799912452697754 seconds.\n",
      "For store id exp features, we spend 8.488570213317871 seconds.\n",
      "For store id exp features, we spend 6.442018508911133 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|████████████████████████████▎                                                     | 20/58 [11:46<18:49, 29.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-10-23 00:00:00 2016-12-01 00:00:00\n",
      "For area sts features, we spend 0.1865541934967041 seconds.\n",
      "For area name sts features, we spend 0.14960217475891113 seconds.\n",
      "For area name sts features, we spend 0.16057538986206055 seconds.\n",
      "For store id reserve visitors features, we spend 0.02498626708984375 seconds.\n",
      "For store id reserve visitors features, we spend 0.0568394660949707 seconds.\n",
      "For store id reserve visitors features, we spend 0.03789782524108887 seconds.\n",
      "For store id sts features, we spend 0.6809902191162109 seconds.\n",
      "For store id diff sts features, we spend 2.5709874629974365 seconds.\n",
      "For store id diff sts features, we spend 2.0868847370147705 seconds.\n",
      "For store id exp features, we spend 8.31007981300354 seconds.\n",
      "For store id exp features, we spend 6.068579196929932 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▋                                                    | 21/58 [12:14<17:53, 29.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-10-16 00:00:00 2016-11-24 00:00:00\n",
      "For area sts features, we spend 0.18239998817443848 seconds.\n",
      "For area name sts features, we spend 0.1405963897705078 seconds.\n",
      "For area name sts features, we spend 0.1702561378479004 seconds.\n",
      "For store id reserve visitors features, we spend 0.020960092544555664 seconds.\n",
      "For store id reserve visitors features, we spend 0.05285978317260742 seconds.\n",
      "For store id reserve visitors features, we spend 0.03486776351928711 seconds.\n",
      "For store id sts features, we spend 0.6949660778045654 seconds.\n",
      "For store id diff sts features, we spend 2.5435903072357178 seconds.\n",
      "For store id diff sts features, we spend 2.097756862640381 seconds.\n",
      "For store id exp features, we spend 7.768974304199219 seconds.\n",
      "For store id exp features, we spend 5.861369371414185 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████                                                   | 22/58 [12:40<16:58, 28.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-10-09 00:00:00 2016-11-17 00:00:00\n",
      "For area sts features, we spend 0.1825249195098877 seconds.\n",
      "For area name sts features, we spend 0.14662528038024902 seconds.\n",
      "For area name sts features, we spend 0.1815333366394043 seconds.\n",
      "For store id reserve visitors features, we spend 0.018977642059326172 seconds.\n",
      "For store id reserve visitors features, we spend 0.05086255073547363 seconds.\n",
      "For store id reserve visitors features, we spend 0.03291177749633789 seconds.\n",
      "For store id sts features, we spend 0.6861474514007568 seconds.\n",
      "For store id diff sts features, we spend 2.449674129486084 seconds.\n",
      "For store id diff sts features, we spend 2.024864435195923 seconds.\n",
      "For store id exp features, we spend 7.434938430786133 seconds.\n",
      "For store id exp features, we spend 5.6686437129974365 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▌                                                 | 23/58 [13:06<16:06, 27.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-10-02 00:00:00 2016-11-10 00:00:00\n",
      "For area sts features, we spend 0.17757964134216309 seconds.\n",
      "For area name sts features, we spend 0.14460420608520508 seconds.\n",
      "For area name sts features, we spend 0.15557098388671875 seconds.\n",
      "For store id reserve visitors features, we spend 0.014971494674682617 seconds.\n",
      "For store id reserve visitors features, we spend 0.04487800598144531 seconds.\n",
      "For store id reserve visitors features, we spend 0.02992391586303711 seconds.\n",
      "For store id sts features, we spend 0.683701753616333 seconds.\n",
      "For store id diff sts features, we spend 2.3796744346618652 seconds.\n",
      "For store id diff sts features, we spend 2.0980687141418457 seconds.\n",
      "For store id exp features, we spend 7.09605860710144 seconds.\n",
      "For store id exp features, we spend 5.417093753814697 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▉                                                | 24/58 [13:32<15:18, 27.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-09-25 00:00:00 2016-11-03 00:00:00\n",
      "For area sts features, we spend 0.17481660842895508 seconds.\n",
      "For area name sts features, we spend 0.14361166954040527 seconds.\n",
      "For area name sts features, we spend 0.1575760841369629 seconds.\n",
      "For store id reserve visitors features, we spend 0.01596379280090332 seconds.\n",
      "For store id reserve visitors features, we spend 0.045879364013671875 seconds.\n",
      "For store id reserve visitors features, we spend 0.029918909072875977 seconds.\n",
      "For store id sts features, we spend 0.6775078773498535 seconds.\n",
      "For store id diff sts features, we spend 2.4212849140167236 seconds.\n",
      "For store id diff sts features, we spend 2.000904083251953 seconds.\n",
      "For store id exp features, we spend 6.745864152908325 seconds.\n",
      "For store id exp features, we spend 5.172078847885132 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████▎                                              | 25/58 [13:57<14:30, 26.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-09-18 00:00:00 2016-10-27 00:00:00\n",
      "For area sts features, we spend 0.1865401268005371 seconds.\n",
      "For area name sts features, we spend 0.15392184257507324 seconds.\n",
      "For area name sts features, we spend 0.14860773086547852 seconds.\n",
      "For store id reserve visitors features, we spend 0.010989665985107422 seconds.\n",
      "For store id reserve visitors features, we spend 0.03490924835205078 seconds.\n",
      "For store id reserve visitors features, we spend 0.016953468322753906 seconds.\n",
      "For store id sts features, we spend 0.6940903663635254 seconds.\n",
      "For store id diff sts features, we spend 2.32000994682312 seconds.\n",
      "For store id diff sts features, we spend 1.8706681728363037 seconds.\n",
      "For store id exp features, we spend 6.528420925140381 seconds.\n",
      "For store id exp features, we spend 4.955225229263306 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▊                                             | 26/58 [14:21<13:44, 25.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-09-11 00:00:00 2016-10-20 00:00:00\n",
      "For area sts features, we spend 0.16957545280456543 seconds.\n",
      "For area name sts features, we spend 0.1376345157623291 seconds.\n",
      "For area name sts features, we spend 0.14745354652404785 seconds.\n",
      "For store id reserve visitors features, we spend 0.014989614486694336 seconds.\n",
      "For store id reserve visitors features, we spend 0.04587721824645996 seconds.\n",
      "For store id reserve visitors features, we spend 0.026931047439575195 seconds.\n",
      "For store id sts features, we spend 0.6832988262176514 seconds.\n",
      "For store id diff sts features, we spend 2.2760910987854004 seconds.\n",
      "For store id diff sts features, we spend 1.8445098400115967 seconds.\n",
      "For store id exp features, we spend 6.1721367835998535 seconds.\n",
      "For store id exp features, we spend 4.75717568397522 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████▏                                           | 27/58 [14:45<12:59, 25.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-09-04 00:00:00 2016-10-13 00:00:00\n",
      "For area sts features, we spend 0.15433812141418457 seconds.\n",
      "For area name sts features, we spend 0.12940359115600586 seconds.\n",
      "For area name sts features, we spend 0.14625048637390137 seconds.\n",
      "For store id reserve visitors features, we spend 0.015615224838256836 seconds.\n",
      "For store id reserve visitors features, we spend 0.04687356948852539 seconds.\n",
      "For store id reserve visitors features, we spend 0.031238079071044922 seconds.\n",
      "For store id sts features, we spend 0.6706438064575195 seconds.\n",
      "For store id diff sts features, we spend 2.2182345390319824 seconds.\n",
      "For store id diff sts features, we spend 1.806088924407959 seconds.\n",
      "For store id exp features, we spend 5.996017217636108 seconds.\n",
      "For store id exp features, we spend 4.467182874679565 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▌                                          | 28/58 [15:08<12:17, 24.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-08-28 00:00:00 2016-10-06 00:00:00\n",
      "For area sts features, we spend 0.16357088088989258 seconds.\n",
      "For area name sts features, we spend 0.1316690444946289 seconds.\n",
      "For area name sts features, we spend 0.1475510597229004 seconds.\n",
      "For store id reserve visitors features, we spend 0.015998125076293945 seconds.\n",
      "For store id reserve visitors features, we spend 0.04488635063171387 seconds.\n",
      "For store id reserve visitors features, we spend 0.027923583984375 seconds.\n",
      "For store id sts features, we spend 0.6712288856506348 seconds.\n",
      "For store id diff sts features, we spend 2.2857425212860107 seconds.\n",
      "For store id diff sts features, we spend 1.7819507122039795 seconds.\n",
      "For store id exp features, we spend 5.720131158828735 seconds.\n",
      "For store id exp features, we spend 4.318446636199951 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 29/58 [15:31<11:37, 24.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-08-21 00:00:00 2016-09-29 00:00:00\n",
      "For area sts features, we spend 0.16079354286193848 seconds.\n",
      "For area name sts features, we spend 0.12618350982666016 seconds.\n",
      "For area name sts features, we spend 0.13073229789733887 seconds.\n",
      "For store id reserve visitors features, we spend 0.01562190055847168 seconds.\n",
      "For store id reserve visitors features, we spend 0.03123927116394043 seconds.\n",
      "For store id reserve visitors features, we spend 0.03124380111694336 seconds.\n",
      "For store id sts features, we spend 0.6795947551727295 seconds.\n",
      "For store id diff sts features, we spend 2.4833195209503174 seconds.\n",
      "For store id diff sts features, we spend 1.8670971393585205 seconds.\n",
      "For store id exp features, we spend 5.294267416000366 seconds.\n",
      "For store id exp features, we spend 3.9481277465820312 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▍                                       | 30/58 [15:53<10:59, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-08-14 00:00:00 2016-09-22 00:00:00\n",
      "For area sts features, we spend 0.15561985969543457 seconds.\n",
      "For area name sts features, we spend 0.12367939949035645 seconds.\n",
      "For area name sts features, we spend 0.13264679908752441 seconds.\n",
      "For store id reserve visitors features, we spend 0.014988899230957031 seconds.\n",
      "For store id reserve visitors features, we spend 0.046875715255737305 seconds.\n",
      "For store id reserve visitors features, we spend 0.027925729751586914 seconds.\n",
      "For store id sts features, we spend 0.6552479267120361 seconds.\n",
      "For store id diff sts features, we spend 2.0729427337646484 seconds.\n",
      "For store id diff sts features, we spend 1.689157247543335 seconds.\n",
      "For store id exp features, we spend 4.909710884094238 seconds.\n",
      "For store id exp features, we spend 3.8814756870269775 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████▊                                      | 31/58 [16:15<10:18, 22.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-08-07 00:00:00 2016-09-15 00:00:00\n",
      "For area sts features, we spend 0.14860844612121582 seconds.\n",
      "For area name sts features, we spend 0.12369298934936523 seconds.\n",
      "For area name sts features, we spend 0.12671375274658203 seconds.\n",
      "For store id reserve visitors features, we spend 0.015958547592163086 seconds.\n",
      "For store id reserve visitors features, we spend 0.04687929153442383 seconds.\n",
      "For store id reserve visitors features, we spend 0.027919769287109375 seconds.\n",
      "For store id sts features, we spend 0.6692113876342773 seconds.\n",
      "For store id diff sts features, we spend 2.038917303085327 seconds.\n",
      "For store id diff sts features, we spend 1.56614351272583 seconds.\n",
      "For store id exp features, we spend 4.656211853027344 seconds.\n",
      "For store id exp features, we spend 3.5735552310943604 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████▏                                    | 32/58 [16:35<09:38, 22.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-07-31 00:00:00 2016-09-08 00:00:00\n",
      "For area sts features, we spend 0.14362144470214844 seconds.\n",
      "For area name sts features, we spend 0.14561200141906738 seconds.\n",
      "For area name sts features, we spend 0.12268853187561035 seconds.\n",
      "For store id reserve visitors features, we spend 0.011972427368164062 seconds.\n",
      "For store id reserve visitors features, we spend 0.0339205265045166 seconds.\n",
      "For store id reserve visitors features, we spend 0.016942501068115234 seconds.\n",
      "For store id sts features, we spend 0.6712703704833984 seconds.\n",
      "For store id diff sts features, we spend 1.9201037883758545 seconds.\n",
      "For store id diff sts features, we spend 1.551978588104248 seconds.\n",
      "For store id exp features, we spend 4.433219909667969 seconds.\n",
      "For store id exp features, we spend 3.2894976139068604 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████▋                                   | 33/58 [16:55<08:59, 21.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-07-24 00:00:00 2016-09-01 00:00:00\n",
      "For area sts features, we spend 0.12918591499328613 seconds.\n",
      "For area name sts features, we spend 0.10935044288635254 seconds.\n",
      "For area name sts features, we spend 0.1149747371673584 seconds.\n",
      "For store id reserve visitors features, we spend 0.015618324279785156 seconds.\n",
      "For store id reserve visitors features, we spend 0.04681229591369629 seconds.\n",
      "For store id reserve visitors features, we spend 0.03130459785461426 seconds.\n",
      "For store id sts features, we spend 0.6404702663421631 seconds.\n",
      "For store id diff sts features, we spend 1.8671185970306396 seconds.\n",
      "For store id diff sts features, we spend 1.3950273990631104 seconds.\n",
      "For store id exp features, we spend 4.0662829875946045 seconds.\n",
      "For store id exp features, we spend 3.1304874420166016 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████████                                  | 34/58 [17:15<08:21, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-07-17 00:00:00 2016-08-25 00:00:00\n",
      "For area sts features, we spend 0.132704496383667 seconds.\n",
      "For area name sts features, we spend 0.11031651496887207 seconds.\n",
      "For area name sts features, we spend 0.11170315742492676 seconds.\n",
      "For store id reserve visitors features, we spend 0.016959190368652344 seconds.\n",
      "For store id reserve visitors features, we spend 0.05086231231689453 seconds.\n",
      "For store id reserve visitors features, we spend 0.03091740608215332 seconds.\n",
      "For store id sts features, we spend 0.64813232421875 seconds.\n",
      "For store id diff sts features, we spend 1.7371139526367188 seconds.\n",
      "For store id diff sts features, we spend 1.321169376373291 seconds.\n",
      "For store id exp features, we spend 3.8817801475524902 seconds.\n",
      "For store id exp features, we spend 2.8746256828308105 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▍                                | 35/58 [17:33<07:45, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-07-10 00:00:00 2016-08-18 00:00:00\n",
      "For area sts features, we spend 0.12771248817443848 seconds.\n",
      "For area name sts features, we spend 0.1085367202758789 seconds.\n",
      "For area name sts features, we spend 0.11070442199707031 seconds.\n",
      "For store id reserve visitors features, we spend 0.017950057983398438 seconds.\n",
      "For store id reserve visitors features, we spend 0.053894758224487305 seconds.\n",
      "For store id reserve visitors features, we spend 0.03390812873840332 seconds.\n",
      "For store id sts features, we spend 0.650930643081665 seconds.\n",
      "For store id diff sts features, we spend 1.6583259105682373 seconds.\n",
      "For store id diff sts features, we spend 1.2282869815826416 seconds.\n",
      "For store id exp features, we spend 3.468172550201416 seconds.\n",
      "For store id exp features, we spend 2.637803792953491 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████▉                               | 36/58 [17:51<07:09, 19.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-07-03 00:00:00 2016-08-11 00:00:00\n",
      "For area sts features, we spend 0.12440276145935059 seconds.\n",
      "For area name sts features, we spend 0.09174942970275879 seconds.\n",
      "For area name sts features, we spend 0.10073995590209961 seconds.\n",
      "For store id reserve visitors features, we spend 0.016959667205810547 seconds.\n",
      "For store id reserve visitors features, we spend 0.049864768981933594 seconds.\n",
      "For store id reserve visitors features, we spend 0.0318608283996582 seconds.\n",
      "For store id sts features, we spend 0.630789041519165 seconds.\n",
      "For store id diff sts features, we spend 1.5577950477600098 seconds.\n",
      "For store id diff sts features, we spend 1.1347887516021729 seconds.\n",
      "For store id exp features, we spend 3.1704976558685303 seconds.\n",
      "For store id exp features, we spend 2.4446046352386475 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▎                             | 37/58 [18:08<06:34, 18.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-06-26 00:00:00 2016-08-04 00:00:00\n",
      "For area sts features, we spend 0.136749267578125 seconds.\n",
      "For area name sts features, we spend 0.09372711181640625 seconds.\n",
      "For area name sts features, we spend 0.10042738914489746 seconds.\n",
      "For store id reserve visitors features, we spend 0.010091781616210938 seconds.\n",
      "For store id reserve visitors features, we spend 0.04691958427429199 seconds.\n",
      "For store id reserve visitors features, we spend 0.031244993209838867 seconds.\n",
      "For store id sts features, we spend 0.33636927604675293 seconds.\n",
      "For store id diff sts features, we spend 1.1108872890472412 seconds.\n",
      "For store id diff sts features, we spend 0.8806850910186768 seconds.\n",
      "For store id exp features, we spend 3.058558225631714 seconds.\n",
      "For store id exp features, we spend 2.26994252204895 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████▋                            | 38/58 [18:24<05:56, 17.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-06-19 00:00:00 2016-07-28 00:00:00\n",
      "For area sts features, we spend 0.1237032413482666 seconds.\n",
      "For area name sts features, we spend 0.08440327644348145 seconds.\n",
      "For area name sts features, we spend 0.09963726997375488 seconds.\n",
      "For store id reserve visitors features, we spend 0.01694631576538086 seconds.\n",
      "For store id reserve visitors features, we spend 0.03677654266357422 seconds.\n",
      "For store id reserve visitors features, we spend 0.03130030632019043 seconds.\n",
      "For store id sts features, we spend 0.34340715408325195 seconds.\n",
      "For store id diff sts features, we spend 1.1144845485687256 seconds.\n",
      "For store id diff sts features, we spend 0.879366397857666 seconds.\n",
      "For store id exp features, we spend 2.859858751296997 seconds.\n",
      "For store id exp features, we spend 2.273834705352783 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▏                          | 39/58 [18:39<05:25, 17.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-06-12 00:00:00 2016-07-21 00:00:00\n",
      "For area sts features, we spend 0.13360857963562012 seconds.\n",
      "For area name sts features, we spend 0.09574484825134277 seconds.\n",
      "For area name sts features, we spend 0.10277605056762695 seconds.\n",
      "For store id reserve visitors features, we spend 0.01795339584350586 seconds.\n",
      "For store id reserve visitors features, we spend 0.05385780334472656 seconds.\n",
      "For store id reserve visitors features, we spend 0.033907175064086914 seconds.\n",
      "For store id sts features, we spend 0.3227567672729492 seconds.\n",
      "For store id diff sts features, we spend 1.1080148220062256 seconds.\n",
      "For store id diff sts features, we spend 0.8546898365020752 seconds.\n",
      "For store id exp features, we spend 2.8030202388763428 seconds.\n",
      "For store id exp features, we spend 2.068869113922119 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████▌                         | 40/58 [18:55<04:57, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-06-05 00:00:00 2016-07-14 00:00:00\n",
      "For area sts features, we spend 0.12305307388305664 seconds.\n",
      "For area name sts features, we spend 0.0937340259552002 seconds.\n",
      "For area name sts features, we spend 0.09534168243408203 seconds.\n",
      "For store id reserve visitors features, we spend 0.01695990562438965 seconds.\n",
      "For store id reserve visitors features, we spend 0.04230499267578125 seconds.\n",
      "For store id reserve visitors features, we spend 0.03124690055847168 seconds.\n",
      "For store id sts features, we spend 0.3319823741912842 seconds.\n",
      "For store id diff sts features, we spend 1.0813217163085938 seconds.\n",
      "For store id diff sts features, we spend 0.8492603302001953 seconds.\n",
      "For store id exp features, we spend 2.6535604000091553 seconds.\n",
      "For store id exp features, we spend 1.9895520210266113 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|█████████████████████████████████████████████████████████▉                        | 41/58 [19:09<04:32, 16.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-05-29 00:00:00 2016-07-07 00:00:00\n",
      "For area sts features, we spend 0.11773324012756348 seconds.\n",
      "For area name sts features, we spend 0.0868062973022461 seconds.\n",
      "For area name sts features, we spend 0.0977470874786377 seconds.\n",
      "For store id reserve visitors features, we spend 0.015983104705810547 seconds.\n",
      "For store id reserve visitors features, we spend 0.04985761642456055 seconds.\n",
      "For store id reserve visitors features, we spend 0.030904293060302734 seconds.\n",
      "For store id sts features, we spend 0.319561243057251 seconds.\n",
      "For store id diff sts features, we spend 1.039029598236084 seconds.\n",
      "For store id diff sts features, we spend 0.8121087551116943 seconds.\n",
      "For store id exp features, we spend 2.5127811431884766 seconds.\n",
      "For store id exp features, we spend 1.9493491649627686 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████████▍                      | 42/58 [19:24<04:09, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-05-22 00:00:00 2016-06-30 00:00:00\n",
      "For area sts features, we spend 0.12024617195129395 seconds.\n",
      "For area name sts features, we spend 0.0804746150970459 seconds.\n",
      "For area name sts features, we spend 0.1032099723815918 seconds.\n",
      "For store id reserve visitors features, we spend 0.01699542999267578 seconds.\n",
      "For store id reserve visitors features, we spend 0.04691958427429199 seconds.\n",
      "For store id reserve visitors features, we spend 0.031242847442626953 seconds.\n",
      "For store id sts features, we spend 0.3286778926849365 seconds.\n",
      "For store id diff sts features, we spend 1.034055233001709 seconds.\n",
      "For store id diff sts features, we spend 0.7801558971405029 seconds.\n",
      "For store id exp features, we spend 2.358875036239624 seconds.\n",
      "For store id exp features, we spend 1.8563482761383057 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▊                     | 43/58 [19:38<03:47, 15.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-05-15 00:00:00 2016-06-23 00:00:00\n",
      "For area sts features, we spend 0.12644267082214355 seconds.\n",
      "For area name sts features, we spend 0.07653474807739258 seconds.\n",
      "For area name sts features, we spend 0.1023869514465332 seconds.\n",
      "For store id reserve visitors features, we spend 0.017004966735839844 seconds.\n",
      "For store id reserve visitors features, we spend 0.043519020080566406 seconds.\n",
      "For store id reserve visitors features, we spend 0.03128314018249512 seconds.\n",
      "For store id sts features, we spend 0.3317070007324219 seconds.\n",
      "For store id diff sts features, we spend 1.0415003299713135 seconds.\n",
      "For store id diff sts features, we spend 0.7743160724639893 seconds.\n",
      "For store id exp features, we spend 2.404412269592285 seconds.\n",
      "For store id exp features, we spend 1.9219672679901123 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▏                   | 44/58 [19:53<03:32, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-05-08 00:00:00 2016-06-16 00:00:00\n",
      "For area sts features, we spend 0.1226339340209961 seconds.\n",
      "For area name sts features, we spend 0.09178900718688965 seconds.\n",
      "For area name sts features, we spend 0.10373091697692871 seconds.\n",
      "For store id reserve visitors features, we spend 0.018947601318359375 seconds.\n",
      "For store id reserve visitors features, we spend 0.05489826202392578 seconds.\n",
      "For store id reserve visitors features, we spend 0.03291678428649902 seconds.\n",
      "For store id sts features, we spend 0.36499595642089844 seconds.\n",
      "For store id diff sts features, we spend 1.087148666381836 seconds.\n",
      "For store id diff sts features, we spend 0.8784842491149902 seconds.\n",
      "For store id exp features, we spend 2.6456265449523926 seconds.\n",
      "For store id exp features, we spend 1.624523639678955 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████▌                  | 45/58 [20:08<03:15, 15.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-05-01 00:00:00 2016-06-09 00:00:00\n",
      "For area sts features, we spend 0.11365437507629395 seconds.\n",
      "For area name sts features, we spend 0.08477163314819336 seconds.\n",
      "For area name sts features, we spend 0.1197357177734375 seconds.\n",
      "For store id reserve visitors features, we spend 0.017936229705810547 seconds.\n",
      "For store id reserve visitors features, we spend 0.05286049842834473 seconds.\n",
      "For store id reserve visitors features, we spend 0.03390955924987793 seconds.\n",
      "For store id sts features, we spend 0.32910799980163574 seconds.\n",
      "For store id diff sts features, we spend 0.9882543087005615 seconds.\n",
      "For store id diff sts features, we spend 0.7677180767059326 seconds.\n",
      "For store id exp features, we spend 2.043654441833496 seconds.\n",
      "For store id exp features, we spend 1.5666508674621582 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|█████████████████████████████████████████████████████████████████                 | 46/58 [20:22<02:55, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-04-24 00:00:00 2016-06-02 00:00:00\n",
      "For area sts features, we spend 0.10868239402770996 seconds.\n",
      "For area name sts features, we spend 0.0827798843383789 seconds.\n",
      "For area name sts features, we spend 0.0887908935546875 seconds.\n",
      "For store id reserve visitors features, we spend 0.019900083541870117 seconds.\n",
      "For store id reserve visitors features, we spend 0.05191326141357422 seconds.\n",
      "For store id reserve visitors features, we spend 0.034906864166259766 seconds.\n",
      "For store id sts features, we spend 0.34801745414733887 seconds.\n",
      "For store id diff sts features, we spend 0.9906506538391113 seconds.\n",
      "For store id diff sts features, we spend 0.7362551689147949 seconds.\n",
      "For store id exp features, we spend 1.9513707160949707 seconds.\n",
      "For store id exp features, we spend 1.491698980331421 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████▍               | 47/58 [20:35<02:37, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-04-17 00:00:00 2016-05-26 00:00:00\n",
      "For area sts features, we spend 0.10935258865356445 seconds.\n",
      "For area name sts features, we spend 0.07386207580566406 seconds.\n",
      "For area name sts features, we spend 0.08893394470214844 seconds.\n",
      "For store id reserve visitors features, we spend 0.018954038619995117 seconds.\n",
      "For store id reserve visitors features, we spend 0.04363560676574707 seconds.\n",
      "For store id reserve visitors features, we spend 0.0312497615814209 seconds.\n",
      "For store id sts features, we spend 0.32544922828674316 seconds.\n",
      "For store id diff sts features, we spend 0.9701931476593018 seconds.\n",
      "For store id diff sts features, we spend 0.7388050556182861 seconds.\n",
      "For store id exp features, we spend 1.8369145393371582 seconds.\n",
      "For store id exp features, we spend 1.391049861907959 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|███████████████████████████████████████████████████████████████████▊              | 48/58 [20:49<02:20, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-04-10 00:00:00 2016-05-19 00:00:00\n",
      "For area sts features, we spend 0.10932517051696777 seconds.\n",
      "For area name sts features, we spend 0.08587980270385742 seconds.\n",
      "For area name sts features, we spend 0.07814216613769531 seconds.\n",
      "For store id reserve visitors features, we spend 0.031245708465576172 seconds.\n",
      "For store id reserve visitors features, we spend 0.04686260223388672 seconds.\n",
      "For store id reserve visitors features, we spend 0.046126604080200195 seconds.\n",
      "For store id sts features, we spend 0.32214879989624023 seconds.\n",
      "For store id diff sts features, we spend 0.9395842552185059 seconds.\n",
      "For store id diff sts features, we spend 0.7491462230682373 seconds.\n",
      "For store id exp features, we spend 1.685614824295044 seconds.\n",
      "For store id exp features, we spend 1.311722755432129 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|█████████████████████████████████████████████████████████████████████▎            | 49/58 [21:02<02:03, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-04-03 00:00:00 2016-05-12 00:00:00\n",
      "For area sts features, we spend 0.11255741119384766 seconds.\n",
      "For area name sts features, we spend 0.07850193977355957 seconds.\n",
      "For area name sts features, we spend 0.10393404960632324 seconds.\n",
      "For store id reserve visitors features, we spend 0.018955707550048828 seconds.\n",
      "For store id reserve visitors features, we spend 0.046723127365112305 seconds.\n",
      "For store id reserve visitors features, we spend 0.040888071060180664 seconds.\n",
      "For store id sts features, we spend 0.3179028034210205 seconds.\n",
      "For store id diff sts features, we spend 0.9581284523010254 seconds.\n",
      "For store id diff sts features, we spend 0.7059383392333984 seconds.\n",
      "For store id exp features, we spend 1.6634573936462402 seconds.\n",
      "For store id exp features, we spend 1.195340633392334 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████████████████████████████████████████▋           | 50/58 [21:15<01:47, 13.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-03-27 00:00:00 2016-05-05 00:00:00\n",
      "For area sts features, we spend 0.10970735549926758 seconds.\n",
      "For area name sts features, we spend 0.07978558540344238 seconds.\n",
      "For area name sts features, we spend 0.08781266212463379 seconds.\n",
      "For store id reserve visitors features, we spend 0.01995682716369629 seconds.\n",
      "For store id reserve visitors features, we spend 0.053858041763305664 seconds.\n",
      "For store id reserve visitors features, we spend 0.03490447998046875 seconds.\n",
      "For store id sts features, we spend 0.30643796920776367 seconds.\n",
      "For store id diff sts features, we spend 0.9114043712615967 seconds.\n",
      "For store id diff sts features, we spend 0.6852202415466309 seconds.\n",
      "For store id exp features, we spend 1.4840610027313232 seconds.\n",
      "For store id exp features, we spend 1.14418625831604 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████          | 51/58 [21:27<01:32, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-03-20 00:00:00 2016-04-28 00:00:00\n",
      "For area sts features, we spend 0.10871028900146484 seconds.\n",
      "For area name sts features, we spend 0.08078265190124512 seconds.\n",
      "For area name sts features, we spend 0.0857689380645752 seconds.\n",
      "For store id reserve visitors features, we spend 0.021943092346191406 seconds.\n",
      "For store id reserve visitors features, we spend 0.0618746280670166 seconds.\n",
      "For store id reserve visitors features, we spend 0.039895057678222656 seconds.\n",
      "For store id sts features, we spend 0.3258647918701172 seconds.\n",
      "For store id diff sts features, we spend 0.8678996562957764 seconds.\n",
      "For store id diff sts features, we spend 0.694629430770874 seconds.\n",
      "For store id exp features, we spend 1.3404169082641602 seconds.\n",
      "For store id exp features, we spend 1.0370523929595947 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▌        | 52/58 [21:40<01:17, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-03-13 00:00:00 2016-04-21 00:00:00\n",
      "For area sts features, we spend 0.10471916198730469 seconds.\n",
      "For area name sts features, we spend 0.07680368423461914 seconds.\n",
      "For area name sts features, we spend 0.08177757263183594 seconds.\n",
      "For store id reserve visitors features, we spend 0.021971464157104492 seconds.\n",
      "For store id reserve visitors features, we spend 0.058588266372680664 seconds.\n",
      "For store id reserve visitors features, we spend 0.03991961479187012 seconds.\n",
      "For store id sts features, we spend 0.3149268627166748 seconds.\n",
      "For store id diff sts features, we spend 0.8936851024627686 seconds.\n",
      "For store id diff sts features, we spend 0.6370184421539307 seconds.\n",
      "For store id exp features, we spend 1.225912094116211 seconds.\n",
      "For store id exp features, we spend 0.9787020683288574 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 53/58 [21:52<01:04, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-03-06 00:00:00 2016-04-14 00:00:00\n",
      "For area sts features, we spend 0.1691277027130127 seconds.\n",
      "For area name sts features, we spend 0.12497496604919434 seconds.\n",
      "For area name sts features, we spend 0.09049272537231445 seconds.\n",
      "For store id reserve visitors features, we spend 0.01565718650817871 seconds.\n",
      "For store id reserve visitors features, we spend 0.07927608489990234 seconds.\n",
      "For store id reserve visitors features, we spend 0.04686713218688965 seconds.\n",
      "For store id sts features, we spend 0.3502366542816162 seconds.\n",
      "For store id diff sts features, we spend 0.8716831207275391 seconds.\n",
      "For store id diff sts features, we spend 0.6190669536590576 seconds.\n",
      "For store id exp features, we spend 1.1291053295135498 seconds.\n",
      "For store id exp features, we spend 0.8430182933807373 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|████████████████████████████████████████████████████████████████████████████▎     | 54/58 [22:04<00:50, 12.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-02-28 00:00:00 2016-04-07 00:00:00\n",
      "For area sts features, we spend 0.0937352180480957 seconds.\n",
      "For area name sts features, we spend 0.06923985481262207 seconds.\n",
      "For area name sts features, we spend 0.07808113098144531 seconds.\n",
      "For store id reserve visitors features, we spend 0.031244516372680664 seconds.\n",
      "For store id reserve visitors features, we spend 0.04690408706665039 seconds.\n",
      "For store id reserve visitors features, we spend 0.031239032745361328 seconds.\n",
      "For store id sts features, we spend 0.3178846836090088 seconds.\n",
      "For store id diff sts features, we spend 0.8298208713531494 seconds.\n",
      "For store id diff sts features, we spend 0.6412744522094727 seconds.\n",
      "For store id exp features, we spend 1.021803379058838 seconds.\n",
      "For store id exp features, we spend 0.7862379550933838 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▊    | 55/58 [22:16<00:37, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-02-21 00:00:00 2016-03-31 00:00:00\n",
      "For area sts features, we spend 0.0865945816040039 seconds.\n",
      "For area name sts features, we spend 0.0545499324798584 seconds.\n",
      "For area name sts features, we spend 0.08331704139709473 seconds.\n",
      "For store id reserve visitors features, we spend 0.015620946884155273 seconds.\n",
      "For store id reserve visitors features, we spend 0.0624842643737793 seconds.\n",
      "For store id reserve visitors features, we spend 0.04191946983337402 seconds.\n",
      "For store id sts features, we spend 0.31394195556640625 seconds.\n",
      "For store id diff sts features, we spend 0.8395860195159912 seconds.\n",
      "For store id diff sts features, we spend 0.5466623306274414 seconds.\n",
      "For store id exp features, we spend 0.8837182521820068 seconds.\n",
      "For store id exp features, we spend 0.6993393898010254 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████████▏  | 56/58 [22:28<00:24, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-02-14 00:00:00 2016-03-24 00:00:00\n",
      "For area sts features, we spend 0.10270071029663086 seconds.\n",
      "For area name sts features, we spend 0.06881570816040039 seconds.\n",
      "For area name sts features, we spend 0.0759575366973877 seconds.\n",
      "For store id reserve visitors features, we spend 0.022934913635253906 seconds.\n",
      "For store id reserve visitors features, we spend 0.05386471748352051 seconds.\n",
      "For store id reserve visitors features, we spend 0.03685903549194336 seconds.\n",
      "For store id sts features, we spend 0.3054957389831543 seconds.\n",
      "For store id diff sts features, we spend 0.7711505889892578 seconds.\n",
      "For store id diff sts features, we spend 0.5735859870910645 seconds.\n",
      "For store id exp features, we spend 0.7718179225921631 seconds.\n",
      "For store id exp features, we spend 0.6054859161376953 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████████▌ | 57/58 [22:39<00:11, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2016-02-07 00:00:00 2016-03-17 00:00:00\n",
      "For area sts features, we spend 0.10369634628295898 seconds.\n",
      "For area name sts features, we spend 0.06685042381286621 seconds.\n",
      "For area name sts features, we spend 0.062486886978149414 seconds.\n",
      "For store id reserve visitors features, we spend 0.03124380111694336 seconds.\n",
      "For store id reserve visitors features, we spend 0.04686307907104492 seconds.\n",
      "For store id reserve visitors features, we spend 0.032396793365478516 seconds.\n",
      "For store id sts features, we spend 0.2933840751647949 seconds.\n",
      "For store id diff sts features, we spend 0.7631344795227051 seconds.\n",
      "For store id diff sts features, we spend 0.5026836395263672 seconds.\n",
      "For store id exp features, we spend 0.6685564517974854 seconds.\n",
      "For store id exp features, we spend 0.5014147758483887 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [22:50<00:00, 23.64s/it]\n"
     ]
    }
   ],
   "source": [
    "df_tr_feas = pd.DataFrame()\n",
    "tr_fea_list = []\n",
    "for i in tqdm(range(58)): \n",
    "    try:\n",
    "        tr_label_date      = parse('2017-04-23') - timedelta(7 * 6 + 7 * i)   #*2\n",
    "        tr_fea_date        = parse('2017-04-23') - timedelta(7 * 6 + 7 * i + 1) #**2\n",
    "\n",
    "        df_tr_tmp          = get_features(df_meta, air_reserve, hpg_air_reserve, label_st_date=tr_label_date)    \n",
    "        df_tr_feas         = pd.concat([df_tr_feas, df_tr_tmp], axis=0, ignore_index=True) \n",
    "        tr_fea_list.append(df_tr_tmp)\n",
    "    except:\n",
    "        print('Problems happen at step {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:32:14.558688Z",
     "start_time": "2020-07-10T10:25:26.033266Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-03-19 00:00:00 2017-04-23 00:00:00\n",
      "For area sts features, we spend 0.3222973346710205 seconds.\n",
      "For area name sts features, we spend 0.21712517738342285 seconds.\n",
      "For area name sts features, we spend 0.21384453773498535 seconds.\n",
      "For store id reserve visitors features, we spend 0.04041171073913574 seconds.\n",
      "For store id reserve visitors features, we spend 0.0781104564666748 seconds.\n",
      "For store id reserve visitors features, we spend 0.056084632873535156 seconds.\n",
      "For store id sts features, we spend 0.7814249992370605 seconds.\n",
      "For store id diff sts features, we spend 3.429210901260376 seconds.\n",
      "For store id diff sts features, we spend 3.0542123317718506 seconds.\n",
      "For store id exp features, we spend 14.691834688186646 seconds.\n",
      "For store id exp features, we spend 11.932658195495605 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▊                                                                   | 1/5 [00:47<03:11, 47.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-03-26 00:00:00 2017-04-23 00:00:00\n",
      "For area sts features, we spend 0.2662825584411621 seconds.\n",
      "For area name sts features, we spend 0.2343745231628418 seconds.\n",
      "For area name sts features, we spend 0.2092733383178711 seconds.\n",
      "For store id reserve visitors features, we spend 0.031969547271728516 seconds.\n",
      "For store id reserve visitors features, we spend 0.06582236289978027 seconds.\n",
      "For store id reserve visitors features, we spend 0.04288601875305176 seconds.\n",
      "For store id sts features, we spend 0.7626745700836182 seconds.\n",
      "For store id diff sts features, we spend 3.453118324279785 seconds.\n",
      "For store id diff sts features, we spend 3.137575387954712 seconds.\n",
      "For store id exp features, we spend 15.348093509674072 seconds.\n",
      "For store id exp features, we spend 11.249058485031128 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [01:34<02:22, 47.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-04-02 00:00:00 2017-04-23 00:00:00\n",
      "For area sts features, we spend 0.26803040504455566 seconds.\n",
      "For area name sts features, we spend 0.2054598331451416 seconds.\n",
      "For area name sts features, we spend 0.213423490524292 seconds.\n",
      "For store id reserve visitors features, we spend 0.03047013282775879 seconds.\n",
      "For store id reserve visitors features, we spend 0.059883832931518555 seconds.\n",
      "For store id reserve visitors features, we spend 0.039880990982055664 seconds.\n",
      "For store id sts features, we spend 0.7940318584442139 seconds.\n",
      "For store id diff sts features, we spend 3.4644792079925537 seconds.\n",
      "For store id diff sts features, we spend 3.10251522064209 seconds.\n",
      "For store id exp features, we spend 15.454034328460693 seconds.\n",
      "For store id exp features, we spend 12.171231985092163 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [02:23<01:35, 47.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-04-09 00:00:00 2017-04-23 00:00:00\n",
      "For area sts features, we spend 0.2622971534729004 seconds.\n",
      "For area name sts features, we spend 0.2074596881866455 seconds.\n",
      "For area name sts features, we spend 0.20934510231018066 seconds.\n",
      "For store id reserve visitors features, we spend 0.012047052383422852 seconds.\n",
      "For store id reserve visitors features, we spend 0.06254124641418457 seconds.\n",
      "For store id reserve visitors features, we spend 0.04686379432678223 seconds.\n",
      "For store id sts features, we spend 0.75888991355896 seconds.\n",
      "For store id diff sts features, we spend 3.5566561222076416 seconds.\n",
      "For store id diff sts features, we spend 3.1573891639709473 seconds.\n",
      "For store id exp features, we spend 15.59132981300354 seconds.\n",
      "For store id exp features, we spend 11.714913606643677 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [03:10<00:47, 47.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-04-16 00:00:00 2017-04-23 00:00:00\n",
      "For area sts features, we spend 0.26612162590026855 seconds.\n",
      "For area name sts features, we spend 0.20562219619750977 seconds.\n",
      "For area name sts features, we spend 0.2125861644744873 seconds.\n",
      "For store id reserve visitors features, we spend 0.02498006820678711 seconds.\n",
      "For store id reserve visitors features, we spend 0.06253457069396973 seconds.\n",
      "For store id reserve visitors features, we spend 0.031235694885253906 seconds.\n",
      "For store id sts features, we spend 0.7756028175354004 seconds.\n",
      "For store id diff sts features, we spend 3.6182496547698975 seconds.\n",
      "For store id diff sts features, we spend 3.2113964557647705 seconds.\n",
      "For store id exp features, we spend 15.792046785354614 seconds.\n",
      "For store id exp features, we spend 12.107356786727905 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:59<00:00, 47.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label date,  2017-03-12 00:00:00 2017-04-20 00:00:00\n",
      "For area sts features, we spend 0.2505829334259033 seconds.\n",
      "For area name sts features, we spend 0.1954958438873291 seconds.\n",
      "For area name sts features, we spend 0.20346927642822266 seconds.\n",
      "For store id reserve visitors features, we spend 0.04492449760437012 seconds.\n",
      "For store id reserve visitors features, we spend 0.07081985473632812 seconds.\n",
      "For store id reserve visitors features, we spend 0.0488734245300293 seconds.\n",
      "For store id sts features, we spend 0.756033182144165 seconds.\n",
      "For store id diff sts features, we spend 3.4510409832000732 seconds.\n",
      "For store id diff sts features, we spend 3.134182929992676 seconds.\n",
      "For store id exp features, we spend 14.393874883651733 seconds.\n",
      "For store id exp features, we spend 10.774326801300049 seconds.\n",
      "label date,  2017-04-23 00:00:00 2017-06-01 00:00:00\n",
      "For area sts features, we spend 0.25017881393432617 seconds.\n",
      "For area name sts features, we spend 0.22463035583496094 seconds.\n",
      "For area name sts features, we spend 0.227691650390625 seconds.\n",
      "For store id reserve visitors features, we spend 0.04125165939331055 seconds.\n",
      "For store id reserve visitors features, we spend 0.06249666213989258 seconds.\n",
      "For store id reserve visitors features, we spend 0.046853065490722656 seconds.\n",
      "For store id sts features, we spend 0.8121066093444824 seconds.\n",
      "For store id diff sts features, we spend 3.6328749656677246 seconds.\n",
      "For store id diff sts features, we spend 3.291476011276245 seconds.\n",
      "For store id exp features, we spend 18.044981718063354 seconds.\n",
      "For store id exp features, we spend 12.41184663772583 seconds.\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1, 6)): \n",
    "    tr_label_date      = parse('2017-04-23') - timedelta(7 * 6 - 7 * i) \n",
    "    df_tr_tmp          = get_features(df_meta, air_reserve, hpg_air_reserve, days=42 - 7 * i, label_st_date=tr_label_date)    \n",
    "    df_tr_feas         = pd.concat([df_tr_feas, df_tr_tmp], axis=0,ignore_index=True) \n",
    "    tr_fea_list.append(df_tr_tmp)\n",
    "\n",
    "val_label_date    = parse('2017-04-23')  - timedelta(7*6) \n",
    "te_fea_date       = parse('2017-04-23')\n",
    " \n",
    "df_val = get_features(df_meta, air_reserve, hpg_air_reserve, label_st_date=val_label_date)    \n",
    "df_te  = get_features(df_meta, air_reserve, hpg_air_reserve, label_st_date=te_fea_date, is_te=True)      \n",
    "\n",
    "## df_date['visit_date'] = pd.to_datetime(df_date['visit_date'])\n",
    "df_date['visit_date'] = df_date['visit_date'].astype(str)\n",
    "df_tr                 = df_tr_feas.merge(df_date, on=['visit_date'], how='left')\n",
    "df_tr                 = df_tr.merge(df_storeid,   on=['air_store_id'], how='left')  \n",
    "df_tr['visit_date']   = pd.to_datetime(df_tr['visit_date'])\n",
    "df_tr['day_to_now']   = df_tr['visit_date'].apply(lambda x: (parse('2017-04-22') - (x)).days) \n",
    " \n",
    "df_val = df_val.merge(df_date,       on=['visit_date'], how='left')\n",
    "df_val = df_val.merge(df_storeid,    on=['air_store_id'], how='left')  \n",
    " \n",
    "df_te  = df_te.merge(df_date,       on=['visit_date'], how='left') \n",
    "df_te  = df_te.merge(df_storeid,    on=['air_store_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:32:14.805687Z",
     "start_time": "2020-07-10T10:32:14.567486Z"
    }
   },
   "outputs": [],
   "source": [
    "other_cols   = [col for col in df_tr_feas.columns if df_tr_feas[col].dtypes!='object' and col not in ['air_store_id','visit_date','air_store_id_weekday','air_store_id_holiday','air_store_id_weekday_holiday','visitors','weekday',\\\n",
    "                                                                'air_store_id_visit_date','air_area_name','air_area_name_weekday']]\n",
    "date_cols    = [col for col in df_date.columns if col not in ['visit_date']]\n",
    "storeid_cols = [col for col in df_storeid.columns if col not in ['air_store_id']]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(list(set(df_tr['air_store_id'].values)) + list(set(df_val['air_store_id'].values)) + list(set(df_te['air_store_id'].values)))   \n",
    "\n",
    "df_tr['air_store_id_lb']  = le.transform(df_tr['air_store_id'].values)\n",
    "df_val['air_store_id_lb'] = le.transform(df_val['air_store_id'].values)\n",
    "df_te['air_store_id_lb']  = le.transform(df_te['air_store_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:49:03.753665Z",
     "start_time": "2020-07-10T10:32:14.806686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1500 rounds\n",
      "[100]\ttraining's rmse: 0.512099\tvalid_1's rmse: 0.499047\n",
      "[200]\ttraining's rmse: 0.490999\tvalid_1's rmse: 0.480723\n",
      "[300]\ttraining's rmse: 0.477733\tvalid_1's rmse: 0.467757\n",
      "[400]\ttraining's rmse: 0.467846\tvalid_1's rmse: 0.457847\n",
      "[500]\ttraining's rmse: 0.459713\tvalid_1's rmse: 0.449177\n",
      "[600]\ttraining's rmse: 0.452696\tvalid_1's rmse: 0.441954\n",
      "[700]\ttraining's rmse: 0.446322\tvalid_1's rmse: 0.435499\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[700]\ttraining's rmse: 0.446322\tvalid_1's rmse: 0.435499\n"
     ]
    }
   ],
   "source": [
    "label_col    = 'visitors' \n",
    "feature_cols = date_cols + storeid_cols + other_cols + ['air_store_id_lb']  \n",
    "feature_cols = [col for col in feature_cols if col not in ['day_to_last_holiday', 'day_to_next_holiday']]\n",
    "\n",
    "models1, feature_importance1, test_pred1 = lgb_model_test_weight_timebased(df_tr=df_tr,\n",
    "                                                                           df_val=df_val,\n",
    "                                                                           features=feature_cols,\n",
    "                                                                           ws=[1.0],\n",
    "                                                                           test_df=df_te)\n",
    "\n",
    "submit = df_te[['air_store_id', 'visit_date']].copy()\n",
    "submit['id'] = submit['air_store_id'] + '_' + submit['visit_date'].astype(str) \n",
    "submit['visitors'] =  np.expm1(test_pred1[0])\n",
    "submit['visitors'] = submit['visitors'] #.astype(int)\n",
    "submit.loc[submit['visitors'] == 0, 'visitors'] = 1\n",
    "submit[['id','visitors']].to_csv('../sub/sub.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
