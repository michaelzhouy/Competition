{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.830Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.833Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../input/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.836Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据集1：base_info.csv\n",
    "# 包含数据集7和8中涉及到的所有企业的基本信息，每一行代表一个企业的基本数据，每一行有33列，其中id列为企业唯一标识，列之间采用“,”分隔符分割。\n",
    "# 数据格式如下：\n",
    "# [id:企业唯一标识, oplocdistrict:行政区划代码, industryphy:行业类别代码, industryco:行业细类代码, dom:经营地址, opscope:经营范围, enttype:企业类型, enttypeitem:企业类型小类, opfrom:经营期限起, opto:经营期限止, state:状态, orgid:机构标识, jobid:职位标识, adbusign:是否广告经营, townsign:是否城镇, regtype:主题登记类型, empnum:从业人数, compform:组织形式, parnum:合伙人数, exenum:执行人数, opform:经营方式, ptbusscope:兼营范围, venind:风险行业, enttypeminu:企业类型细类, midpreindcode:中西部优势产业代码, protype:项目类型, oploc:经营场所, regcap:注册资本（金）, reccap:实缴资本, forreccap:实缴资本（外方）, forregcap:注册资本（外方）, congro:投资总额, enttypegb:企业（机构）类型]\n",
    "\n",
    "base_info = pd.read_csv('../../input/train/base_info.csv')\n",
    "print(base_info.shape)\n",
    "base_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.842Z"
    }
   },
   "outputs": [],
   "source": [
    "def identify_missing(df, missing_threshold):\n",
    "    \"\"\"\n",
    "    缺失率\n",
    "    @param df:\n",
    "    @param missing_threshold:\n",
    "    @return:\n",
    "    \"\"\"\n",
    "    missing_rate = df.isnull().sum() / len(df)\n",
    "    missing_rate = missing_rate.sort_values(ascending=False)\n",
    "    print(missing_rate)\n",
    "    to_drop = missing_rate[missing_rate > missing_threshold].index.to_list()\n",
    "    print('{} features with greater than {} missing values.\\n'.format(len(to_drop), missing_threshold))\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.848Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_drop = identify_missing(base_info, missing_threshold=0.9)\n",
    "base_info.drop(to_drop, axis=1, inplace=True)\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.852Z"
    }
   },
   "outputs": [],
   "source": [
    "base_info['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.855Z"
    }
   },
   "outputs": [],
   "source": [
    "base_info['opform'] = base_info['opform'].replace('01', '01-以个人财产出资').replace('02', '02-以家庭共有财产作为个人出资')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.858Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = base_info.select_dtypes(include=['object']).columns.to_list()\n",
    "num_cols = base_info.select_dtypes(exclude=['object']).columns.to_list()\n",
    "cat_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.860Z"
    }
   },
   "outputs": [],
   "source": [
    "# dom, opscope, opfrom, opto\n",
    "# 'dom', 'opscope' 取值太多\n",
    "base_info.drop(['dom', 'opscope', 'opfrom', 'opto'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.863Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in tqdm(['industryphy', 'opform', 'oploc', 'orgid', 'jobid', 'oplocdistrict', 'enttypegb', 'industryco', 'enttype', 'enttypeitem']):\n",
    "    le = LabelEncoder()\n",
    "    base_info[i] = le.fit_transform(base_info[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.865Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.merge(base_info, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.868Z"
    }
   },
   "outputs": [],
   "source": [
    "train = data[data['label'].notnull()]\n",
    "test = data[data['label'].isnull()]\n",
    "sub = test[['id']]\n",
    "# train.shape, test.shape\n",
    "\n",
    "used_cols = [i for i in train.columns if i not in ['id', 'label']]\n",
    "y = train['label']\n",
    "train = train[used_cols]\n",
    "test = test[used_cols]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train, y, test_size=0.25, random_state=2020)\n",
    "\n",
    "cols = X_train.columns\n",
    "useful_dict, useless_dict, useful_cols, useless_cols = auc_select(X_train, y_train, X_valid, y_valid, cols, threshold=0.52)\n",
    "print('AUC useless_cols: \\n', useless_cols)\n",
    "\n",
    "dtrain = lgb.Dataset(X_train, y_train)\n",
    "dvalid = lgb.Dataset(X_valid, y_valid, reference=dtrain)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'metric': 'auc',\n",
    "#     'metric': 'None',  # 用自定义评估函数是将metric设置为'None'\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'lambda_l1': 0,\n",
    "    'lambda_l2': 1,\n",
    "    'num_threads': 23,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'first_metric_only': True,\n",
    "    'is_unbalance': True,\n",
    "    'max_depth': -1,\n",
    "    'seed': 2020\n",
    "}\n",
    "\n",
    "valid_model = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    valid_sets=[dtrain, dvalid],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=300 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.871Z"
    }
   },
   "outputs": [],
   "source": [
    "importance = valid_model.feature_importance(importance_type='gain')\n",
    "feature_name = valid_model.feature_name()\n",
    "\n",
    "df_importance = pd.DataFrame({\n",
    "    'feature_name': feature_name,\n",
    "    'importance': importance\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "df_importance['normalized_importance'] = df_importance['importance'] / df_importance['importance'].sum()\n",
    "df_importance['cumulative_importance'] = np.cumsum(df_importance['normalized_importance'])\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.874Z"
    }
   },
   "outputs": [],
   "source": [
    "record_low_importance = df_importance[df_importance['cumulative_importance'] > 0.999]\n",
    "to_drop = list(record_low_importance['feature_name'])\n",
    "print(to_drop)\n",
    "\n",
    "base_info.drop(to_drop, axis=1, inplace=True)\n",
    "base_info.to_csv('../../input/annual_report_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T15:06:54.876Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.where(valid_model.predict(test) > 0.5, 1, 0)\n",
    "\n",
    "print('Test mean label: ', np.mean(y_test_pred))\n",
    "sub['score'] = y_test_pred\n",
    "sub.to_csv('../../sub/baseline_{}_{}.csv'.format(time.strftime('%Y%m%d'), str(F1)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
