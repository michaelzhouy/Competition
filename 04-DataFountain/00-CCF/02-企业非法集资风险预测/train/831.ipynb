{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:22:41.212353Z",
     "start_time": "2020-11-22T11:22:39.717760Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "import missingno as msno\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,precision_recall_fscore_support,roc_curve,auc,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:22:41.473713Z",
     "start_time": "2020-11-22T11:22:41.214318Z"
    }
   },
   "outputs": [],
   "source": [
    "base_info = pd.read_csv('../input/train/base_info.csv')\n",
    "entprise_evaluate = pd.read_csv('../input/train/entprise_evaluate.csv')\n",
    "entprise_info = pd.read_csv('../input/train/entprise_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:22:41.498588Z",
     "start_time": "2020-11-22T11:22:41.475619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>oplocdistrict</th>\n",
       "      <th>industryphy</th>\n",
       "      <th>industryco</th>\n",
       "      <th>dom</th>\n",
       "      <th>opscope</th>\n",
       "      <th>enttype</th>\n",
       "      <th>enttypeitem</th>\n",
       "      <th>opfrom</th>\n",
       "      <th>opto</th>\n",
       "      <th>state</th>\n",
       "      <th>orgid</th>\n",
       "      <th>jobid</th>\n",
       "      <th>adbusign</th>\n",
       "      <th>townsign</th>\n",
       "      <th>regtype</th>\n",
       "      <th>empnum</th>\n",
       "      <th>compform</th>\n",
       "      <th>parnum</th>\n",
       "      <th>exenum</th>\n",
       "      <th>opform</th>\n",
       "      <th>ptbusscope</th>\n",
       "      <th>venind</th>\n",
       "      <th>enttypeminu</th>\n",
       "      <th>midpreindcode</th>\n",
       "      <th>protype</th>\n",
       "      <th>oploc</th>\n",
       "      <th>regcap</th>\n",
       "      <th>reccap</th>\n",
       "      <th>forreccap</th>\n",
       "      <th>forregcap</th>\n",
       "      <th>congro</th>\n",
       "      <th>enttypegb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47645761dc56bb8c5fae00114b768b5d9b6e917c3aec07c4</td>\n",
       "      <td>340223</td>\n",
       "      <td>M</td>\n",
       "      <td>7513.0</td>\n",
       "      <td>31487d8f256f16bd6244b7251be2ebb24d1db51663c654...</td>\n",
       "      <td>纳米新材料、机械设备、五金配件加工、销售及技术推广服务，道路货物运输。（依法须经批准的项目，...</td>\n",
       "      <td>1100</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>2019-07-11 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>340223010010000000</td>\n",
       "      <td>340200000000115392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2367b4cac96d8598</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9c7fa510616a683058ce97d0bc768a621cd85ab1e87da2a3</td>\n",
       "      <td>340222</td>\n",
       "      <td>O</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>31487d8f256f16bd6244b7251be2ebb27b17bdfd95c8f3...</td>\n",
       "      <td>健身服务。（依法须经批准的项目，经相关部门批准后方可开展经营活动）</td>\n",
       "      <td>9600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>340222060010000000</td>\n",
       "      <td>340200000000112114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31487d8f256f16bd6244b7251be2ebb27b17bdfd95c8f3...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 id  oplocdistrict  \\\n",
       "0  47645761dc56bb8c5fae00114b768b5d9b6e917c3aec07c4         340223   \n",
       "1  9c7fa510616a683058ce97d0bc768a621cd85ab1e87da2a3         340222   \n",
       "\n",
       "  industryphy  industryco                                                dom  \\\n",
       "0           M      7513.0  31487d8f256f16bd6244b7251be2ebb24d1db51663c654...   \n",
       "1           O      8090.0  31487d8f256f16bd6244b7251be2ebb27b17bdfd95c8f3...   \n",
       "\n",
       "                                             opscope  enttype  enttypeitem  \\\n",
       "0  纳米新材料、机械设备、五金配件加工、销售及技术推广服务，道路货物运输。（依法须经批准的项目，...     1100       1150.0   \n",
       "1                  健身服务。（依法须经批准的项目，经相关部门批准后方可开展经营活动）     9600          NaN   \n",
       "\n",
       "                opfrom opto  state               orgid               jobid  \\\n",
       "0  2019-07-11 00:00:00  NaN      6  340223010010000000  340200000000115392   \n",
       "1           2017-09-06  NaN      6  340222060010000000  340200000000112114   \n",
       "\n",
       "   adbusign  townsign  regtype  empnum  compform  parnum  exenum opform  \\\n",
       "0         0         0        1     5.0       NaN     NaN     NaN    NaN   \n",
       "1         0         1        1     3.0       1.0     NaN     NaN     10   \n",
       "\n",
       "   ptbusscope  venind  enttypeminu  midpreindcode  protype  \\\n",
       "0         NaN     NaN       1151.0            NaN      NaN   \n",
       "1         NaN     3.0          NaN            NaN      NaN   \n",
       "\n",
       "                                               oploc  regcap  reccap  \\\n",
       "0                                   2367b4cac96d8598    50.0     NaN   \n",
       "1  31487d8f256f16bd6244b7251be2ebb27b17bdfd95c8f3...    10.0     NaN   \n",
       "\n",
       "   forreccap  forregcap  congro  enttypegb  \n",
       "0        NaN        NaN     NaN       1151  \n",
       "1        NaN        NaN     NaN       9600  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:22:41.509563Z",
     "start_time": "2020-11-22T11:22:41.500550Z"
    }
   },
   "outputs": [],
   "source": [
    "base_info.drop(['midpreindcode', 'ptbusscope'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:22:41.518501Z",
     "start_time": "2020-11-22T11:22:41.510522Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_concat(df, col1, col2):\n",
    "    col = col1 + '_' + col2\n",
    "    df[col] = df[col1].astype(str) + '_' + df[col2].astype(str)\n",
    "    return df, col\n",
    "\n",
    "\n",
    "def count_encode(df, cat_cols, freq):\n",
    "    for i in cat_cols:\n",
    "        name_dict = dict(zip(*np.unique(df[i], return_counts=True)))\n",
    "        df['{}_count'.format(i)] = df[i].apply(lambda x: -999 if name_dict[x] < freq else name_dict[x])\n",
    "    return df\n",
    "\n",
    "\n",
    "def label_encode(df, cat_cols, verbose=True):\n",
    "    for col in cat_cols:\n",
    "        df[col], _ = df[col].factorize(sort=True)\n",
    "        if df[col].max() > 32000:\n",
    "            df[col] = df[col].astype('int32')\n",
    "        else:\n",
    "            df[col] = df[col].astype('int16')\n",
    "        if verbose:\n",
    "            print(col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:23:19.763333Z",
     "start_time": "2020-11-22T11:22:41.519500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industryphy\n",
      "dom\n",
      "opform\n",
      "oploc\n",
      "oplocdistrict_oploc\n",
      "enttype_enttypeitem\n",
      "enttype_enttypeminu\n",
      "enttype_enttypegb\n",
      "enttypeitem_enttypeminu\n",
      "enttypeitem_enttypegb\n",
      "enttypeminu_enttypegb\n",
      "industryphy_industryco\n",
      "industryphy_venind\n",
      "industryco_venind\n",
      "industryphy_industryco_venind\n",
      "orgid_jobid\n",
      "opscope\n"
     ]
    }
   ],
   "source": [
    "le_cols = ['industryphy', 'dom', 'opform', 'oploc']\n",
    "cat_cols = ['industryphy', 'industryco',\n",
    "            'enttype', 'enttypeitem', 'enttypeminu', 'enttypegb',\n",
    "            'oplocdistrict', 'dom', 'oploc', 'state']\n",
    "\n",
    "# 时间相关\n",
    "base_info['opfrom'] = pd.to_datetime(base_info['opfrom'])\n",
    "base_info['opto'] = pd.to_datetime(base_info['opto'])\n",
    "base_info['opfrom_TONOW'] = (datetime.now() - base_info['opfrom']).dt.days\n",
    "base_info['opfrom_TIME'] = (base_info['opto'] - base_info['opfrom']).dt.days\n",
    "base_info.drop(['opfrom', 'opto'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# 企业人数相关\n",
    "base_info['person_SUM'] = base_info[['empnum', 'parnum', 'exenum']].sum(1)\n",
    "base_info['person_NULL_SUM'] = base_info[['empnum', 'parnum', 'exenum']].isnull().astype(int).sum(1)\n",
    "\n",
    "\n",
    "# 地址相关\n",
    "district_cols = ['oplocdistrict', 'dom', 'oploc', 'townsign']\n",
    "# le_cols += district_cols\n",
    "# cat_cols += ['oplocdistrict', 'dom', 'oploc']\n",
    "base_info['district_flag1'] = (base_info['oplocdistrict'].astype(str)[:6] == base_info['orgid'].astype(str)[:6]).astype(int)\n",
    "base_info['district_flag2'] = (base_info['oplocdistrict'].astype(str)[:6] == base_info['jobid'].astype(str)[:6]).astype(int)\n",
    "base_info['district_flag3'] = (base_info['orgid'].astype(str)[:6] == base_info['jobid'].astype(str)[:6]).astype(int)\n",
    "base_info, col = get_concat(base_info, 'oplocdistrict', 'oploc')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "# base_info, col = get_concat(base_info, 'oplocdistrict', 'townsign')\n",
    "# le_cols.append(col)\n",
    "# cat_cols.append(col)\n",
    "# base_info, col = get_concat(base_info, 'oploc', 'townsign')\n",
    "# le_cols.append(col)\n",
    "# cat_cols.append(col)\n",
    "\n",
    "\n",
    "# 企业类型相关\n",
    "enttype_cols = ['enttype', 'enttypeitem', 'enttypeminu', 'enttypegb']\n",
    "# le_cols += enttype_cols\n",
    "# cat_cols += enttype_cols\n",
    "base_info, col = get_concat(base_info, 'enttype', 'enttypeitem')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "base_info, col = get_concat(base_info, 'enttype', 'enttypeminu')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "base_info, col = get_concat(base_info, 'enttype', 'enttypegb')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "base_info, col = get_concat(base_info, 'enttypeitem', 'enttypeminu')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "base_info, col = get_concat(base_info, 'enttypeitem', 'enttypegb')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "base_info, col = get_concat(base_info, 'enttypeminu', 'enttypegb')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "\n",
    "\n",
    "# 行业类型相关\n",
    "industry_cols = ['industryphy', 'industryco', 'venind']\n",
    "# le_cols += industry_cols\n",
    "# cat_cols += industry_cols\n",
    "base_info, col = get_concat(base_info, 'industryphy', 'industryco')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "base_info, col = get_concat(base_info, 'industryphy', 'venind')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "base_info, col = get_concat(base_info, 'industryco', 'venind')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "base_info['industryphy_industryco_venind'] = base_info['industryphy'].astype(str) + '_' + base_info['industryco'].astype(str) + '_' + base_info['venind'].astype(str)\n",
    "le_cols.append('industryphy_industryco_venind')\n",
    "cat_cols.append('industryphy_industryco_venind')\n",
    "\n",
    "# 标识相关\n",
    "id_cols = ['orgid', 'jobid']\n",
    "# le_cols += id_cols\n",
    "# cat_cols += id_cols\n",
    "base_info, col = get_concat(base_info, 'orgid', 'jobid')\n",
    "le_cols.append(col)\n",
    "cat_cols.append(col)\n",
    "\n",
    "\n",
    "# 其他\n",
    "other_cols = ['adbusign', 'opform', 'state', 'protype', 'regtype', 'compform', 'opscope']\n",
    "# le_cols += other_cols\n",
    "# cat_cols += ['opform', 'state', 'protype', 'regtype', 'compform', 'opscope']\n",
    "\n",
    "\n",
    "# Count编码\n",
    "# base_info = count_encode(base_info, le_cols, 10)\n",
    "for col in cat_cols:\n",
    "    base_info[col + '_COUNT'] = base_info[col].map(base_info[col].value_counts())\n",
    "    col_idx = base_info[col].value_counts()\n",
    "    for idx in col_idx[col_idx < 10].index:\n",
    "        base_info[col] = base_info[col].replace(idx, -1)  \n",
    "\n",
    "\n",
    "# Label Encoder\n",
    "\n",
    "base_info = label_encode(base_info, le_cols + ['opscope'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:23:19.767417Z",
     "start_time": "2020-11-22T11:23:19.764303Z"
    }
   },
   "outputs": [],
   "source": [
    "# train = pd.merge(base_info, entprise_info, on='id')\n",
    "\n",
    "# entprise_evaluate = entprise_evaluate[['id']]\n",
    "# test = pd.merge(base_info, entprise_evaluate, on='id')\n",
    "\n",
    "\n",
    "# used_cols = [i for i in train.columns if i not in ['id', 'label']]\n",
    "# y = train['label']\n",
    "# train = train[used_cols]\n",
    "# test = test[used_cols]\n",
    "\n",
    "# num_folds=5\n",
    "# kfold = StratifiedKFold(n_splits=num_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "# oof_probs = np.zeros(train.shape[0])\n",
    "# output_probs = np.zeros((test.shape[0], 5))\n",
    "# offline_score = []\n",
    "# feature_importance_df = pd.DataFrame()\n",
    "\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kfold.split(train, y)):\n",
    "#     X_train, y_train = train.iloc[train_idx], y.iloc[train_idx]\n",
    "#     X_valid, y_valid = train.iloc[valid_idx], y.iloc[valid_idx]\n",
    "    \n",
    "#     model=CatBoostClassifier(\n",
    "#         loss_function=\"Logloss\",\n",
    "#         eval_metric=\"F1\",\n",
    "#         task_type=\"GPU\",\n",
    "#         learning_rate=0.01,\n",
    "#         iterations=100000,\n",
    "#         random_seed=2020,\n",
    "#         od_type=\"Iter\",\n",
    "#         depth=8,\n",
    "#         early_stopping_rounds=500\n",
    "#     )\n",
    "\n",
    "#     clf = model.fit(X_train, y_train, eval_set=(X_valid,y_valid), verbose=500, cat_features=le_cols)\n",
    "#     yy_pred_valid=clf.predict(X_valid)\n",
    "#     y_pred_valid = clf.predict(X_valid, prediction_type='Probability')[:, -1]\n",
    "#     oof_probs[valid_idx] = y_pred_valid\n",
    "#     offline_score.append(f1_score(y_valid, yy_pred_valid))\n",
    "#     output_probs[:, fold] = clf.predict(test, prediction_type='Probability')[:,-1]\n",
    "    \n",
    "#     # feature importance\n",
    "#     fold_importance_df = pd.DataFrame()\n",
    "#     fold_importance_df[\"feature\"] = model.feature_names_\n",
    "#     fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "#     fold_importance_df[\"fold\"] = fold + 1\n",
    "#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "# print('OOF-MEAN-F1:%.6f, OOF-STD-F1:%.6f' % (np.mean(offline_score), np.std(offline_score)))\n",
    "# print('feature importance:')\n",
    "# feature_importance_df_ = feature_importance_df.groupby('feature', as_index=False)['importance'].mean().sort_values(by='importance', ascending=False)\n",
    "# feature_importance_df_['normalized_importance'] = feature_importance_df_['importance'] / feature_importance_df_['importance'].sum()\n",
    "# feature_importance_df_['cumulative_importance'] = np.cumsum(feature_importance_df_['normalized_importance'])\n",
    "# record_low_importance = feature_importance_df_[feature_importance_df_['cumulative_importance'] > 0.99]\n",
    "# to_drop = list(record_low_importance['feature'])\n",
    "# print(to_drop)\n",
    "# # print(feature_importance_df_.head(15))\n",
    "# print(feature_importance_df_)\n",
    "# # feature_importance_df_.to_csv(\"./importance.csv\")\n",
    "\n",
    "# sub['score'] = np.mean(output_probs, axis=1)\n",
    "# # print(sub['score'])\n",
    "# sub.to_csv('cat_sub_{}_{}.csv'.format(time.strftime('%Y%m%d'), np.mean(offline_score)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:23:19.848949Z",
     "start_time": "2020-11-22T11:23:19.769291Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.merge(base_info, entprise_info, on='id')\n",
    "\n",
    "entprise_evaluate = entprise_evaluate[['id']]\n",
    "test_data = pd.merge(base_info, entprise_evaluate, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:23:19.858731Z",
     "start_time": "2020-11-22T11:23:19.849756Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_score(y_test,y_pre):\n",
    "    _,_,f_class,_=precision_recall_fscore_support(y_true=y_test,y_pred=y_pre,labels=[0,1],average=None)\n",
    "    fper_class={'合法':f_class[0],'违法':f_class[1],'f1':f1_score(y_test,y_pre)}\n",
    "    return fper_class\n",
    "\n",
    "\n",
    "def k_fold_serachParmaters(model,train_val_data,train_val_kind, test_kind):\n",
    "    mean_f1=0\n",
    "    mean_f1Train=0\n",
    "    n_splits=5\n",
    "    \n",
    "    cat_features = cat_cols\n",
    "    \n",
    "    sk = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "    pred_Test = np.zeros(len(test_kind))\n",
    "    for train, test in sk.split(train_val_data, train_val_kind):\n",
    "        x_train = train_val_data.iloc[train]\n",
    "        y_train = train_val_kind.iloc[train]\n",
    "        x_test = train_val_data.iloc[test]\n",
    "        y_test = train_val_kind.iloc[test]\n",
    "\n",
    "        model.fit(x_train, y_train, \n",
    "                  eval_set=[(x_test, y_test)], \n",
    "                  categorical_feature = cat_features,\n",
    "                 early_stopping_rounds=100,\n",
    "                 verbose=False)\n",
    "        \n",
    "        pred = model.predict(x_test)\n",
    "        fper_class = eval_score(y_test,pred)\n",
    "        \n",
    "        pred_Train = model.predict(x_train)\n",
    "        pred_Test += model.predict_proba(test_kind)[:, 1]/n_splits\n",
    "        fper_class_train = eval_score(y_train,pred_Train)\n",
    "\n",
    "        mean_f1 += fper_class['f1']/n_splits\n",
    "        mean_f1Train+=fper_class_train['f1']/n_splits\n",
    "        # print(mean_f1, mean_f1Train)\n",
    "        \n",
    "        \n",
    "    return mean_f1, pred_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:24:17.067212Z",
     "start_time": "2020-11-22T11:23:19.859729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8368273175940117 0.0018629674140329677\n"
     ]
    }
   ],
   "source": [
    "score_tta = None\n",
    "score_list = []\n",
    "\n",
    "tta_fold = 20\n",
    "for _ in range(tta_fold):\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        num_leaves=np.random.randint(6, 10), min_child_samples= np.random.randint(2,5),\n",
    "        max_depth=5,learning_rate=0.03,\n",
    "        n_estimators=150,n_jobs=-1)\n",
    "\n",
    "    score, test_pred = k_fold_serachParmaters(clf,\n",
    "                           train_data.drop(['id', 'label'], axis=1),\n",
    "                           train_data['label'],\n",
    "                           test_data.drop(['id'], axis=1),\n",
    "                          )\n",
    "\n",
    "    if score_tta is None:\n",
    "        score_tta = test_pred/tta_fold\n",
    "    else:\n",
    "        score_tta += test_pred/tta_fold\n",
    "    # print(score)\n",
    "    score_list.append(score)\n",
    "    \n",
    "print(np.array(score_list).mean(), np.array(score_list).std())\n",
    "# 0.8478168974849689 0.83884757\n",
    "\n",
    "# 0.8420447002972562 0.00198977186270193\n",
    "# 0.8430490420761639 0.0022246925904664443\n",
    "# 0.8359080768530107 0.0014376075368214521\n",
    "# 0.8353250245440478 0.0011930088571253086\n",
    "# 0.8368273175940117 0.0018629674140329677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T11:24:17.167211Z",
     "start_time": "2020-11-22T11:24:17.070205Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data['score'] = score_tta\n",
    "test_data[['id', 'score']].to_csv('lgb_sub_{}_{}.csv'.format(time.strftime('%Y%m%d'), np.array(score_list).mean()), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
