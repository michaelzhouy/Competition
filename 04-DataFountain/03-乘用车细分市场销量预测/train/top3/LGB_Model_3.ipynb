{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:22:17.030103Z",
     "start_time": "2021-06-16T01:22:15.414530Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:22:17.115567Z",
     "start_time": "2021-06-16T01:22:17.032838Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '../../input/Round1/'\n",
    "\n",
    "# train_user_reply_data = pd.read_csv(data_path + 'train_user_reply_data.csv', encoding='utf-8')\n",
    "train_search_data = pd.read_csv(data_path + 'train_search_data.csv', encoding='utf-8')\n",
    "train_sales_data = pd.read_csv(data_path + 'train_sales_data.csv', encoding='utf-8')\n",
    "evaluation_public = pd.read_csv(data_path + 'evaluation_public.csv', encoding='utf-8')\n",
    "\n",
    "train_sales_data = train_sales_data.merge(train_search_data, on=['province', 'adcode', 'model', 'regYear', 'regMonth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 固定车型和省份顺序-样本顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:22:17.122975Z",
     "start_time": "2021-06-16T01:22:17.118465Z"
    }
   },
   "outputs": [],
   "source": [
    "cars = ['f8a6975573af1b33', '2a2ab41f8f6ff1cb', 'd4efbebb087fd03f', '3e21824be728cbec',\n",
    "        'ea489c253676aafc', '6155b214590c66e6', 'fc32b1a017b34efe', '9c1c7ee8ebdda299',\n",
    "        'fde95ea242abd896', '7a7885e2d7c00bcf', '7245e0ee27b195cd', 'b25c4e2e3856af22',\n",
    "        '7aab7fca2470987e', 'feabbf46658382b9', '04e66e578f653ab9', '5d7fb682edd0f937',\n",
    "        'b4be3a4917289c82', '54fc07138d70374c', 'ef76a85c4b39f693', 'bb9fbec9a2833839',\n",
    "        '3c974920a76ac9c1', '212083a9246d2fd3', '4f79773e600518a6', 'af6f4f548684e14d',\n",
    "        '936168bd4850913d', 'cd5841d44fd7625e', '0797526c057dcf5b', 'a207df29ec9583f0',\n",
    "        '3d7554f1f56dd664', '7023efdab9cedc03', 'da457d15788fe8ee', '12f8b7e14947c34d',\n",
    "        '28e29f2c03dcd84c', '63065128401bb3ff', 'a432c483b5beb856', '37aa9169b575ef79',\n",
    "        '17bc272c93f19d56', '61e73e32ad101892', '4a103c30d593fbbe', '2d0d2c3403909fdb',\n",
    "        '6858d6dfe680bdf7', '17363f08d683d52b', '346393c2c6305fb1', '5b1c11c3efed5312',\n",
    "        '97f15de12cfabbd5', 'a9a43d1a7ecbe75d', '7cf283430b3b5e38', 'c6833cb891626c17',\n",
    "        'a28bb927b6fcb33c', 'dff803b4024d261d', '02aab221aabc03b9', 'f5d69960089c3614',\n",
    "        '06880909932890ca', '79de4e4b24c35b04', 'd0f245b8781e3631', 'c06a2a387c0ee510',\n",
    "        'cc21c7e91a3b5a0c', 'f270f6a489c6a9d7', '8c915fe4632fb9fa', 'c6cd4e0e073f5ac2']\n",
    "\n",
    "provinces = ['浙江', '福建', '四川', '陕西', '安徽', '湖南', '广东', '云南', '上海', '山东',\n",
    "             '湖北', '黑龙江', '江苏', '广西', '内蒙古', '辽宁', '北京', '重庆', '河北', '山西',\n",
    "             '江西', '河南']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:22:17.130012Z",
     "start_time": "2021-06-16T01:22:17.125550Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred, model):\n",
    "    data = pd.DataFrame({'model': model, 'salesVolume': y_true, 'label': y_pred})\n",
    "    data['label'] = data['label'].map(lambda index: -index if index < 0 else index)\n",
    "    res, count = 0, 0\n",
    "    for index, cars in data.groupby('model'):\n",
    "        a = np.array(cars['salesVolume'])\n",
    "        b = np.array(cars['label'])\n",
    "        temp = np.sqrt(np.sum((a - b) ** 2) / len(a)) / np.mean(a)\n",
    "        res += temp\n",
    "        count += 1\n",
    "#         print(temp)\n",
    "    return 1 - (res / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取训练/测试数据索引下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:22:17.138535Z",
     "start_time": "2021-06-16T01:22:17.132138Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_feature(windows_size, before):\n",
    "    # windows_size=1, before=10\n",
    "    # windows_size=2, before=9\n",
    "    # windows_size=3, before=8\n",
    "    # windows_size=4, before=7\n",
    "    features = pd.DataFrame()\n",
    "    # 每个车型，每个省份，car_province_part就相当于只有24个月的数据\n",
    "    for car in cars:\n",
    "        for province in provinces:\n",
    "            car_province_part = train_sales_data[(train_sales_data['model'] == car) & (train_sales_data['province'] == province)]\n",
    "            # shift：label为下个月的销售量\n",
    "            car_province_part['label'] = car_province_part['salesVolume'].shift(-windows_size)\n",
    "            # print('car_province_part:\\n', car_province_part)\n",
    "            # car_province_part的行数为24，这里取前23行做训练集\n",
    "            car_province_part = car_province_part[before: 24-windows_size]\n",
    "            features = pd.concat([features, car_province_part], axis=0)\n",
    "    features.index = range(len(features))\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_test_feature(windows_size, before):\n",
    "    features = pd.DataFrame()\n",
    "    for car in cars:\n",
    "        for province in provinces:\n",
    "            car_province_part = train_sales_data[(train_sales_data['model'] == car) & (train_sales_data['province'] == province)]\n",
    "            car_province_part['label'] = car_province_part['salesVolume'].shift(-windows_size)\n",
    "            # print('car_province_part:\\n', car_province_part)\n",
    "            # 最后一行用作验证\n",
    "            car_province_part = car_province_part[-1:]\n",
    "            features = pd.concat([features, car_province_part], axis=0)\n",
    "    features.index = range(len(features))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:22:17.202491Z",
     "start_time": "2021-06-16T01:22:17.141743Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_basic_feature(windows_size, before, data_set_name):\n",
    "    # windows_size=1, before=10, data_set_name='train'\n",
    "    features = pd.DataFrame()\n",
    "    # 遍历\n",
    "    for car in cars:\n",
    "        for province in provinces:\n",
    "            car_province_part = train_sales_data[(train_sales_data['model'] == car) & (train_sales_data['province'] == province)].copy()\n",
    "            \n",
    "            # 对popularity和salesVolume做log变换\n",
    "            car_province_part['popularity'] = car_province_part['popularity'].apply(lambda index: np.log(index))\n",
    "            car_province_part['salesVolume'] = car_province_part['salesVolume'].apply(lambda index: np.log(index))\n",
    "            \n",
    "            # 春节标记特征\n",
    "            car_province_part['is_spring_festival'] = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                                                       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "            car_province_part['distance_spring_festival'] = [1, 0, 1, 2, 3, 4, 5, 5, 4, 3, 2, 1,\n",
    "                                                             0, 1, 2, 3, 4, 5, 6, 6, 5, 4, 3, 2]\n",
    "            \n",
    "            # 一阶差分\n",
    "            for index in range(1, before):\n",
    "                # salesVolume\n",
    "                # shift\n",
    "                car_province_part['salesVolume_' + str(index)] = car_province_part['salesVolume'].shift(index)\n",
    "                # 后一项减前一项\n",
    "                car_province_part['salesVolume_diff_' + str(index)] = car_province_part['salesVolume'].diff(index)\n",
    "                # shift的比值\n",
    "                car_province_part['salesVolume_qoq_' + str(index)] = (car_province_part['salesVolume']\n",
    "                                                                      / car_province_part['salesVolume_' + str(index)])\n",
    "                \n",
    "                # popularity\n",
    "                car_province_part['popularity_' + str(index)] = car_province_part['popularity'].shift(index)\n",
    "                car_province_part['popularity_diff_' + str(index)] = car_province_part['popularity'].diff(index)\n",
    "                car_province_part['popularity_hb_' + str(index)] = (car_province_part['popularity']\n",
    "                                                                    / car_province_part['popularity_' + str(index)])\n",
    "\n",
    "            # 二阶差分\n",
    "            for index in range(1, before-1):   \n",
    "                car_province_part['salesVolume_diff2_' + str(index)] = car_province_part['salesVolume_diff_' + str(index)].diff(1)\n",
    "\n",
    "            # 历史统计特征\n",
    "            salesVolume = list(car_province_part['salesVolume'])\n",
    "            popularity = list(car_province_part['popularity'])\n",
    "            # index=1, 2, 3, 4, ..., 24\n",
    "            car_province_part['index'] = 1\n",
    "            car_province_part['index'] = car_province_part['index'].cumsum()\n",
    "            car_province_part['salesVolume_his'] = car_province_part['index'].map(lambda index: salesVolume[index-7: index])\n",
    "            car_province_part['popularity_his'] = car_province_part['index'].map(lambda index: popularity[index-7: index])\n",
    "\n",
    "            car_province_part['salesVolume_his_diff'] = car_province_part['salesVolume_his'].map(lambda index: np.diff(index))\n",
    "            car_province_part['popularity_his_diff'] = car_province_part['popularity_his'].map(lambda index: np.diff(index))\n",
    "\n",
    "            def pth(array):\n",
    "                return np.max(array) - np.min(array)\n",
    "\n",
    "            fea_name = ['max', 'min', 'aver', 'var', 'pth']\n",
    "            fun_name = [np.max, np.min, np.average, np.var, pth]\n",
    "            for i in range(len(fun_name)):\n",
    "                car_province_part['salesVolume_his_' + fea_name[i]] = car_province_part['salesVolume_his'].apply(\n",
    "                    lambda index: 0 if len(index) == 0 else fun_name[i](index)\n",
    "                )                \n",
    "                car_province_part['salesVolume_his_diff_' + fea_name[i]] = car_province_part['salesVolume_his_diff'].apply(\n",
    "                    lambda index: 0 if len(index) == 0 else fun_name[i](index)\n",
    "                )\n",
    "            \n",
    "            car_province_part.drop(['index', 'salesVolume_his', 'popularity_his', 'salesVolume_his_diff', 'popularity_his_diff'],\n",
    "                                   axis=1,\n",
    "                                   inplace=True)\n",
    "            \n",
    "            # 数据集划分\n",
    "            if data_set_name == 'train':\n",
    "                car_province_part = car_province_part[before: 24-windows_size]\n",
    "            else:\n",
    "                car_province_part = car_province_part[-1:]\n",
    "\n",
    "            car_province_part.drop(['popularity'], axis=1, inplace=True)    ###  , 'day_count', 'day_salesVolume', 'popularity'\n",
    "            features = pd.concat([features, car_province_part], axis=0, ignore_index=True)\n",
    "\n",
    "#     print(features.head())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:22:17.208025Z",
     "start_time": "2021-06-16T01:22:17.205063Z"
    }
   },
   "outputs": [],
   "source": [
    "test_prob_collection = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 一月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:24:21.211635Z",
     "start_time": "2021-06-16T01:22:17.211321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feature.columns: Index(['province', 'adcode', 'model', 'bodyType', 'regYear', 'regMonth',\n",
      "       'label', 'salesVolume', 'is_spring_festival',\n",
      "       'distance_spring_festival', 'salesVolume_1', 'salesVolume_diff_1',\n",
      "       'salesVolume_qoq_1', 'popularity_1', 'popularity_diff_1',\n",
      "       'popularity_hb_1', 'salesVolume_2', 'salesVolume_diff_2',\n",
      "       'salesVolume_qoq_2', 'popularity_2', 'popularity_diff_2',\n",
      "       'popularity_hb_2', 'salesVolume_3', 'salesVolume_diff_3',\n",
      "       'salesVolume_qoq_3', 'popularity_3', 'popularity_diff_3',\n",
      "       'popularity_hb_3', 'salesVolume_4', 'salesVolume_diff_4',\n",
      "       'salesVolume_qoq_4', 'popularity_4', 'popularity_diff_4',\n",
      "       'popularity_hb_4', 'salesVolume_5', 'salesVolume_diff_5',\n",
      "       'salesVolume_qoq_5', 'popularity_5', 'popularity_diff_5',\n",
      "       'popularity_hb_5', 'salesVolume_6', 'salesVolume_diff_6',\n",
      "       'salesVolume_qoq_6', 'popularity_6', 'popularity_diff_6',\n",
      "       'popularity_hb_6', 'salesVolume_7', 'salesVolume_diff_7',\n",
      "       'salesVolume_qoq_7', 'popularity_7', 'popularity_diff_7',\n",
      "       'popularity_hb_7', 'salesVolume_8', 'salesVolume_diff_8',\n",
      "       'salesVolume_qoq_8', 'popularity_8', 'popularity_diff_8',\n",
      "       'popularity_hb_8', 'salesVolume_9', 'salesVolume_diff_9',\n",
      "       'salesVolume_qoq_9', 'popularity_9', 'popularity_diff_9',\n",
      "       'popularity_hb_9', 'salesVolume_diff2_1', 'salesVolume_diff2_2',\n",
      "       'salesVolume_diff2_3', 'salesVolume_diff2_4', 'salesVolume_diff2_5',\n",
      "       'salesVolume_diff2_6', 'salesVolume_diff2_7', 'salesVolume_diff2_8',\n",
      "       'salesVolume_his_max', 'salesVolume_his_diff_max',\n",
      "       'salesVolume_his_min', 'salesVolume_his_diff_min',\n",
      "       'salesVolume_his_aver', 'salesVolume_his_diff_aver',\n",
      "       'salesVolume_his_var', 'salesVolume_his_diff_var',\n",
      "       'salesVolume_his_pth', 'salesVolume_his_diff_pth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "size, pre = 1, 10  # 4\n",
    "train_feature  = get_train_feature(size, pre) # [10: 23] 行用作train\n",
    "test_feature  = get_test_feature(size, pre) # 24 行用作验证\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  'salesVolume'\n",
    "\n",
    "categorial_name = [0, 1, 2, 3, 4, 6, 7]\n",
    "drop_cols = ['salesVolume', 'popularity']\n",
    "\n",
    "# train\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "print('train_feature.columns:', train_feature.columns)\n",
    "\n",
    "# test\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "# print('test_feature.columns:', test_feature.columns)\n",
    "\n",
    "# 将2017年12月的特征作为待预测2018年1月的特征，注意label是空\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 1\n",
    "###############################\n",
    "\n",
    "# test index\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 11)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "# train index\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "#  Label Encoder\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:24:28.298755Z",
     "start_time": "2021-06-16T01:24:21.214857Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.497356\n",
      "[200]\tvalid_0's rmse: 0.479672\n",
      "[300]\tvalid_0's rmse: 0.467463\n",
      "[400]\tvalid_0's rmse: 0.463958\n",
      "[500]\tvalid_0's rmse: 0.46287\n",
      "[600]\tvalid_0's rmse: 0.461786\n",
      "[700]\tvalid_0's rmse: 0.461684\n",
      "Early stopping, best iteration is:\n",
      "[635]\tvalid_0's rmse: 0.460652\n",
      "importance:\n",
      " [1242 2782   12  171 1652  684  225  140  207  119  108   66  202  169\n",
      "  223  203  235   70  144  174  117  204  169   53  118   93  107  141\n",
      "  152   65  100   82  165  178  162   67  105   86  119  174  135   41\n",
      "  115  105  136  175  128   50  107  137  181  170  124   60  107   76\n",
      "  302  218  186   64  102   91  206  250  239  285  229  216  168  236\n",
      "  107  128  123  116  231   36  175  123  182  158]\n",
      "model train over, rmse: 0.7028459870461325\n",
      "train_feature.shape:  (17160, 80)\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'rmse',\n",
    "    'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 2 ** 5 - 1,    # 2 ** 5 - 1\n",
    "    # 'min_child_samples': 100,\n",
    "    'max_depth': 6,    # 6\n",
    "    'subsample': 0.8,   # 0.8\n",
    "    'subsample_freq': 5,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 2020,\n",
    "    'nthread': -1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# num_boost_round: 5000   early_stopping_rounds:100\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "# feature importance\n",
    "importance = module.feature_importance()\n",
    "print('importance:\\n', importance)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params,\n",
    "                  lgb_data,\n",
    "                  num_boost_round=iters,\n",
    "                  categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "# print('predict:\\n', predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)   \n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)\n",
    "print('train_feature.shape: ', train_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 二月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:26:41.572099Z",
     "start_time": "2021-06-16T01:24:28.301065Z"
    }
   },
   "outputs": [],
   "source": [
    "size, pre = 2, 9  # 4\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 2\n",
    "######################################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 10)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:26:45.188694Z",
     "start_time": "2021-06-16T01:26:41.574716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.597728\n",
      "[200]\tvalid_0's rmse: 0.554425\n",
      "[300]\tvalid_0's rmse: 0.54585\n",
      "[400]\tvalid_0's rmse: 0.546025\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid_0's rmse: 0.542689\n",
      "model train over, rmse: 0.6585909537287084\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "      'boosting_type': 'gbdt',\n",
    "      'objective': 'rmse',\n",
    "      'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "      'learning_rate': 0.03,\n",
    "      'num_leaves': 2 ** 5 - 1,\n",
    "      # 'min_child_samples': 100,\n",
    "      'max_depth': 6,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 5,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'seed': 2020,\n",
    "      'nthread': -1,\n",
    "      'verbose': -1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# categorial_name = ['adcode', 'model', 'bodyType', 'regYear', 'regMonth']\n",
    "\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params, lgb_data, num_boost_round=iters, categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "# print('predict: \\n', predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)   \n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 三月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:28:26.774045Z",
     "start_time": "2021-06-16T01:26:45.191142Z"
    }
   },
   "outputs": [],
   "source": [
    "size, pre = 3, 8   # 5\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 3\n",
    "##############################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 9)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:28:28.996674Z",
     "start_time": "2021-06-16T01:28:26.777420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.626519\n",
      "[200]\tvalid_0's rmse: 0.614531\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's rmse: 0.613131\n",
      "model train over, rmse: 0.6085811911978194\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model\n",
    "params = {\n",
    "      'boosting_type': 'gbdt',\n",
    "      'objective': 'rmse',\n",
    "      'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "      'learning_rate': 0.03,\n",
    "      'num_leaves': 2 ** 5 - 1,\n",
    "      # 'min_child_samples': 100,\n",
    "      'max_depth': 6,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 5,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'seed': 2020,\n",
    "      'nthread': -1,\n",
    "      'verbose': -1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# categorial_name = ['adcode', 'model', 'bodyType', 'regYear', 'regMonth']\n",
    "\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params, lgb_data, num_boost_round=iters, categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "# print('predict:\\n', predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)\n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 四月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:30:03.116365Z",
     "start_time": "2021-06-16T01:28:28.998921Z"
    }
   },
   "outputs": [],
   "source": [
    "size, pre = 4, 7   # 5\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 4\n",
    "###############################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 8)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:30:07.577120Z",
     "start_time": "2021-06-16T01:30:03.119931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.682109\n",
      "[200]\tvalid_0's rmse: 0.64402\n",
      "[300]\tvalid_0's rmse: 0.637194\n",
      "[400]\tvalid_0's rmse: 0.636991\n",
      "[500]\tvalid_0's rmse: 0.639042\n",
      "Early stopping, best iteration is:\n",
      "[416]\tvalid_0's rmse: 0.635467\n",
      "model train over, rmse: 0.6137120293380912\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "      'boosting_type': 'gbdt',\n",
    "      'objective': 'rmse',\n",
    "      'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "      'learning_rate': 0.03,\n",
    "      'num_leaves': 2 ** 5 - 1,\n",
    "      # 'min_child_samples': 100,\n",
    "      'max_depth': 6,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 5,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'seed': 2020,\n",
    "      'nthread': -1,\n",
    "      'verbose': -1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# categorial_name = ['adcode', 'model', 'bodyType', 'regYear', 'regMonth']\n",
    "\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params, lgb_data, num_boost_round=iters, categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "# print(predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)\n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:30:07.585610Z",
     "start_time": "2021-06-16T01:30:07.579517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17160, 59)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:30:07.599823Z",
     "start_time": "2021-06-16T01:30:07.587906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>adcode</th>\n",
       "      <th>model</th>\n",
       "      <th>regYear</th>\n",
       "      <th>regMonth</th>\n",
       "      <th>forecastVolum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>浙江</td>\n",
       "      <td>330000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>840.575706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>福建</td>\n",
       "      <td>350000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>449.643631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>四川</td>\n",
       "      <td>510000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>658.649902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>陕西</td>\n",
       "      <td>610000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>151.252980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>安徽</td>\n",
       "      <td>340000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>654.570691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  province  adcode             model  regYear  regMonth  forecastVolum\n",
       "0       浙江  330000  f8a6975573af1b33     2018         1     840.575706\n",
       "1       福建  350000  f8a6975573af1b33     2018         1     449.643631\n",
       "2       四川  510000  f8a6975573af1b33     2018         1     658.649902\n",
       "3       陕西  610000  f8a6975573af1b33     2018         1     151.252980\n",
       "4       安徽  340000  f8a6975573af1b33     2018         1     654.570691"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob_collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:30:07.658381Z",
     "start_time": "2021-06-16T01:30:07.601992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.69867424242426"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob_collection.index = range(len(test_prob_collection))\n",
    "evaluation_public = evaluation_public.merge(test_prob_collection, on=['province', 'adcode', 'model', 'regYear', 'regMonth'], how='left')\n",
    "evaluation_public['forecastVolum'] = evaluation_public['forecastVolum_y']\n",
    "evaluation_public['forecastVolum'] = evaluation_public['forecastVolum'].apply(lambda index: int(np.round(index)))\n",
    "evaluation_public['forecastVolum'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:31:27.048551Z",
     "start_time": "2021-06-16T01:31:27.038191Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation_public[['id', 'forecastVolum']].to_csv('../../sub/sub_method_one.csv', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T01:31:32.081734Z",
     "start_time": "2021-06-16T01:31:32.051638Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regMonth</th>\n",
       "      <th>forecastVolum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>553.784091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>364.019697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>475.586364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>481.404545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regMonth  forecastVolum\n",
       "0         1     553.784091\n",
       "1         2     364.019697\n",
       "2         3     475.586364\n",
       "3         4     481.404545"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_public.describe()\n",
    "evaluation_public.groupby(['regMonth'], as_index=False)['forecastVolum'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
