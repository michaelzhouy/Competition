{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:59:05.368762Z",
     "start_time": "2021-06-15T22:59:01.120026Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:59:05.589785Z",
     "start_time": "2021-06-15T22:59:05.371735Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '../../input/Round1/'\n",
    "\n",
    "# train_user_reply_data = pd.read_csv(data_path + 'train_user_reply_data.csv', encoding='utf-8')\n",
    "train_search_data = pd.read_csv(data_path + 'train_search_data.csv', encoding='utf-8')\n",
    "train_sales_data = pd.read_csv(data_path + 'train_sales_data.csv', encoding='utf-8')\n",
    "evaluation_public = pd.read_csv(data_path + 'evaluation_public.csv', encoding='utf-8')\n",
    "\n",
    "train_sales_data = train_sales_data.merge(train_search_data, on=['province', 'adcode', 'model', 'regYear', 'regMonth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 固定车型和省份顺序-样本顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:59:05.623766Z",
     "start_time": "2021-06-15T22:59:05.593783Z"
    }
   },
   "outputs": [],
   "source": [
    "cars = ['f8a6975573af1b33', '2a2ab41f8f6ff1cb', 'd4efbebb087fd03f', '3e21824be728cbec',\n",
    "        'ea489c253676aafc', '6155b214590c66e6', 'fc32b1a017b34efe', '9c1c7ee8ebdda299',\n",
    "        'fde95ea242abd896', '7a7885e2d7c00bcf', '7245e0ee27b195cd', 'b25c4e2e3856af22',\n",
    "        '7aab7fca2470987e', 'feabbf46658382b9', '04e66e578f653ab9', '5d7fb682edd0f937',\n",
    "        'b4be3a4917289c82', '54fc07138d70374c', 'ef76a85c4b39f693', 'bb9fbec9a2833839',\n",
    "        '3c974920a76ac9c1', '212083a9246d2fd3', '4f79773e600518a6', 'af6f4f548684e14d',\n",
    "        '936168bd4850913d', 'cd5841d44fd7625e', '0797526c057dcf5b', 'a207df29ec9583f0',\n",
    "        '3d7554f1f56dd664', '7023efdab9cedc03', 'da457d15788fe8ee', '12f8b7e14947c34d',\n",
    "        '28e29f2c03dcd84c', '63065128401bb3ff', 'a432c483b5beb856', '37aa9169b575ef79',\n",
    "        '17bc272c93f19d56', '61e73e32ad101892', '4a103c30d593fbbe', '2d0d2c3403909fdb',\n",
    "        '6858d6dfe680bdf7', '17363f08d683d52b', '346393c2c6305fb1', '5b1c11c3efed5312',\n",
    "        '97f15de12cfabbd5', 'a9a43d1a7ecbe75d', '7cf283430b3b5e38', 'c6833cb891626c17',\n",
    "        'a28bb927b6fcb33c', 'dff803b4024d261d', '02aab221aabc03b9', 'f5d69960089c3614',\n",
    "        '06880909932890ca', '79de4e4b24c35b04', 'd0f245b8781e3631', 'c06a2a387c0ee510',\n",
    "        'cc21c7e91a3b5a0c', 'f270f6a489c6a9d7', '8c915fe4632fb9fa', 'c6cd4e0e073f5ac2']\n",
    "\n",
    "provinces = ['浙江', '福建', '四川', '陕西', '安徽', '湖南', '广东', '云南', '上海', '山东',\n",
    "             '湖北', '黑龙江', '江苏', '广西', '内蒙古', '辽宁', '北京', '重庆', '河北', '山西',\n",
    "             '江西', '河南']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:59:05.653748Z",
     "start_time": "2021-06-15T22:59:05.630762Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred, model):\n",
    "    data = pd.DataFrame({'model': model, 'salesVolume': y_true, 'label': y_pred})\n",
    "    data['label'] = data['label'].map(lambda index: -index if index < 0 else index)\n",
    "    res, count = 0, 0\n",
    "    for index, cars in data.groupby('model'):\n",
    "        a = np.array(cars['salesVolume'])\n",
    "        b = np.array(cars['label'])\n",
    "        temp = np.sqrt(np.sum((a - b) ** 2) / len(a)) / np.mean(a)\n",
    "        res += temp\n",
    "        count += 1\n",
    "        print(temp)\n",
    "    return 1 - (res / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取训练/测试数据索引下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:59:05.684731Z",
     "start_time": "2021-06-15T22:59:05.658745Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_feature(windows_size, before):\n",
    "    # windows_size=1, before=10\n",
    "    # windows_size=2, before=9\n",
    "    # windows_size=3, before=8\n",
    "    # windows_size=4, before=7\n",
    "    features = pd.DataFrame()\n",
    "    # 每个车型，每个省份，car_province_part就相当于只有24个月的数据\n",
    "    for car in cars:\n",
    "        for province in provinces:\n",
    "            car_province_part = train_sales_data[(train_sales_data['model'] == car) & (train_sales_data['province'] == province)]\n",
    "            # shift：label为下个月的销售量\n",
    "            car_province_part['label'] = car_province_part['salesVolume'].shift(-windows_size)\n",
    "            # print('car_province_part:\\n', car_province_part)\n",
    "            # car_province_part的行数为24，这里取前23行做训练集\n",
    "            car_province_part = car_province_part[before: 24-windows_size]\n",
    "            features = pd.concat([features, car_province_part], axis=0)\n",
    "    features.index = range(len(features))\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_test_feature(windows_size, before):\n",
    "    features = pd.DataFrame()\n",
    "    for car in cars:\n",
    "        for province in provinces:\n",
    "            car_province_part = train_sales_data[(train_sales_data['model'] == car) & (train_sales_data['province'] == province)]\n",
    "            car_province_part['label'] = car_province_part['salesVolume'].shift(-windows_size)\n",
    "            # print('car_province_part:\\n', car_province_part)\n",
    "            # 最后一行用作验证\n",
    "            car_province_part = car_province_part[-1:]\n",
    "            features = pd.concat([features, car_province_part], axis=0)\n",
    "    features.index = range(len(features))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:59:05.715997Z",
     "start_time": "2021-06-15T22:59:05.686730Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_basic_feature(windows_size, before, data_set_name):\n",
    "    # windows_size=1, before=10, data_set_name='train'\n",
    "    features = pd.DataFrame()\n",
    "    # 遍历\n",
    "    for car in cars:\n",
    "        for province in provinces:\n",
    "            car_province_part = train_sales_data[(train_sales_data['model'] == car) & (train_sales_data['province'] == province)].copy()\n",
    "            \n",
    "            # 对popularity和salesVolume做log变换\n",
    "            car_province_part['popularity'] = car_province_part['popularity'].apply(lambda index: np.log(index))\n",
    "            car_province_part['salesVolume'] = car_province_part['salesVolume'].apply(lambda index: np.log(index))\n",
    "            \n",
    "            # 春节标记特征\n",
    "            car_province_part['is_spring_festival'] = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                                                       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "            car_province_part['distance_spring_festival'] = [1, 0, 1, 2, 3, 4, 5, 5, 4, 3, 2, 1,\n",
    "                                                             0, 1, 2, 3, 4, 5, 6, 6, 5, 4, 3, 2]\n",
    "            \n",
    "            # 一阶差分\n",
    "            for index in range(1, before):\n",
    "                # salesVolume\n",
    "                # shift\n",
    "                car_province_part['salesVolume_' + str(index)] = car_province_part['salesVolume'].shift(index)\n",
    "                # 后一项减前一项\n",
    "                car_province_part['salesVolume_diff_' + str(index)] = car_province_part['salesVolume'].diff(index)\n",
    "                # shift的比值\n",
    "                car_province_part['salesVolume_qoq_' + str(index)] = (car_province_part['salesVolume']\n",
    "                                                                      / car_province_part['salesVolume_' + str(index)])\n",
    "                \n",
    "                # popularity\n",
    "                car_province_part['popularity_' + str(index)] = car_province_part['popularity'].shift(index)\n",
    "                car_province_part['popularity_diff_' + str(index)] = car_province_part['popularity'].diff(index)\n",
    "                car_province_part['popularity_hb_' + str(index)] = (car_province_part['popularity']\n",
    "                                                                    / car_province_part['popularity_' + str(index)])\n",
    "\n",
    "            # 二阶差分\n",
    "            for index in range(1, before-1):   \n",
    "                car_province_part['salesVolume_diff2_' + str(index)] = car_province_part['salesVolume_diff_' + str(index)].diff(1)\n",
    "\n",
    "            # 历史统计特征\n",
    "            salesVolume = list(car_province_part['salesVolume'])\n",
    "            popularity = list(car_province_part['popularity'])\n",
    "            # index=1, 2, 3, 4, ..., 24\n",
    "            car_province_part['index'] = 1\n",
    "            car_province_part['index'] = car_province_part['index'].cumsum()\n",
    "            car_province_part['salesVolume_his'] = car_province_part['index'].map(lambda index: salesVolume[index-7: index])\n",
    "            car_province_part['popularity_his'] = car_province_part['index'].map(lambda index: popularity[index-7: index])\n",
    "\n",
    "            car_province_part['salesVolume_his_diff'] = car_province_part['salesVolume_his'].map(lambda index: np.diff(index))\n",
    "            car_province_part['popularity_his_diff'] = car_province_part['popularity_his'].map(lambda index: np.diff(index))\n",
    "\n",
    "            def pth(array):\n",
    "                return np.max(array) - np.min(array)\n",
    "\n",
    "            fea_name = ['max', 'min', 'aver', 'var', 'pth']\n",
    "            fun_name = [np.max, np.min, np.average, np.var, pth]\n",
    "            for i in range(len(fun_name)):\n",
    "                car_province_part['salesVolume_his_' + fea_name[i]] = car_province_part['salesVolume_his'].apply(\n",
    "                    lambda index: 0 if len(index) == 0 else fun_name[i](index)\n",
    "                )                \n",
    "                car_province_part['salesVolume_his_diff_' + fea_name[i]] = car_province_part['salesVolume_his_diff'].apply(\n",
    "                    lambda index: 0 if len(index) == 0 else fun_name[i](index)\n",
    "                )\n",
    "            \n",
    "            car_province_part.drop(['index', 'salesVolume_his', 'popularity_his', 'salesVolume_his_diff', 'popularity_his_diff'],\n",
    "                                   axis=1,\n",
    "                                   inplace=True)\n",
    "            \n",
    "            # 数据集划分\n",
    "            if data_set_name == 'train':\n",
    "                car_province_part = car_province_part[before: 24-windows_size]\n",
    "            else:\n",
    "                car_province_part = car_province_part[-1:]\n",
    "\n",
    "            car_province_part.drop(['popularity'], axis=1, inplace=True)    ###  , 'day_count', 'day_salesVolume', 'popularity'\n",
    "            features = pd.concat([features, car_province_part], axis=0, ignore_index=True)\n",
    "\n",
    "#     print(features.head())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:59:05.731988Z",
     "start_time": "2021-06-15T22:59:05.717996Z"
    }
   },
   "outputs": [],
   "source": [
    "test_prob_collection = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 一月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:02:59.165197Z",
     "start_time": "2021-06-15T22:59:05.735988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feature.columns: Index(['province', 'adcode', 'model', 'bodyType', 'regYear', 'regMonth',\n",
      "       'label', 'salesVolume', 'is_spring_festival',\n",
      "       'distance_spring_festival', 'salesVolume_1', 'salesVolume_diff_1',\n",
      "       'salesVolume_qoq_1', 'popularity_1', 'popularity_diff_1',\n",
      "       'popularity_hb_1', 'salesVolume_2', 'salesVolume_diff_2',\n",
      "       'salesVolume_qoq_2', 'popularity_2', 'popularity_diff_2',\n",
      "       'popularity_hb_2', 'salesVolume_3', 'salesVolume_diff_3',\n",
      "       'salesVolume_qoq_3', 'popularity_3', 'popularity_diff_3',\n",
      "       'popularity_hb_3', 'salesVolume_4', 'salesVolume_diff_4',\n",
      "       'salesVolume_qoq_4', 'popularity_4', 'popularity_diff_4',\n",
      "       'popularity_hb_4', 'salesVolume_5', 'salesVolume_diff_5',\n",
      "       'salesVolume_qoq_5', 'popularity_5', 'popularity_diff_5',\n",
      "       'popularity_hb_5', 'salesVolume_6', 'salesVolume_diff_6',\n",
      "       'salesVolume_qoq_6', 'popularity_6', 'popularity_diff_6',\n",
      "       'popularity_hb_6', 'salesVolume_7', 'salesVolume_diff_7',\n",
      "       'salesVolume_qoq_7', 'popularity_7', 'popularity_diff_7',\n",
      "       'popularity_hb_7', 'salesVolume_8', 'salesVolume_diff_8',\n",
      "       'salesVolume_qoq_8', 'popularity_8', 'popularity_diff_8',\n",
      "       'popularity_hb_8', 'salesVolume_9', 'salesVolume_diff_9',\n",
      "       'salesVolume_qoq_9', 'popularity_9', 'popularity_diff_9',\n",
      "       'popularity_hb_9', 'salesVolume_diff2_1', 'salesVolume_diff2_2',\n",
      "       'salesVolume_diff2_3', 'salesVolume_diff2_4', 'salesVolume_diff2_5',\n",
      "       'salesVolume_diff2_6', 'salesVolume_diff2_7', 'salesVolume_diff2_8',\n",
      "       'salesVolume_his_max', 'salesVolume_his_diff_max',\n",
      "       'salesVolume_his_min', 'salesVolume_his_diff_min',\n",
      "       'salesVolume_his_aver', 'salesVolume_his_diff_aver',\n",
      "       'salesVolume_his_var', 'salesVolume_his_diff_var',\n",
      "       'salesVolume_his_pth', 'salesVolume_his_diff_pth'],\n",
      "      dtype='object')\n",
      "test_feature.columns: Index(['province', 'adcode', 'model', 'bodyType', 'regYear', 'regMonth',\n",
      "       'label', 'salesVolume', 'is_spring_festival',\n",
      "       'distance_spring_festival', 'salesVolume_1', 'salesVolume_diff_1',\n",
      "       'salesVolume_qoq_1', 'popularity_1', 'popularity_diff_1',\n",
      "       'popularity_hb_1', 'salesVolume_2', 'salesVolume_diff_2',\n",
      "       'salesVolume_qoq_2', 'popularity_2', 'popularity_diff_2',\n",
      "       'popularity_hb_2', 'salesVolume_3', 'salesVolume_diff_3',\n",
      "       'salesVolume_qoq_3', 'popularity_3', 'popularity_diff_3',\n",
      "       'popularity_hb_3', 'salesVolume_4', 'salesVolume_diff_4',\n",
      "       'salesVolume_qoq_4', 'popularity_4', 'popularity_diff_4',\n",
      "       'popularity_hb_4', 'salesVolume_5', 'salesVolume_diff_5',\n",
      "       'salesVolume_qoq_5', 'popularity_5', 'popularity_diff_5',\n",
      "       'popularity_hb_5', 'salesVolume_6', 'salesVolume_diff_6',\n",
      "       'salesVolume_qoq_6', 'popularity_6', 'popularity_diff_6',\n",
      "       'popularity_hb_6', 'salesVolume_7', 'salesVolume_diff_7',\n",
      "       'salesVolume_qoq_7', 'popularity_7', 'popularity_diff_7',\n",
      "       'popularity_hb_7', 'salesVolume_8', 'salesVolume_diff_8',\n",
      "       'salesVolume_qoq_8', 'popularity_8', 'popularity_diff_8',\n",
      "       'popularity_hb_8', 'salesVolume_9', 'salesVolume_diff_9',\n",
      "       'salesVolume_qoq_9', 'popularity_9', 'popularity_diff_9',\n",
      "       'popularity_hb_9', 'salesVolume_diff2_1', 'salesVolume_diff2_2',\n",
      "       'salesVolume_diff2_3', 'salesVolume_diff2_4', 'salesVolume_diff2_5',\n",
      "       'salesVolume_diff2_6', 'salesVolume_diff2_7', 'salesVolume_diff2_8',\n",
      "       'salesVolume_his_max', 'salesVolume_his_diff_max',\n",
      "       'salesVolume_his_min', 'salesVolume_his_diff_min',\n",
      "       'salesVolume_his_aver', 'salesVolume_his_diff_aver',\n",
      "       'salesVolume_his_var', 'salesVolume_his_diff_var',\n",
      "       'salesVolume_his_pth', 'salesVolume_his_diff_pth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "size, pre = 1, 10  # 4\n",
    "train_feature  = get_train_feature(size, pre) # [10: 23] 行用作train\n",
    "test_feature  = get_test_feature(size, pre) # 24 行用作验证\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  'salesVolume'\n",
    "\n",
    "categorial_name = [0, 1, 2, 3, 4, 6, 7]\n",
    "drop_cols = ['salesVolume', 'popularity']\n",
    "\n",
    "# train\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "print('train_feature.columns:', train_feature.columns)\n",
    "\n",
    "# test\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "print('test_feature.columns:', test_feature.columns)\n",
    "\n",
    "# 将2017年12月的特征作为待预测2018年1月的特征，注意label是空\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 1\n",
    "###############################\n",
    "\n",
    "# test index\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 11)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "# train index\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "#  Label Encoder\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:03:22.181486Z",
     "start_time": "2021-06-15T23:02:59.165197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.504982\n",
      "[200]\tvalid_0's rmse: 0.477841\n",
      "[300]\tvalid_0's rmse: 0.467237\n",
      "[400]\tvalid_0's rmse: 0.462656\n",
      "[500]\tvalid_0's rmse: 0.459201\n",
      "[600]\tvalid_0's rmse: 0.457963\n",
      "[700]\tvalid_0's rmse: 0.457999\n",
      "Early stopping, best iteration is:\n",
      "[636]\tvalid_0's rmse: 0.45705\n",
      "importance:\n",
      " [1276 2810   82  164 1650  664  206  157  191  129  138   68  199  172\n",
      "  203  269  233   74  143  153  122  215  151   49   82  110  118  125\n",
      "  150   58  104   80  140  134  131   63   99   98  142  149  141   48\n",
      "  118   96  134  157  167   50  101   99  186  146  147   76  102   85\n",
      "  313  246  170   63  100   97  219  285  231  298  243  220  158  260\n",
      "   85  184  127   95  237   34  172  127  160  143]\n",
      "0.235664444383198\n",
      "0.2639890713606915\n",
      "0.3146114751514538\n",
      "0.20079176350543748\n",
      "0.3653391928575023\n",
      "0.8147338099487671\n",
      "0.2289502493130332\n",
      "0.1838861452194883\n",
      "0.1919407442466147\n",
      "0.15769741247671323\n",
      "0.32897853943959576\n",
      "0.21132295023313058\n",
      "0.11076351612083812\n",
      "0.23377895135917043\n",
      "0.22591865378874315\n",
      "0.30857059317318536\n",
      "0.1140949732527063\n",
      "0.16362335439951958\n",
      "0.13444826175348848\n",
      "0.3450380333995316\n",
      "0.2061555182936783\n",
      "0.24005495683482417\n",
      "0.10661458387994648\n",
      "0.3116174142269199\n",
      "0.11792326567692105\n",
      "0.4422901597090634\n",
      "0.3039270514826982\n",
      "0.3168709697428295\n",
      "0.17405706732798948\n",
      "0.3499579174340662\n",
      "0.37140867656977244\n",
      "0.25055681122771195\n",
      "0.18430615794594246\n",
      "0.12926472780110246\n",
      "0.7827337944393014\n",
      "0.21460281413453708\n",
      "0.11490109395722349\n",
      "0.36137097333525514\n",
      "0.15701799391239216\n",
      "0.15147494953884655\n",
      "1.0461093092641303\n",
      "0.3518451053474527\n",
      "0.10169862502143034\n",
      "0.32256782961156855\n",
      "0.3560722934944002\n",
      "0.9513733349548299\n",
      "0.2750524148698886\n",
      "0.12407046904648082\n",
      "0.8255419037671777\n",
      "0.2846419284325196\n",
      "0.1667339130230932\n",
      "0.16538327048692222\n",
      "0.5383796912201192\n",
      "0.24298373898371878\n",
      "0.2365393928984854\n",
      "0.9363286844067059\n",
      "0.0912766899766409\n",
      "0.2799993100105596\n",
      "0.24186450325009137\n",
      "0.24673216721212138\n",
      "predict:\n",
      " [856.81785681 445.93041706 657.34449898 ... 140.69711785 278.33409934\n",
      " 977.37245736]\n",
      "model train over, rmse: 0.6965592731977972\n",
      "train_feature.shape:  (17160, 80)\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'rmse',\n",
    "    'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 2 ** 5 - 1,    # 2 ** 5 - 1\n",
    "    # 'min_child_samples': 100,\n",
    "    'max_depth': 6,    # 6\n",
    "    'subsample': 0.8,   # 0.8\n",
    "    'subsample_freq': 5,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 2020,\n",
    "    'nthread': -1,\n",
    "    'verbose': 1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# num_boost_round: 5000   early_stopping_rounds:100\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "# feature importance\n",
    "importance = module.feature_importance()\n",
    "print('importance:\\n', importance)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params,\n",
    "                  lgb_data,\n",
    "                  num_boost_round=iters,\n",
    "                  categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "print('predict:\\n', predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)   \n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)\n",
    "print('train_feature.shape: ', train_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 二月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:06:42.632310Z",
     "start_time": "2021-06-15T23:03:22.183483Z"
    }
   },
   "outputs": [],
   "source": [
    "size, pre = 2, 9  # 4\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 2\n",
    "######################################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 10)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:07:02.360196Z",
     "start_time": "2021-06-15T23:06:42.632310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.602171\n",
      "[200]\tvalid_0's rmse: 0.562741\n",
      "[300]\tvalid_0's rmse: 0.555046\n",
      "[400]\tvalid_0's rmse: 0.552141\n",
      "[500]\tvalid_0's rmse: 0.551111\n",
      "[600]\tvalid_0's rmse: 0.55082\n",
      "Early stopping, best iteration is:\n",
      "[513]\tvalid_0's rmse: 0.550694\n",
      "0.17529446590420064\n",
      "0.20748214473161702\n",
      "0.3432403129963316\n",
      "0.2721301228695746\n",
      "0.4532390604901013\n",
      "1.0033628189408994\n",
      "0.20162253932826815\n",
      "0.17817894299515946\n",
      "0.1725769416269705\n",
      "0.16339106831396036\n",
      "0.32634754073980893\n",
      "0.2548127158585516\n",
      "0.1986308262046992\n",
      "0.39298416332255925\n",
      "0.2094806622593866\n",
      "0.2515491391377793\n",
      "0.15461615103333526\n",
      "0.19960941230984003\n",
      "0.10733900727572827\n",
      "0.44050889388663855\n",
      "0.2526560721752099\n",
      "0.3804634605345667\n",
      "0.09128347167908937\n",
      "0.432040859136412\n",
      "0.15247841640016732\n",
      "0.5276635615778361\n",
      "0.28116641811371124\n",
      "0.26310379723230093\n",
      "0.08119645022436948\n",
      "0.3323371205154294\n",
      "0.374451602728627\n",
      "0.17258252319409287\n",
      "0.3143193504351198\n",
      "0.12166167385144219\n",
      "0.7429617172141403\n",
      "0.34800988190362986\n",
      "0.16900996488446238\n",
      "0.4140481101650591\n",
      "0.15950330826692316\n",
      "0.17180314964329116\n",
      "1.1187623997377791\n",
      "0.3459721958953609\n",
      "0.12037305690185768\n",
      "0.28183857518139094\n",
      "0.3540601762480014\n",
      "1.0812353971645259\n",
      "0.27237485478361984\n",
      "0.1459761371595912\n",
      "0.9008707510893544\n",
      "0.3125674567446362\n",
      "0.10479783226152319\n",
      "0.2504559423882538\n",
      "0.6869128788308866\n",
      "0.34217604804028817\n",
      "0.36022845309477947\n",
      "1.1453140955741232\n",
      "0.12273905108805362\n",
      "0.3351951110738329\n",
      "0.37346721447108117\n",
      "0.1630821872555194\n",
      "predict: \n",
      " [683.65837353 320.21882943 431.0470777  ...  79.1989059  136.95732638\n",
      " 401.89481294]\n",
      "model train over, rmse: 0.6615410390819043\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "      'boosting_type': 'gbdt',\n",
    "      'objective': 'rmse',\n",
    "      'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "      'learning_rate': 0.03,\n",
    "      'num_leaves': 2 ** 5 - 1,\n",
    "      # 'min_child_samples': 100,\n",
    "      'max_depth': 6,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 5,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'seed': 2020,\n",
    "      'nthread': -1,\n",
    "      'verbose': 1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# categorial_name = ['adcode', 'model', 'bodyType', 'regYear', 'regMonth']\n",
    "\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params, lgb_data, num_boost_round=iters, categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "print('predict: \\n', predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)   \n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 三月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:10:07.015126Z",
     "start_time": "2021-06-15T23:07:02.362196Z"
    }
   },
   "outputs": [],
   "source": [
    "size, pre = 3, 8   # 5\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 3\n",
    "##############################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 9)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:10:14.585183Z",
     "start_time": "2021-06-15T23:10:07.015126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.634187\n",
      "[200]\tvalid_0's rmse: 0.616264\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's rmse: 0.612924\n",
      "0.36038565164423464\n",
      "0.28104214146461737\n",
      "0.35174189486108703\n",
      "0.3734426225439029\n",
      "0.46096870672375884\n",
      "1.0247092744986555\n",
      "0.3183834916191204\n",
      "0.36539171826472694\n",
      "0.24399587629289776\n",
      "0.15624739058109216\n",
      "0.470694579111279\n",
      "0.29815345311169844\n",
      "0.14722613217262928\n",
      "0.32396964233771824\n",
      "0.34214213271604\n",
      "0.26999258098189344\n",
      "0.1607605920801131\n",
      "0.23172039572037653\n",
      "0.1745219100211342\n",
      "0.5970547354287056\n",
      "0.18640184257962397\n",
      "0.4306250980198308\n",
      "0.11918953271404335\n",
      "0.439271119585673\n",
      "0.2921898824770153\n",
      "0.5916487890285171\n",
      "0.39087591234770513\n",
      "0.34168284428626894\n",
      "0.11857371250377957\n",
      "0.38345217795511033\n",
      "0.25428468671480464\n",
      "0.23634920331071232\n",
      "0.3086089413551588\n",
      "0.09420842535312948\n",
      "1.0101239411820622\n",
      "0.5069624553199465\n",
      "0.16806750244636934\n",
      "0.6195690479548907\n",
      "0.20206585541809063\n",
      "0.12174839142702812\n",
      "1.4751921233320966\n",
      "0.2951202778482063\n",
      "0.08565787789850018\n",
      "0.3792801743634672\n",
      "0.44626641548090085\n",
      "1.103039441788535\n",
      "0.46742696167799697\n",
      "0.20155678143047434\n",
      "0.9316313029714028\n",
      "0.4377142741231477\n",
      "0.2156531242764255\n",
      "0.2750204511784376\n",
      "0.7740501309315442\n",
      "0.43843682138884227\n",
      "0.382868585596168\n",
      "1.0901994794112384\n",
      "0.1938812989559452\n",
      "0.49340233983001563\n",
      "0.2802516260955273\n",
      "0.2321648951475866\n",
      "predict:\n",
      " [868.34102936 429.97805627 534.04493062 ... 110.62292189 150.3017945\n",
      " 488.81179862]\n",
      "model train over, rmse: 0.6005456888686349\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model\n",
    "params = {\n",
    "      'boosting_type': 'gbdt',\n",
    "      'objective': 'rmse',\n",
    "      'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "      'learning_rate': 0.03,\n",
    "      'num_leaves': 2 ** 5 - 1,\n",
    "      # 'min_child_samples': 100,\n",
    "      'max_depth': 6,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 5,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'seed': 2020,\n",
    "      'nthread': -1,\n",
    "      'verbose': 1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# categorial_name = ['adcode', 'model', 'bodyType', 'regYear', 'regMonth']\n",
    "\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params, lgb_data, num_boost_round=iters, categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "print('predict:\\n', predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)\n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-LightGBM - 四月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:13:05.783132Z",
     "start_time": "2021-06-15T23:10:14.588181Z"
    }
   },
   "outputs": [],
   "source": [
    "size, pre = 4, 7   # 5\n",
    "train_feature  = get_train_feature(size, pre)\n",
    "test_feature  = get_test_feature(size, pre)\n",
    "\n",
    "cols = ['province', 'adcode', 'model', 'regYear', 'regMonth', 'bodyType']   #  , 'salesVolume'\n",
    "\n",
    "temp_train = get_basic_feature(size, pre, 'train')\n",
    "train_feature = train_feature.drop(drop_cols, axis=1).merge(temp_train, on=cols, how='left')\n",
    "train_feature\n",
    "\n",
    "temp_test = get_basic_feature(size, pre, 'test')\n",
    "test_feature = test_feature.drop(drop_cols, axis=1).merge(temp_test, on=cols, how='left')\n",
    "test_feature\n",
    "train_feature.isnull().sum()\n",
    "test_feature\n",
    "\n",
    "submit = test_feature[['province', 'adcode', 'model']]\n",
    "submit['regYear'] = 2018\n",
    "submit['regMonth'] = 4\n",
    "###############################\n",
    "\n",
    "test_index = list(train_feature[(train_feature['regYear'] == 2017) & (train_feature['regMonth'] == 8)].index)\n",
    "\n",
    "def drop_duplicate(n):\n",
    "    return n not in test_index\n",
    "\n",
    "train_index = list(filter(drop_duplicate, list(range(len(train_feature)))))\n",
    "\n",
    "train_model = train_feature['model'].values[train_index]   # model\n",
    "val_model = train_feature['model'].values[test_index]\n",
    "\n",
    "model_set = dict()\n",
    "for index in range(len(cars)):\n",
    "    model_set[cars[index]] = index\n",
    "train_feature['bodyType'] = train_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "train_feature['model'] = train_feature['model'].map(model_set)\n",
    "test_feature['bodyType'] = test_feature['bodyType'].map({'Hatchback': 0, 'MPV': 1, 'SUV': 2, 'Sedan': 3})\n",
    "test_feature['model'] = test_feature['model'].map(model_set)\n",
    "\n",
    "train_label = train_feature[['label']]\n",
    "train_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "test_feature.drop(['province', 'label'], axis=1, inplace=True)\n",
    "\n",
    "train_label['log'] = train_label['label'].apply(lambda index: np.log2(index) + 1)\n",
    "x_train = train_feature.values[train_index]\n",
    "y_train = train_label['log'].values[train_index]\n",
    "x_test = train_feature.values[test_index]\n",
    "y_test = train_label['log'].values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:13:23.135671Z",
     "start_time": "2021-06-15T23:13:05.783132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.669032\n",
      "[200]\tvalid_0's rmse: 0.64649\n",
      "[300]\tvalid_0's rmse: 0.637652\n",
      "[400]\tvalid_0's rmse: 0.634277\n",
      "[500]\tvalid_0's rmse: 0.634494\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's rmse: 0.633342\n",
      "0.3316704080482528\n",
      "0.2568025226371792\n",
      "0.41891640981415323\n",
      "0.09862534434881365\n",
      "0.3749036515320365\n",
      "1.0784307265452855\n",
      "0.1786504669472129\n",
      "0.1890259656433429\n",
      "0.3617409424317229\n",
      "0.15471318904954245\n",
      "0.5341985116231796\n",
      "0.19886703890955662\n",
      "0.15946327900008986\n",
      "0.5379378013805817\n",
      "0.36201729196960025\n",
      "0.27797725273290247\n",
      "0.1240418501097146\n",
      "0.21696517969277654\n",
      "0.20729458531302236\n",
      "0.5252144304959323\n",
      "0.27195199400639203\n",
      "0.27774656674449294\n",
      "0.1666924246269019\n",
      "0.32464176169237274\n",
      "0.3750744022885043\n",
      "0.4951248481741097\n",
      "0.2518198829675532\n",
      "0.17720362160304495\n",
      "0.22608656592364906\n",
      "0.39232688337559096\n",
      "0.1841100050062942\n",
      "0.16994869067258278\n",
      "0.4805518659430191\n",
      "0.2030636440104387\n",
      "1.0271065985101475\n",
      "0.46908525943678814\n",
      "0.1265412394230385\n",
      "0.5431664248745748\n",
      "0.2891891497423213\n",
      "0.12786059416903828\n",
      "1.6696098995999586\n",
      "0.29998551379103233\n",
      "0.10082506361718778\n",
      "0.3916647673665618\n",
      "0.4006836853860002\n",
      "1.122577148119743\n",
      "0.6718424206505259\n",
      "0.24344360405115292\n",
      "0.8535300452230455\n",
      "0.3688341074075\n",
      "0.15529600711622946\n",
      "0.34830585019171867\n",
      "0.6677800649370002\n",
      "0.33010443155378605\n",
      "0.3783330991711807\n",
      "0.9741839531511379\n",
      "0.19500389594760242\n",
      "0.3346322435297312\n",
      "0.45556506001834385\n",
      "0.1854472482045829\n",
      "[873.19448282 446.06237551 524.32923833 ...  94.52446757 138.58534059\n",
      " 461.30299882]\n",
      "model train over, rmse: 0.6114267103258371\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "      'boosting_type': 'gbdt',\n",
    "      'objective': 'rmse',\n",
    "      'metric': ['rmse'],   # 'l2', 'binary_logloss',\n",
    "      'learning_rate': 0.03,\n",
    "      'num_leaves': 2 ** 5 - 1,\n",
    "      # 'min_child_samples': 100,\n",
    "      'max_depth': 6,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 5,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'seed': 2020,\n",
    "      'nthread': -1,\n",
    "      'verbose': 1,\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "lgb_eval = lgb.Dataset(x_test, y_test.ravel(), reference=lgb_train)\n",
    "# categorial_name = ['adcode', 'model', 'bodyType', 'regYear', 'regMonth']\n",
    "\n",
    "module = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                   num_boost_round=5000,\n",
    "                   valid_sets=lgb_eval,\n",
    "                   early_stopping_rounds=100,\n",
    "                   categorical_feature=categorial_name,\n",
    "                   verbose_eval=100)\n",
    "\n",
    "val = module.predict(x_test, num_iteration=module.best_iteration)\n",
    "val = 2 ** (val - 1)\n",
    "y_true = 2 ** (y_test.reshape(1, -1)[0] - 1)\n",
    "nrmse = metrics(y_true, val, val_model.reshape(1, -1)[0])\n",
    "\n",
    "iters = module.best_iteration + 100\n",
    "train_all = np.vstack((x_train, x_test))\n",
    "label_all = np.hstack((y_train, y_test))\n",
    "lgb_data = lgb.Dataset(train_all, label_all.ravel())\n",
    "model = lgb.train(params, lgb_data, num_boost_round=iters, categorical_feature=categorial_name)\n",
    "\n",
    "predict = model.predict(test_feature)\n",
    "predict = 2 ** (predict - 1)\n",
    "# print(predict)\n",
    "\n",
    "print('model train over, rmse:', nrmse)\n",
    "submit['forecastVolum'] = predict\n",
    "test_prob_collection = pd.concat([test_prob_collection, submit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:13:23.150661Z",
     "start_time": "2021-06-15T23:13:23.137668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17160, 59)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:13:23.195309Z",
     "start_time": "2021-06-15T23:13:23.152661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>adcode</th>\n",
       "      <th>model</th>\n",
       "      <th>regYear</th>\n",
       "      <th>regMonth</th>\n",
       "      <th>forecastVolum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>浙江</td>\n",
       "      <td>330000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>856.817857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>福建</td>\n",
       "      <td>350000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>445.930417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>四川</td>\n",
       "      <td>510000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>657.344499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>陕西</td>\n",
       "      <td>610000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>161.944001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>安徽</td>\n",
       "      <td>340000</td>\n",
       "      <td>f8a6975573af1b33</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>640.131221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  province  adcode             model  regYear  regMonth  forecastVolum\n",
       "0       浙江  330000  f8a6975573af1b33     2018         1     856.817857\n",
       "1       福建  350000  f8a6975573af1b33     2018         1     445.930417\n",
       "2       四川  510000  f8a6975573af1b33     2018         1     657.344499\n",
       "3       陕西  610000  f8a6975573af1b33     2018         1     161.944001\n",
       "4       安徽  340000  f8a6975573af1b33     2018         1     640.131221"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob_collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:13:23.291246Z",
     "start_time": "2021-06-15T23:13:23.195309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472.5691287878788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob_collection.index = range(len(test_prob_collection))\n",
    "evaluation_public = evaluation_public.merge(test_prob_collection, on=['province', 'adcode', 'model', 'regYear', 'regMonth'], how='left')\n",
    "evaluation_public['forecastVolum'] = evaluation_public['forecastVolum_y']\n",
    "evaluation_public['forecastVolum'] = evaluation_public['forecastVolum'].apply(lambda index: int(np.round(index)))\n",
    "evaluation_public['forecastVolum'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:13:23.323228Z",
     "start_time": "2021-06-15T23:13:23.294244Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation_public[['id', 'forecastVolum']].to_csv('../../sub/sub_method_one.csv', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:13:23.386191Z",
     "start_time": "2021-06-15T23:13:23.327226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regMonth</th>\n",
       "      <th>forecastVolum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>559.806061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>374.103788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>473.390152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>482.976515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regMonth  forecastVolum\n",
       "0         1     559.806061\n",
       "1         2     374.103788\n",
       "2         3     473.390152\n",
       "3         4     482.976515"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_public.describe()\n",
    "evaluation_public.groupby(['regMonth'], as_index=False)['forecastVolum'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
