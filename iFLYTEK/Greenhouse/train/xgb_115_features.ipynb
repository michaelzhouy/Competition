{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.166294Z",
     "start_time": "2020-08-15T02:42:06.892396Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.172249Z",
     "start_time": "2020-08-15T02:42:08.168222Z"
    }
   },
   "outputs": [],
   "source": [
    "def timestamp2string(timeStamp):\n",
    "    try:\n",
    "        d = datetime.fromtimestamp(timeStamp)\n",
    "        str1 = d.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        # 2015-08-28 16:43:37'\n",
    "        return datetime.strptime(str1,'%Y-%m-%d %H:%M:%S')\n",
    "    except Exception as e:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.184178Z",
     "start_time": "2020-08-15T02:42:08.174206Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_psi(c):\n",
    "    psi_res = pd.DataFrame()\n",
    "    psi_dict={}\n",
    "    # for c in tqdm(f_cols):\n",
    "    try:\n",
    "        t_train = x_train[c].fillna(-998)\n",
    "        t_test = x_test[c].fillna(-998)\n",
    "        #获取切分点\n",
    "        bins=[]\n",
    "        for i in np.arange(0,1.1,0.2):\n",
    "            bins.append(t_train.quantile(i))\n",
    "        bins=sorted(set(bins))\n",
    "        bins[0]=-np.inf\n",
    "        bins[-1]=np.inf\n",
    "        #计算psi\n",
    "        t_psi = pd.DataFrame()\n",
    "        t_psi['train'] = pd.cut(t_train,bins).value_counts().sort_index()\n",
    "        t_psi['test'] = pd.cut(t_test,bins).value_counts()\n",
    "        t_psi.index=[str(x) for x in t_psi.index]\n",
    "        t_psi.loc['总计',:] = t_psi.sum()\n",
    "        t_psi['train_rate'] = t_psi['train']/t_psi.loc['总计','train']\n",
    "        t_psi['test_rate'] = t_psi['test']/t_psi.loc['总计','test']\n",
    "        t_psi['psi'] = (t_psi['test_rate']-t_psi['train_rate'])*(np.log(t_psi['test_rate'])-np.log(t_psi['train_rate']))\n",
    "        t_psi.loc['总计','psi'] = t_psi['psi'].sum()\n",
    "        t_psi.index.name=c\n",
    "        #汇总\n",
    "        t_res = pd.DataFrame([[c,t_psi.loc['总计','psi']]],\n",
    "                             columns=['变量名','PSI'])\n",
    "        psi_res = pd.concat([psi_res,t_res])\n",
    "        psi_dict[c]=t_psi\n",
    "        print(c,'done')\n",
    "    except:\n",
    "        print(c,'error')\n",
    "    return psi_res #, psi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.193154Z",
     "start_time": "2020-08-15T02:42:08.185176Z"
    }
   },
   "outputs": [],
   "source": [
    "def correlation(df, threshold=0.98):\n",
    "    \"\"\"\n",
    "    特征相关性计算\n",
    "    @param df: \n",
    "    @param threshold: \n",
    "    @return: \n",
    "    \"\"\"\n",
    "    col_corr = set()\n",
    "    corr_matrix = df.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colName = corr_matrix.columns[i]\n",
    "                col_corr.add(colName)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.590614Z",
     "start_time": "2020-08-15T02:42:08.194154Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_hdf('../input/train.h5')\n",
    "test_df = pd.read_hdf('../input/test.h5')\n",
    "sub = pd.DataFrame(test_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.630812Z",
     "start_time": "2020-08-15T02:42:08.591572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[train_df['temperature'].notnull()]\n",
    "train_df = train_df.fillna(method='bfill')\n",
    "test_df = test_df.fillna(method='bfill')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.636815Z",
     "start_time": "2020-08-15T02:42:08.632806Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.columns = ['time', 'year', 'month', 'day', 'hour', 'min', 'sec', 'outdoorTemp', 'outdoorHum', 'outdoorAtmo',\n",
    "                    'indoorHum', 'indoorAtmo', 'temperature']\n",
    "test_df.columns = ['time', 'year', 'month', 'day', 'hour', 'min', 'sec', 'outdoorTemp', 'outdoorHum', 'outdoorAtmo',\n",
    "                   'indoorHum', 'indoorAtmo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.647787Z",
     "start_time": "2020-08-15T02:42:08.637792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape:  (24807, 13)\n",
      "处理后 train_df.shape:  (19338, 13)\n"
     ]
    }
   ],
   "source": [
    "print('train_df.shape: ', train_df.shape)\n",
    "train_df = train_df.loc[(train_df['outdoorTemp'] >= test_df['outdoorTemp'].min()) & (train_df['outdoorTemp'] <= test_df['outdoorTemp'].max())]\n",
    "print('处理后 train_df.shape: ', train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.652753Z",
     "start_time": "2020-08-15T02:42:08.648764Z"
    }
   },
   "outputs": [],
   "source": [
    "train_count = train_df.shape[0]\n",
    "y_train = train_df['temperature'].values - train_df['outdoorTemp'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.691649Z",
     "start_time": "2020-08-15T02:42:08.653750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "del train_df, test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.696635Z",
     "start_time": "2020-08-15T02:42:08.692646Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']\n",
    "diff_features = ['{}_diff'.format(i) for i in numerical_features]\n",
    "numerical_diff_features = numerical_features + diff_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.708603Z",
     "start_time": "2020-08-15T02:42:08.697632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 1671.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(numerical_features):\n",
    "    data_df['{}_diff'.format(i)] = data_df[i].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:08.715584Z",
     "start_time": "2020-08-15T02:42:08.709600Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:09.034799Z",
     "start_time": "2020-08-15T02:42:08.716582Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df['datetime'] = data_df['time'].apply(timestamp2string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:16.632666Z",
     "start_time": "2020-08-15T02:42:09.035741Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in numerical_diff_features:\n",
    "    for j in ['1D', '2D', '3D']:\n",
    "        data_df.set_index('datetime', inplace=True)\n",
    "        tmp = data_df.groupby('hour')[i].rolling(j, closed='left', min_periods=2).agg({\n",
    "            '{}_{}_rolling_mean'.format(i, j): 'mean',\n",
    "            '{}_{}_rolling_median'.format(i, j): 'median',\n",
    "            '{}_{}_rolling_max'.format(i, j): 'max',\n",
    "            '{}_{}_rolling_min'.format(i, j): 'min',\n",
    "            '{}_{}_rolling_sum'.format(i, j): 'sum',\n",
    "            '{}_{}_rolling_std'.format(i, j): 'std',\n",
    "            '{}_{}_rolling_skew'.format(i, j): 'skew'\n",
    "        })\n",
    "        tmp.reset_index(inplace=True)\n",
    "        data_df.reset_index(inplace=True)\n",
    "        data_df = data_df.merge(tmp, on=['datetime', 'hour'], how='left')\n",
    "        del tmp\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "for i in numerical_diff_features:\n",
    "    data_df.set_index('datetime', inplace=True)\n",
    "    tmp = data_df.groupby('hour')[i].expanding(min_periods=2).agg({\n",
    "        '{}_expanding_mean'.format(i): 'mean',\n",
    "        '{}_expanding_median'.format(i): 'median',\n",
    "        '{}_expanding_max'.format(i): 'max',\n",
    "        '{}_expanding_min'.format(i): 'min',\n",
    "        '{}_expanding_sum'.format(i): 'sum',\n",
    "        '{}_expanding_std'.format(i): 'std',\n",
    "        '{}_expanding_skew'.format(i): 'skew',\n",
    "    })\n",
    "    tmp.reset_index(inplace=True)\n",
    "    data_df.reset_index(inplace=True)\n",
    "    data_df = data_df.merge(tmp, on=['datetime', 'hour'], how='left')\n",
    "    del tmp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:16.712456Z",
     "start_time": "2020-08-15T02:42:16.633667Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.drop('datetime', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:16.731405Z",
     "start_time": "2020-08-15T02:42:16.713453Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:42:25.921567Z",
     "start_time": "2020-08-15T02:42:16.732402Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# 基本聚合特征\n",
    "group_feats = []\n",
    "for f in tqdm(numerical_diff_features):\n",
    "    data_df['MDH_{}_medi'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('median')\n",
    "    data_df['MDH_{}_mean'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('mean')\n",
    "    data_df['MDH_{}_max'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('max')\n",
    "    data_df['MDH_{}_min'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('min')\n",
    "    data_df['MDH_{}_sum'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('sum')\n",
    "    data_df['MDH_{}_std'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('std')\n",
    "    data_df['MDH_{}_skew'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('skew')\n",
    "    \n",
    "    data_df['MD_{}_medi'.format(f)] = data_df.groupby(['month', 'day'])[f].transform('median')\n",
    "    data_df['MD_{}_mean'.format(f)] = data_df.groupby(['month', 'day'])[f].transform('mean')\n",
    "    data_df['MD_{}_max'.format(f)] = data_df.groupby(['month', 'day'])[f].transform('max')\n",
    "    data_df['MD_{}_min'.format(f)] = data_df.groupby(['month', 'day'])[f].transform('min')\n",
    "    data_df['MD_{}_sum'.format(f)] = data_df.groupby(['month', 'day'])[f].transform('sum')\n",
    "    data_df['MD_{}_std'.format(f)] = data_df.groupby(['month', 'day'])[f].transform('std')\n",
    "    data_df['MD_{}_skew'.format(f)] = data_df.groupby(['month', 'day'])[f].transform('skew')\n",
    "\n",
    "    group_feats.append('MDH_{}_medi'.format(f))\n",
    "    group_feats.append('MDH_{}_mean'.format(f))\n",
    "    group_feats.append('MDH_{}_max'.format(f))\n",
    "    group_feats.append('MDH_{}_min'.format(f))\n",
    "    group_feats.append('MDH_{}_sum'.format(f))\n",
    "#     group_feats.append('MDH_{}_std'.format(f))\n",
    "#     group_feats.append('MDH_{}_skew'.format(f))\n",
    "    \n",
    "    group_feats.append('MD_{}_medi'.format(f))\n",
    "    group_feats.append('MD_{}_mean'.format(f))\n",
    "    group_feats.append('MD_{}_max'.format(f))\n",
    "    group_feats.append('MD_{}_min'.format(f))\n",
    "    group_feats.append('MD_{}_sum'.format(f))\n",
    "#     group_feats.append('MD_{}_std'.format(f))\n",
    "#     group_feats.append('MD_{}_skew'.format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:50:19.137364Z",
     "start_time": "2020-08-15T02:42:25.922565Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [07:53<00:00,  4.30s/it]\n"
     ]
    }
   ],
   "source": [
    "cross_features = numerical_diff_features + group_feats\n",
    "\n",
    "# 基本交叉特征\n",
    "for f1 in tqdm(cross_features):\n",
    "    for f2 in cross_features:\n",
    "        if f1 != f2:\n",
    "            # colname_substract = '{}_{}_subtract'.format(f1, f2)\n",
    "            # colname_add = '{}_{}_add'.format(f1, f2)\n",
    "            colname_multiply = '{}_{}_multyply'.format(f1, f2)\n",
    "            colname_ratio = '{}_{}_ratio'.format(f1, f2)\n",
    "            \n",
    "            # data_df[colname_substract] = data_df[f1].values - data_df[f2].values\n",
    "            # data_df[colname_add] = data_df[f1].values + data_df[f2].values\n",
    "            data_df[colname_multiply] = data_df[f1].values * data_df[f2].values\n",
    "            data_df[colname_ratio] = data_df[f1].values / (data_df[f2].values + 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:56:19.478320Z",
     "start_time": "2020-08-15T02:50:19.139332Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [06:00<00:00,  3.28s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(cross_features))):\n",
    "    for j in range(i + 1, len(cross_features)):\n",
    "        colname_add = '{}_{}_add'.format(f1, f2)\n",
    "        colname_substract = '{}_{}_subtract'.format(cross_features[i], cross_features[j])\n",
    "        \n",
    "        data_df[colname_add] = data_df[f1].values + data_df[f2].values\n",
    "        data_df[colname_substract] = data_df[cross_features[i]].values - data_df[cross_features[j]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:56:27.153487Z",
     "start_time": "2020-08-15T02:56:19.485301Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:56:27.195949Z",
     "start_time": "2020-08-15T02:56:27.190998Z"
    }
   },
   "outputs": [],
   "source": [
    "# 历史信息提取\n",
    "# data_df['dt'] = data_df['day'].values + (data_df['month'].values - 3) * 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:56:27.205923Z",
     "start_time": "2020-08-15T02:56:27.199938Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_t_sts(f):\n",
    "#     tmp_df = pd.DataFrame()\n",
    "#     for t in tqdm(range(15, 45)):\n",
    "#         tmp_data = data_df.loc[data_df['dt'] < t, :]\n",
    "#         tmp = tmp_data.groupby(['hour'], as_index=False)[f].agg({\n",
    "#             'hit_{}_mean'.format(f): 'mean',\n",
    "#             'hit_{}_median'.format(f): 'median',\n",
    "#             'hit_{}_max'.format(f): 'max',\n",
    "#             'hit_{}_min'.format(f): 'min',\n",
    "#             'hit_{}_sum'.format(f): 'sum',\n",
    "#             'hit_{}_std'.format(f): 'std',\n",
    "#             'hit_{}_skew'.format(f): 'skew'\n",
    "#         })\n",
    "#         tmp['dt'] = t\n",
    "#         tmp_df = tmp_df.append(tmp)\n",
    "#         del tmp\n",
    "#         gc.collect()\n",
    "    \n",
    "#     data_df = data_df.merge(tmp_df, on=['dt', 'hour'], how='left')\n",
    "#     del tmp_df\n",
    "#     gc.collect()\n",
    "    \n",
    "# Parallel(n_jobs=4)(delayed(get_t_sts)(f) for f in tqdm(numerical_diff_features + ['temperature']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:56:27.214899Z",
     "start_time": "2020-08-15T02:56:27.206920Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_t_1_sts(f):\n",
    "#     tmp_df = pd.DataFrame()\n",
    "#     for t in tqdm(range(15, 45)):\n",
    "#         tmp = data_df.loc[(data_df['dt'] < t) & (data_df['dt'] >= t - 1), :].groupby(['hour'], as_index=False)[f].agg({\n",
    "#             'hit_t_1_{}_mean'.format(f): 'mean',\n",
    "#             'hit_t_1_{}_median'.format(f): 'median',\n",
    "#             'hit_t_1_{}_max'.format(f): 'max',\n",
    "#             'hit_t_1_{}_min'.format(f): 'min',\n",
    "#             'hit_t_1_{}_sum'.format(f): 'sum',\n",
    "#             'hit_t_1_{}_std'.format(f): 'std',\n",
    "#             'hit_t_1_{}_skew'.format(f): 'skew'\n",
    "#         })\n",
    "#         tmp['dt'] = t\n",
    "#         tmp_df = tmp_df.append(tmp)\n",
    "#         del tmp\n",
    "#         gc.collect()\n",
    "\n",
    "#     data_df = data_df.merge(tmp_df, on=['dt', 'hour'], how='left')\n",
    "#     del tmp_df\n",
    "#     gc.collect()\n",
    "\n",
    "# Parallel(n_jobs=4)(delayed(get_t_1_sts)(f) for f in tqdm(numerical_diff_features + ['temperature']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:56:27.219886Z",
     "start_time": "2020-08-15T02:56:27.215895Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_t_2_sts(f):\n",
    "#     tmp_df = pd.DataFrame()\n",
    "#     for t in tqdm(range(15, 45)):\n",
    "#         tmp = data_df.loc[(data_df['dt'] < t) & (data_df['dt'] >= t - 2), :].groupby(['hour'], as_index=False)[f].agg({\n",
    "#             'hit_t_1_{}_mean'.format(f): 'mean',\n",
    "#             'hit_t_1_{}_median'.format(f): 'median',\n",
    "#             'hit_t_1_{}_max'.format(f): 'max',\n",
    "#             'hit_t_1_{}_min'.format(f): 'min',\n",
    "#             'hit_t_1_{}_sum'.format(f): 'sum',\n",
    "#             'hit_t_1_{}_std'.format(f): 'std',\n",
    "#             'hit_t_1_{}_skew'.format(f): 'skew'\n",
    "#         })\n",
    "#         tmp['dt'] = t\n",
    "#         tmp_df = tmp_df.append(tmp)\n",
    "#         del tmp\n",
    "#         gc.collect()\n",
    "\n",
    "#     data_df = data_df.merge(tmp_df, on=['dt', 'hour'], how='left')\n",
    "#     del tmp_df\n",
    "#     gc.collect()\n",
    "\n",
    "# Parallel(n_jobs=4)(delayed(get_t_2_sts)(f) for f in tqdm(numerical_diff_features + ['temperature']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:56:28.550448Z",
     "start_time": "2020-08-15T02:56:27.221914Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:56:28.867871Z",
     "start_time": "2020-08-15T02:56:28.562064Z"
    }
   },
   "outputs": [],
   "source": [
    "# 离散化\n",
    "for f in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "    data_df[f + '_20_bin'] = pd.cut(data_df[f], 20, duplicates='drop').apply(lambda x: x.left).astype(int)\n",
    "    data_df[f + '_50_bin'] = pd.cut(data_df[f], 50, duplicates='drop').apply(lambda x: x.left).astype(int)\n",
    "    data_df[f + '_100_bin'] = pd.cut(data_df[f], 100, duplicates='drop').apply(lambda x: x.left).astype(int)\n",
    "    data_df[f + '_200_bin'] = pd.cut(data_df[f], 200, duplicates='drop').apply(lambda x: x.left).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T02:56:28.875853Z",
     "start_time": "2020-08-15T02:56:28.870866Z"
    }
   },
   "outputs": [],
   "source": [
    "# for f1 in tqdm(['outdoorTemp_20_bin', 'outdoorHum_20_bin', 'outdoorAtmo_20_bin', 'indoorHum_20_bin', 'indoorAtmo_20_bin']):\n",
    "#     for f2 in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "#         data_df['{}_{}_medi'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "#         data_df['{}_{}_mean'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "#         data_df['{}_{}_max'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "#         data_df['{}_{}_min'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "#         data_df['{}_{}_sum'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('sum')\n",
    "#         data_df['{}_{}_std'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('std')\n",
    "#         data_df['{}_{}_skew'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('skew')\n",
    "\n",
    "# for f1 in tqdm(['outdoorTemp_50_bin', 'outdoorHum_50_bin', 'outdoorAtmo_50_bin', 'indoorHum_50_bin', 'indoorAtmo_50_bin']):\n",
    "#     for f2 in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "#         data_df['{}_{}_medi'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "#         data_df['{}_{}_mean'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "#         data_df['{}_{}_max'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "#         data_df['{}_{}_min'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "#         data_df['{}_{}_sum'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('sum')\n",
    "#         data_df['{}_{}_std'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('std')\n",
    "#         data_df['{}_{}_skew'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('skew')\n",
    "\n",
    "# for f1 in tqdm(['outdoorTemp_100_bin', 'outdoorHum_100_bin', 'outdoorAtmo_100_bin', 'indoorHum_100_bin',\n",
    "#                 'indoorAtmo_100_bin']):\n",
    "#     for f2 in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "#         data_df['{}_{}_medi'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "#         data_df['{}_{}_mean'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "#         data_df['{}_{}_max'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "#         data_df['{}_{}_min'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "#         data_df['{}_{}_sum'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('sum')\n",
    "#         data_df['{}_{}_std'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('std')\n",
    "#         data_df['{}_{}_skew'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('skew')\n",
    "\n",
    "# for f1 in tqdm(['outdoorTemp_200_bin', 'outdoorHum_200_bin', 'outdoorAtmo_200_bin', 'indoorHum_200_bin',\n",
    "#                 'indoorAtmo_200_bin']):\n",
    "#     for f2 in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "#         data_df['{}_{}_medi'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "#         data_df['{}_{}_mean'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "#         data_df['{}_{}_max'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "#         data_df['{}_{}_min'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "#         data_df['{}_{}_sum'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('sum')\n",
    "#         data_df['{}_{}_std'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('std')\n",
    "#         data_df['{}_{}_skew'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('skew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:23:20.776659Z",
     "start_time": "2020-08-15T02:56:28.876850Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [26:51<00:00, 80.59s/it]\n"
     ]
    }
   ],
   "source": [
    "for f1 in tqdm(['{}_20_bin'.format(i) for i in numerical_features] +\n",
    "               ['{}_50_bin'.format(i) for i in numerical_features] +\n",
    "               ['{}_100_bin'.format(i) for i in numerical_features] +\n",
    "               ['{}_200_bin'.format(i) for i in numerical_features]):\n",
    "    for f2 in numerical_features:\n",
    "        tmp = data_df.groupby(f1, as_index=False)[f2].agg({\n",
    "            '{}_{}_medi'.format(f1, f2): 'median',\n",
    "            '{}_{}_mean'.format(f1, f2): 'mean',\n",
    "            '{}_{}_max'.format(f1, f2): 'max',\n",
    "            '{}_{}_min'.format(f1, f2): 'min',\n",
    "            '{}_{}_sum'.format(f1, f2): 'sum',\n",
    "            '{}_{}_std'.format(f1, f2): 'std',\n",
    "            '{}_{}_skew'.format(f1, f2): 'skew'\n",
    "        })\n",
    "        data_df = data_df.merge(tmp, on=f1, how='left')\n",
    "        del tmp\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:23:32.111986Z",
     "start_time": "2020-08-15T03:23:20.776659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = data_df[:train_count].copy().reset_index(drop=True)\n",
    "test_df = data_df[train_count:].copy().reset_index(drop=True)\n",
    "\n",
    "del data_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:23:34.304843Z",
     "start_time": "2020-08-15T03:23:32.112984Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_columns = [\"time\", \"year\", \"sec\", \"temperature\"]\n",
    "\n",
    "features = train_df[:1].drop(drop_columns, axis=1).columns\n",
    "x_train = train_df[features]\n",
    "x_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:55:11.429024Z",
     "start_time": "2020-08-15T03:23:34.304843Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 31130/31130 [31:32<00:00, 16.45it/s]\n"
     ]
    }
   ],
   "source": [
    "psi_res = Parallel(n_jobs=4)(delayed(get_psi)(c) for c in tqdm(features))\n",
    "psi_df = pd.concat(psi_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:55:11.454720Z",
     "start_time": "2020-08-15T03:55:11.429024Z"
    }
   },
   "outputs": [],
   "source": [
    "features = list(psi_df[psi_df['PSI'] <= 0.2]['变量名'].values) + ['outdoorTemp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:55:12.514313Z",
     "start_time": "2020-08-15T03:55:11.454720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train[features]\n",
    "x_test = x_test[features]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T01:25:34.094656Z",
     "start_time": "2020-08-16T01:25:34.089519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:55:16.731066Z",
     "start_time": "2020-08-15T03:55:12.515311Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_hdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-442f0d3e0c30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/train_features.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'df'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/test_features.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'df'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/y_train_features.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'df'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_hdf'"
     ]
    }
   ],
   "source": [
    "x_train.to_hdf('../input/train_features.h5', 'df')\n",
    "x_test.to_hdf('../input/test_features.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-16T01:26:40.114Z"
    }
   },
   "outputs": [],
   "source": [
    "col_corr = correlation(x_train, 0.98)\n",
    "print(col_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-16T01:26:40.116Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.drop(list(col_corr), axis=1, inplace=True)\n",
    "x_test.drop(list(col_corr), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-16T01:26:40.118Z"
    }
   },
   "outputs": [],
   "source": [
    "nums = int(x_train.shape[0] * 0.8)\n",
    "\n",
    "trn_x, trn_y, val_x, val_y = x_train[:nums], y_train[:nums], x_train[nums:], y_train[nums:]\n",
    "\n",
    "train_matrix = xgb.DMatrix(trn_x, label=trn_y, missing=np.nan)\n",
    "valid_matrix = xgb.DMatrix(val_x, label=val_y, missing=np.nan)\n",
    "train_all_matrix = xgb.DMatrix(x_train, y_train, missing=np.nan)\n",
    "test_matrix = xgb.DMatrix(x_test, label=val_y, missing=np.nan)\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'mae',\n",
    "    'min_child_weight': 5,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'eta': 0.01,\n",
    "    'seed': 2020,\n",
    "    'nthread': 36,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "watchlist = [(train_matrix, 'train'), (valid_matrix, 'eval')]\n",
    "\n",
    "model_eval = xgb.train(params,\n",
    "                       train_matrix,\n",
    "                       num_boost_round=50000,\n",
    "                       evals=watchlist,\n",
    "                       verbose_eval=500,\n",
    "                       early_stopping_rounds=1000)\n",
    "val_pred = model_eval.predict(valid_matrix, ntree_limit=model_eval.best_ntree_limit).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-16T01:26:40.120Z"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(val_y, val_pred)\n",
    "print(\"mse_score:\", mse)\n",
    "print(\"mse_score:\", str(mse)[2:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-16T01:26:40.121Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_imp_dict = model_eval.get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-16T01:26:40.123Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(feat_imp_dict).sort_values(ascending=False).reset_index().rename(columns={'index': 'feature',\n",
    "                                                                                               0: 'importance'})\n",
    "feat_imp['normalized_importance'] = feat_imp['importance'] / feat_imp['importance'].sum()\n",
    "feat_imp['cumulative_importance'] = np.cumsum(feat_imp['normalized_importance'])\n",
    "record_low_importance = feat_imp[feat_imp['cumulative_importance'] > 0.92]\n",
    "\n",
    "to_drop = list(record_low_importance['feature'])\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-16T01:26:40.124Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.drop(to_drop, axis=1, inplace=True)\n",
    "x_test.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-16T01:26:40.125Z"
    }
   },
   "outputs": [],
   "source": [
    "train_all_matrix = xgb.DMatrix(x_train, y_train, missing=np.nan)\n",
    "test_matrix = xgb.DMatrix(x_test, label=val_y, missing=np.nan)\n",
    "\n",
    "model = xgb.train(params,\n",
    "                  train_all_matrix,\n",
    "                  num_boost_round=model_eval.best_ntree_limit + 20)\n",
    "\n",
    "test_pred = model.predict(test_matrix, ntree_limit=model.best_ntree_limit).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-16T01:26:40.127Z"
    }
   },
   "outputs": [],
   "source": [
    "sub['temperature'] = test_pred[:, 0] + test_df['outdoorTemp'].values\n",
    "sub.to_csv('../sub/sub_{}_{}.csv'.format(time.strftime('%Y%m%d'), str(mse)[2:7]), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
